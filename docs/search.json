[
  {
    "objectID": "topics-2024/2024-05-24-sits/index.html",
    "href": "topics-2024/2024-05-24-sits/index.html",
    "title": "sits R package",
    "section": "",
    "text": "Image: Py-R Geospatial\nSummary: The sits package wraps up rstac, gdalcubes, and tmap, with nice defaults. It works with 7 collections which are different combinations of Landsat and Sentinel-2 catalogs.\nIt has functions for helping with fitting ML models to these data cubes.",
    "crumbs": [
      "JupyterHub",
      "R - sits R package"
    ]
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/index.html#how-to-clone",
    "href": "topics-2024/2024-05-24-sits/index.html#how-to-clone",
    "title": "sits R package",
    "section": "How to clone",
    "text": "How to clone\nNever cloned the NOAAHackDays repo?\ncd ~\ngit clone https://github.com/nmfs-opensci/NOAAHackDays\nHave cloned it but need to update? This is going to destroy any changes that you made to the repo to make it match the current state of the repo on GitHub.\ncd ~/NOAAHackDays\ngit fetch origin\ngit reset --hard origin/main",
    "crumbs": [
      "JupyterHub",
      "R - sits R package"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-25-vast/index.html",
    "href": "topics-2024/2024-04-25-vast/index.html",
    "title": "VAST",
    "section": "",
    "text": "Image: R - VAST",
    "crumbs": [
      "JupyterHub",
      "R - VAST"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-25-vast/index.html#how-to-clone",
    "href": "topics-2024/2024-04-25-vast/index.html#how-to-clone",
    "title": "VAST",
    "section": "How to clone",
    "text": "How to clone\nNever cloned the NOAAHackDays repo?\ncd ~\ngit clone https://github.com/nmfs-opensci/NOAAHackDays\nHave cloned it but need to update? This is going to destroy any changes that you made to the repo to make it match the current state of the repo on GitHub.\ncd ~/NOAAHackDays\ngit fetch origin\ngit reset --hard origin/main",
    "crumbs": [
      "JupyterHub",
      "R - VAST"
    ]
  },
  {
    "objectID": "topics-skills/02-rstudio.html#open-rstudio-in-the-jupyterhub",
    "href": "topics-skills/02-rstudio.html#open-rstudio-in-the-jupyterhub",
    "title": "RStudio",
    "section": "Open RStudio in the JupyterHub",
    "text": "Open RStudio in the JupyterHub\n\nLogin the JupyterHub\nClick on the RStudio button when the Launcher appears \nLook for the browser tab with the RStudio icon",
    "crumbs": [
      "JupyterHub",
      "RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-rstudio.html#basic-navigation",
    "href": "topics-skills/02-rstudio.html#basic-navigation",
    "title": "RStudio",
    "section": "Basic Navigation",
    "text": "Basic Navigation\n\n\n\nRStudio Panels",
    "crumbs": [
      "JupyterHub",
      "RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-rstudio.html#create-an-rstudio-project",
    "href": "topics-skills/02-rstudio.html#create-an-rstudio-project",
    "title": "RStudio",
    "section": "Create an RStudio project",
    "text": "Create an RStudio project\n\nOpen RStudio\nIn the file panel, click on the Home icon to make sure you are in your home directory\nFrom the file panel, click “New Project” to create a new project\nIn the pop up, select New Directory and then New Project\nName it sandbox\nClick on the dropdown in the upper right corner to select your sandbox project\nClick on Tools &gt; Project Options &gt; General and change the first 2 options about saving and restoring the workspace to “No”",
    "crumbs": [
      "JupyterHub",
      "RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-rstudio.html#installing-packages",
    "href": "topics-skills/02-rstudio.html#installing-packages",
    "title": "RStudio",
    "section": "Installing packages",
    "text": "Installing packages\nIn the bottom right panel, select the Packages tab, click install and then start typing the name of the package. Then click Install.\nThe JupyterHub comes with many packages already installed so you shouldn’t have to install many packages.\nWhen you want to use a package, you first need to load it with\nlibrary(hello)\nYou will see this in the tutorials. You might also see something like\nhello::thefunction()\nThis is using thefunction() from the hello package.\n\n\n\n\n\n\nNote\n\n\n\nPython users. In R, you will always call a function like funtion(object) and never like object.function(). The exception is something called ‘piping’ in R, which I have never seen in Python. In this case you pass objects left to right. Like object %&gt;% function(). Piping is very common in modern R but you won’t see it much in R from 10 years ago.",
    "crumbs": [
      "JupyterHub",
      "RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-rstudio.html#uploading-and-downloading-files",
    "href": "topics-skills/02-rstudio.html#uploading-and-downloading-files",
    "title": "RStudio",
    "section": "Uploading and downloading files",
    "text": "Uploading and downloading files\nNote, Upload and download is only for the JupyterHub not on RStudio on your computer.\n\nUploading is easy.\nLook for the Upload button in the Files tab of the bottom right panel.\n\n\nDownload is less intuitive.\n\nClick the checkbox next to the file you want to download. One only.\nClick the “cog” icon in the Files tab of the bottom right panel. Then click Export.",
    "crumbs": [
      "JupyterHub",
      "RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-rstudio.html#creating-files",
    "href": "topics-skills/02-rstudio.html#creating-files",
    "title": "RStudio",
    "section": "Creating files",
    "text": "Creating files\nWhen you start your server, you will have access to your own virtual drive space. No other users will be able to see or access your files. You can upload files to your virtual drive space and save files here. You can create folders to organize your files. You personal directory is home/rstudio. Everyone has the same home directory but your files are separate and cannot be seen by others.\nPython users: If you open a Python image instead of the R image, your home is home/jovyan.\nThere are a number of different ways to create new files. Let’s practice making new files in RStudio.\n\nR Script\n\nOpen RStudio\nIn the upper right, make sure you are in your sandbox project.\nFrom the file panel, click on “New Blank File” and create a new R script.\nPaste\n\nprint(\"Hello World\")\n1+1\nin the script. 7. Click the Source button (upper left of your new script file) to run this code. 8. Try putting your cursor on one line and running that line of code by clicking “Run” 9. Try selecting lines of code and running that by clicking “Run”\n\n\ncsv file\n\nFrom the file panel, click on “New Blank File” and create a Text File.\nThe file will open in the top left corner. Paste in the following:\n\nname, place, value\nA, 1, 2\nB, 10, 20\nC, 100, 200\n\nClick the save icon (above your new file) to save your csv file\n\n\n\nA Rmarkdown document\nNow let’s create some more complicated files using the RStudio template feature.\n\nFrom the upper left, click File -&gt; New File -&gt; RMarkdown\nClick “Ok” at the bottom.\nWhen the file opens, click Knit (icon at top of file).\nIt will ask for a name. Give it one and save.\nYou file will render into html.\n\nReference sheet for writing in RMarkdown or go to Help &gt; Markdown Quick Reference\n\n\nA Rmarkdown presentation\n\nFrom the upper left, click File -&gt; New File -&gt; RMarkdown\nClick “Presentation” on left of the popup and click “Ok” at the bottom.\nWhen the file opens, click Knit (icon at top of file).\nIt will ask for a name. Give it one and save.\nYou file will render into html.\n\n\n\n(advanced) An interactive application\n\nFrom the upper left, click File -&gt; New File -&gt; Shiny Web App\nIn the popup, give the app a name and make sure the app is saved to my-files\nWhen the file opens, Run App (icon at top of file).\n\n\n\nAnd many more\nPlay around with creating other types of documents using templates. Especially if you already use RStudio.",
    "crumbs": [
      "JupyterHub",
      "RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-rstudio.html#more-tips",
    "href": "topics-skills/02-rstudio.html#more-tips",
    "title": "RStudio",
    "section": "More tips",
    "text": "More tips\nLearn some tips and tricks from these\n\nhttps://colorado.posit.co/rsc/the-unknown/into-the-unknown.html\nhttps://www.dataquest.io/blog/rstudio-tips-tricks-shortcuts/",
    "crumbs": [
      "JupyterHub",
      "RStudio"
    ]
  },
  {
    "objectID": "topics-2025/2025-virtualizarr/index.html",
    "href": "topics-2025/2025-virtualizarr/index.html",
    "title": "VirtualiZarr",
    "section": "",
    "text": "https://virtualizarr.readthedocs.io/en/stable/index.html\nhttps://agu.confex.com/agu/agu24/meetingapp.cgi/Paper/1677256"
  },
  {
    "objectID": "topics-2025/2025-icechunk/index.html",
    "href": "topics-2025/2025-icechunk/index.html",
    "title": "Icechunk",
    "section": "",
    "text": "https://earthmover.io/blog/icechunk/ https://icechunk.io/en/latest/ https://icechunk.io/en/latest/icechunk-python/quickstart/\n1 hr talk https://youtu.be/i-73e3_irpY?feature=shared Pangeo showcase: https://youtu.be/l_y8YOn8hm8?feature=shared"
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/index.html",
    "href": "topics-2024/2024-05-17-ocean-color/index.html",
    "title": "Ocean Color Mapping",
    "section": "",
    "text": "Image: Py - Openscapes",
    "crumbs": [
      "JupyterHub",
      "Python - PACE Ocean Color"
    ]
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/index.html#how-to-clone",
    "href": "topics-2024/2024-05-17-ocean-color/index.html#how-to-clone",
    "title": "Ocean Color Mapping",
    "section": "How to clone",
    "text": "How to clone\nNever cloned the NOAAHackDays repo?\ncd ~\ngit clone https://github.com/nmfs-opensci/NOAAHackDays\nHave cloned it but need to update? This is going to destroy any changes that you made to the repo to make it match the current state of the repo on GitHub.\ncd ~/NOAAHackDays\ngit fetch origin\ngit reset --hard origin/main",
    "crumbs": [
      "JupyterHub",
      "Python - PACE Ocean Color"
    ]
  },
  {
    "objectID": "topics-skills/index.html",
    "href": "topics-skills/index.html",
    "title": "JupyterHub",
    "section": "",
    "text": "Explore the topics in the left navigation bar to learn how to use JupyterLab, RStudio and Git in the JupyterHub plus the other resources available.",
    "crumbs": [
      "JupyterHub",
      "JupyterHub Skills"
    ]
  },
  {
    "objectID": "topics-skills/04-learning.html",
    "href": "topics-skills/04-learning.html",
    "title": "Learning Resources",
    "section": "",
    "text": "You are welcome to use the JupyterHub outside of the HackHours and workshops in order to facilitate your data science and cloud-computing learning. Here are some ideas:",
    "crumbs": [
      "JupyterHub",
      "Learning resources"
    ]
  },
  {
    "objectID": "topics-skills/04-learning.html#python",
    "href": "topics-skills/04-learning.html#python",
    "title": "Learning Resources",
    "section": "Python",
    "text": "Python\n\nUdemy, Coursera, and DataCamp are popular platforms that have data science courses.\n\nI did Python for Data Science and Machine Learning Bootcamp in Udemy\n\nThe same have deep-learning and ML courses\nHarvard https://pll.harvard.edu/catalog and MIT https://ocw.mit.edu/search/?q=python have lots of free material\nGeosciences\n\nhttps://cookbooks.projectpythia.org/\nhttps://nasa-openscapes.github.io/earthdata-cloud-cookbook/\nhttps://ioos.github.io/ioos_code_lab/content/intro.html\nhttps://github.com/coastwatch-training/CoastWatch-Tutorials\nhttps://github.com/NASAARSET\nhttps://earth-env-data-science.github.io/intro.html",
    "crumbs": [
      "JupyterHub",
      "Learning resources"
    ]
  },
  {
    "objectID": "topics-skills/04-learning.html#r",
    "href": "topics-skills/04-learning.html#r",
    "title": "Learning Resources",
    "section": "R",
    "text": "R\n\nUdemy, Coursera, and DataCamp are popular platforms that have data science courses.\nGeosciences\n\nhttps://github.com/USGS-R\nhttps://pmarchand1.github.io/atelier_rgeo/rgeo_workshop.html\nhttps://datacarpentry.github.io/r-raster-vector-geospatial/\nhttps://r.geocompx.org/\nhttps://bookdown.org/mcwimberly/gdswr-book/\nhttps://rspatial.org/index.html",
    "crumbs": [
      "JupyterHub",
      "Learning resources"
    ]
  },
  {
    "objectID": "topics-skills/03-ScratchBucket.html",
    "href": "topics-skills/03-ScratchBucket.html",
    "title": "Using the S3 Scratch Bucket",
    "section": "",
    "text": "The JupyterHub has a preconfigured S3 “Scratch Bucket” that automatically deletes files after 7 days. This is a great resource for experimenting with large datasets and working collaboratively on a shared dataset with other users.",
    "crumbs": [
      "JupyterHub",
      "S3 Scratch Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-ScratchBucket.html#access-the-scratch-bucket",
    "href": "topics-skills/03-ScratchBucket.html#access-the-scratch-bucket",
    "title": "Using the S3 Scratch Bucket",
    "section": "Access the scratch bucket",
    "text": "Access the scratch bucket\nThe scratch bucket is hosted at s3://nmfs-openscapes-scratch. The JupyterHub automatically sets an environment variable SCRATCH_BUCKET that appends a suffix to the s3 url with your GitHub username. This is intended to keep track of file ownership, stay organized, and prevent users from overwriting data!\nEveryone has full access to the scratch bucket, so be careful not to overwrite data from other users when uploading files. Also, any data you put there will be deleted 7 days after it is uploaded\nIf you need more permanent S3 bucket storage refer to AWS_S3_bucket documentation (left) to configure your own S3 Bucket.\nWe’ll use the S3FS Python package, which provides a nice interface for interacting with S3 buckets.\n\nimport os\nimport s3fs\nimport fsspec\nimport boto3\nimport xarray as xr\nimport geopandas as gpd\n\n\n# My GitHub username is `eeholmes`\nscratch = os.environ['SCRATCH_BUCKET']\nscratch \n\n's3://nmfs-openscapes-scratch/eeholmes'\n\n\n\n# But you can set a different S3 object prefix to use:\nscratch = 's3://nmfs-openscapes-scratch/hackhours'",
    "crumbs": [
      "JupyterHub",
      "S3 Scratch Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-ScratchBucket.html#uploading-data",
    "href": "topics-skills/03-ScratchBucket.html#uploading-data",
    "title": "Using the S3 Scratch Bucket",
    "section": "Uploading data",
    "text": "Uploading data\nIt’s great to store data in S3 buckets because this storage features very high network throughput. If many users are simultaneously accessing the same file on a spinning networked harddrive (/home/jovyan/shared) performance can be quite slow. S3 has much higher performance for such cases.\n\nUpload single file\n\nlocal_file = '~/NOAAHackDays/topics-2025/2025-02-14-earthdata/littlecube.nc'\n\nremote_object = f\"{scratch}/littlecube.nc\"\n\ns3.upload(local_file, remote_object)\n\n[None]\n\n\nOnce a bucket has files, I can list them. If the bucket is empty, you will get errors instead of [].\n\ns3 = s3fs.S3FileSystem()\ns3.ls(scratch)\n\n['nmfs-openscapes-scratch/hackhours/littlecube.nc']\n\n\n\ns3.stat(remote_object)\n\n{'Key': 'nmfs-openscapes-scratch/hackhours/littlecube.nc',\n 'LastModified': datetime.datetime(2025, 2, 13, 21, 41, 5, tzinfo=tzlocal()),\n 'ETag': '\"d73616d9e3ad84cf58a4a676b1e3d454\"',\n 'ChecksumAlgorithm': ['CRC32'],\n 'ChecksumType': 'FULL_OBJECT',\n 'Size': 50224,\n 'StorageClass': 'STANDARD',\n 'type': 'file',\n 'size': 50224,\n 'name': 'nmfs-openscapes-scratch/hackhours/littlecube.nc'}\n\n\n\n\nUpload a directory\n\nlocal_dir = '~/NOAAHackDays/topics-2025/resources'\n\n!ls -lh {local_dir}\n\ntotal 5.9M\n-rw-r--r-- 1 jovyan jovyan 5.9M Feb 12 21:05 e_sst.nc\ndrwxr-xr-x 3 jovyan jovyan  281 Feb 12 21:18 longhurst_v4_2010\n\n\n\ns3.upload(local_dir, scratch, recursive=True)\n\n[None, None, None, None, None, None, None, None, None]\n\n\nThe directory name is the directory name (only) of the local directory.\n\ns3.ls(f'{scratch}/resources')\n\n['nmfs-openscapes-scratch/hackhours/resources/e_sst.nc',\n 'nmfs-openscapes-scratch/hackhours/resources/longhurst_v4_2010']",
    "crumbs": [
      "JupyterHub",
      "S3 Scratch Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-ScratchBucket.html#accessing-data",
    "href": "topics-skills/03-ScratchBucket.html#accessing-data",
    "title": "Using the S3 Scratch Bucket",
    "section": "Accessing Data",
    "text": "Accessing Data\nSome software packages allow you to stream data directly from S3 Buckets. But you can always pull objects from S3 and work with local file paths.\nThis download-first, then analyze workflow typically works well for older file formats like HDF and netCDF that were designed to perform well on local hard drives rather than Cloud storage systems like S3.\nFor best performance do not work with data in your home directory. Instead use a local scratch space like `/tmp`\n\nremote_object\n\n's3://nmfs-openscapes-scratch/hackhours/littlecube.nc'\n\n\n\nlocal_object = '/tmp/test.nc'\ns3.download(remote_object, local_object)\n\n[None]\n\n\n\nds = xr.open_dataset(local_object)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 97kB\nDimensions:       (time: 366, lat: 8, lon: 8)\nCoordinates:\n  * time          (time) datetime64[ns] 3kB 2020-01-01 2020-01-02 ... 2020-12-31\n  * lat           (lat) float32 32B 33.62 33.88 34.12 ... 34.88 35.12 35.38\n  * lon           (lon) float32 32B -75.38 -75.12 -74.88 ... -73.88 -73.62\nData variables:\n    analysed_sst  (time, lat, lon) float32 94kB ...xarray.DatasetDimensions:time: 366lat: 8lon: 8Coordinates: (3)time(time)datetime64[ns]2020-01-01 ... 2020-12-31long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time because observations are from different sources and are made at different times of the day.array(['2020-01-01T00:00:00.000000000', '2020-01-02T00:00:00.000000000',\n       '2020-01-03T00:00:00.000000000', ..., '2020-12-29T00:00:00.000000000',\n       '2020-12-30T00:00:00.000000000', '2020-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')lat(lat)float3233.62 33.88 34.12 ... 35.12 35.38long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0bounds :lat_bndscomment :Uniform grid with centers from -89.875 to 89.875 by 0.25 degreesarray([33.625, 33.875, 34.125, 34.375, 34.625, 34.875, 35.125, 35.375],\n      dtype=float32)lon(lon)float32-75.38 -75.12 ... -73.88 -73.62long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0bounds :lon_bndscomment :Uniform grid with centers from -179.875 to 179.875 by 0.25 degreesarray([-75.375, -75.125, -74.875, -74.625, -74.375, -74.125, -73.875, -73.625],\n      dtype=float32)Data variables: (1)analysed_sst(time, lat, lon)float32...long_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :kelvinvalid_min :-300valid_max :4500source :UNKNOWN,ICOADS SHIPS,ICOADS BUOYS,ICOADS argos,MMAB_50KM-NCEP-ICEcomment :Single-sensor Pathfinder 5.0/5.1 AVHRR SSTs used until 2005; two AVHRRs at a time are used 2007 onward. Sea ice and in-situ data used also are near real time quality for recent period. SST (bulk) is at ambiguous depth because multiple types of observations are used.[23424 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',\n               '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08',\n               '2020-01-09', '2020-01-10',\n               ...\n               '2020-12-22', '2020-12-23', '2020-12-24', '2020-12-25',\n               '2020-12-26', '2020-12-27', '2020-12-28', '2020-12-29',\n               '2020-12-30', '2020-12-31'],\n              dtype='datetime64[ns]', name='time', length=366, freq=None))latPandasIndexPandasIndex(Index([33.625, 33.875, 34.125, 34.375, 34.625, 34.875, 35.125, 35.375], dtype='float32', name='lat'))lonPandasIndexPandasIndex(Index([-75.375, -75.125, -74.875, -74.625, -74.375, -74.125, -73.875, -73.625], dtype='float32', name='lon'))Attributes: (0)\n\n\nIf you don't want to think about downloading files you can let `fsspec` handle this behind the scenes for you! This way you only need to think about remote paths\n\nfs = fsspec.filesystem(\"simplecache\", \n                       cache_storage='/tmp/files/',\n                       same_names=True,  \n                       target_protocol='s3',\n                       )\n\n\n# The `simplecache` setting above will download the full file to /tmp/files\nprint(remote_object)\nwith fs.open(remote_object) as f:\n    ds = xr.open_dataset(f.name) # NOTE: pass f.name for local cached path\n\ns3://nmfs-openscapes-scratch/hackhours/littlecube.nc\n\n\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 97kB\nDimensions:       (time: 366, lat: 8, lon: 8)\nCoordinates:\n  * time          (time) datetime64[ns] 3kB 2020-01-01 2020-01-02 ... 2020-12-31\n  * lat           (lat) float32 32B 33.62 33.88 34.12 ... 34.88 35.12 35.38\n  * lon           (lon) float32 32B -75.38 -75.12 -74.88 ... -73.88 -73.62\nData variables:\n    analysed_sst  (time, lat, lon) float32 94kB ...xarray.DatasetDimensions:time: 366lat: 8lon: 8Coordinates: (3)time(time)datetime64[ns]2020-01-01 ... 2020-12-31long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time because observations are from different sources and are made at different times of the day.array(['2020-01-01T00:00:00.000000000', '2020-01-02T00:00:00.000000000',\n       '2020-01-03T00:00:00.000000000', ..., '2020-12-29T00:00:00.000000000',\n       '2020-12-30T00:00:00.000000000', '2020-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')lat(lat)float3233.62 33.88 34.12 ... 35.12 35.38long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0bounds :lat_bndscomment :Uniform grid with centers from -89.875 to 89.875 by 0.25 degreesarray([33.625, 33.875, 34.125, 34.375, 34.625, 34.875, 35.125, 35.375],\n      dtype=float32)lon(lon)float32-75.38 -75.12 ... -73.88 -73.62long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0bounds :lon_bndscomment :Uniform grid with centers from -179.875 to 179.875 by 0.25 degreesarray([-75.375, -75.125, -74.875, -74.625, -74.375, -74.125, -73.875, -73.625],\n      dtype=float32)Data variables: (1)analysed_sst(time, lat, lon)float32...long_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :kelvinvalid_min :-300valid_max :4500source :UNKNOWN,ICOADS SHIPS,ICOADS BUOYS,ICOADS argos,MMAB_50KM-NCEP-ICEcomment :Single-sensor Pathfinder 5.0/5.1 AVHRR SSTs used until 2005; two AVHRRs at a time are used 2007 onward. Sea ice and in-situ data used also are near real time quality for recent period. SST (bulk) is at ambiguous depth because multiple types of observations are used.[23424 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',\n               '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08',\n               '2020-01-09', '2020-01-10',\n               ...\n               '2020-12-22', '2020-12-23', '2020-12-24', '2020-12-25',\n               '2020-12-26', '2020-12-27', '2020-12-28', '2020-12-29',\n               '2020-12-30', '2020-12-31'],\n              dtype='datetime64[ns]', name='time', length=366, freq=None))latPandasIndexPandasIndex(Index([33.625, 33.875, 34.125, 34.375, 34.625, 34.875, 35.125, 35.375], dtype='float32', name='lat'))lonPandasIndexPandasIndex(Index([-75.375, -75.125, -74.875, -74.625, -74.375, -74.125, -73.875, -73.625], dtype='float32', name='lon'))Attributes: (0)",
    "crumbs": [
      "JupyterHub",
      "S3 Scratch Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-ScratchBucket.html#cloud-optimized-formats",
    "href": "topics-skills/03-ScratchBucket.html#cloud-optimized-formats",
    "title": "Using the S3 Scratch Bucket",
    "section": "Cloud-optimized formats",
    "text": "Cloud-optimized formats\nOther formats like COG, ZARR, Parquet are ‘Cloud-optimized’ and allow for very efficient streaming directly from S3. In other words, you do not need to download entire files and instead can easily read subsets of the data.\nThe example below reads a Parquet file directly into memory (RAM) from S3 without using a local disk:\n\n# first upload the file\nlocal_file = '~/NOAAHackDays/topics-2025/resources/example.parquet'\n\nremote_object = f\"{scratch}/example.parquet\"\n\ns3.upload(local_file, remote_object)\n\n[None]\n\n\n\ngf = gpd.read_parquet(remote_object)\ngf.head(2)\n\n\n\n\n\n\n\n\npop_est\ncontinent\nname\niso_a3\ngdp_md_est\ngeometry\n\n\n\n\n0\n889953.0\nOceania\nFiji\nFJI\n5496\nMULTIPOLYGON (((180 -16.06713, 180 -16.55522, ...\n\n\n1\n58005463.0\nAfrica\nTanzania\nTZA\n63177\nPOLYGON ((33.90371 -0.95, 34.07262 -1.05982, 3...",
    "crumbs": [
      "JupyterHub",
      "S3 Scratch Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-ScratchBucket.html#advanced-access-scratch-bucket-outside-of-jupyterhub",
    "href": "topics-skills/03-ScratchBucket.html#advanced-access-scratch-bucket-outside-of-jupyterhub",
    "title": "Using the S3 Scratch Bucket",
    "section": "Advanced: Access Scratch bucket outside of JupyterHub",
    "text": "Advanced: Access Scratch bucket outside of JupyterHub\nLet’s say you have a lot of files on your laptop you want to work with. The S3 Bucket is a convient way to upload large datasets for collaborative analysis. To do this, you need to copy AWS Credentials from the JupyterHub to use on other machines. More extensive documentation on this workflow can be found in this repository https://github.com/scottyhq/jupyter-cloud-scoped-creds.\nThe following code must be run on the JupyterHub to get temporary credentials:\n\nclient = boto3.client('sts')\n\nwith open(os.environ['AWS_WEB_IDENTITY_TOKEN_FILE']) as f:\n    TOKEN = f.read()\n\nresponse = client.assume_role_with_web_identity(\n    RoleArn=os.environ['AWS_ROLE_ARN'],\n    RoleSessionName=os.environ['JUPYTERHUB_CLIENT_ID'],\n    WebIdentityToken=TOKEN,\n    DurationSeconds=3600\n)\n\nreponse will be a python dictionary that looks like this:\n{'Credentials': {'AccessKeyId': 'ASIAYLNAJMXY2KXXXXX',\n  'SecretAccessKey': 'J06p5IOHcxq1Rgv8XE4BYCYl8TG1XXXXXXX',\n  'SessionToken': 'IQoJb3JpZ2luX2VjEDsaCXVzLXdlc////0dsD4zHfjdGi/0+s3XKOUKkLrhdXgZ8nrch2KtzKyYyb...',\n  'Expiration': datetime.datetime(2023, 7, 21, 19, 51, 56, tzinfo=tzlocal())},\n  ...\nYou can copy and paste the values to another computer, and use them to configure your access to S3:\n\ns3 = s3fs.S3FileSystem(key=response['Credentials']['AccessKeyId'],\n                       secret=response['Credentials']['SecretAccessKey'],\n                       token=response['Credentials']['SessionToken'] )\n\n\n# Confirm your credentials give you access\ns3.ls('nmfs-openscapes-scratch', refresh=True)",
    "crumbs": [
      "JupyterHub",
      "S3 Scratch Bucket"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html",
    "href": "topics-skills/02-intro-to-lab.html",
    "title": "Intro to JupyterLab",
    "section": "",
    "text": "When you start the JupyterHub, you will be in JupyterLab.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#terminalshell",
    "href": "topics-skills/02-intro-to-lab.html#terminalshell",
    "title": "Intro to JupyterLab",
    "section": "Terminal/Shell",
    "text": "Terminal/Shell\nLog into the JupyterHub. If you do not see something like this\n\nThen go to File &gt; New Launcher\nClick on the “Terminal” box to open a new terminal window.\n\nShell or Terminal Basics\nIf you have no experience working in a terminal, check out this self-paced lesson on running scripts from the shell: Shell Lesson from Software Carpentry\nBasic shell commands:\n\npwd where am I\ncd nameofdir move into a directory\ncd .. move up a directory\nls list the files in the current directory\nls -a list the files including hidden files\nls -l list the files with more info\ncat filename print out the contents of a file\nrm filename remove a file\nrm -r directoryname remove a directory\nrm -rf directoryname force remove a directory; careful no recovery\n\nClose the terminal by clicking on the X in the terminal tab.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#file-navigation",
    "href": "topics-skills/02-intro-to-lab.html#file-navigation",
    "title": "Intro to JupyterLab",
    "section": "File Navigation",
    "text": "File Navigation\nIn the far left, you will see a line of icons. The top one is a folder and allows us to move around our file system.\n\nClick on file icon below the blue button with a +. Now you see files in your home directory.\nClick on the folder icon that looks like this. Click on the actual folder image. \nThis shows me doing this\n\nCreate a new folder.\n\nNext to the blue rectange with a +, is a grey folder with a +. Click that to create a new folder, called lesson-scripts.\n\n\nCreate a new file\n\nCreate with File &gt; New &gt; Text file\nThe file will open and you can edit it.\nSave with File &gt; Save Text\n\nDelete a file\n\nDelete a file by right-clicking on it and clicking “Delete”",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#create-a-new-jupyter-notebook",
    "href": "topics-skills/02-intro-to-lab.html#create-a-new-jupyter-notebook",
    "title": "Intro to JupyterLab",
    "section": "Create a new Jupyter notebook",
    "text": "Create a new Jupyter notebook\nFrom Launcher, click on the “Python 3” button, this will open a new Jupyter notebook.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#basic-jupyter-notebook-navigation",
    "href": "topics-skills/02-intro-to-lab.html#basic-jupyter-notebook-navigation",
    "title": "Intro to JupyterLab",
    "section": "Basic Jupyter notebook navigation",
    "text": "Basic Jupyter notebook navigation\nA Jupyter notebook is a series of cells than can be code (default), markdown or raw text.\n\nLook at the top cell, this is a code cell which I could see if I click on the cell and look at the top navbar. Next to “Download”, it says “Code”. I can click that dropdown and change the cell type to markdown or raw.\nTo the left of the “Save” icon in the top navbar is a “+”. This will add a new cell.\nWithin a cell, you will see some icons on the right. Roll over these icons to see what they do.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#running-code-in-a-cell",
    "href": "topics-skills/02-intro-to-lab.html#running-code-in-a-cell",
    "title": "Intro to JupyterLab",
    "section": "Running code in a cell",
    "text": "Running code in a cell\nTo run code in a cell, click in the cell and then hit “Shift Return”. You can also click “Run” in the menu or click the little right arrow in the top navbar above the cells.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#creating-and-rendering-markdown",
    "href": "topics-skills/02-intro-to-lab.html#creating-and-rendering-markdown",
    "title": "Intro to JupyterLab",
    "section": "Creating and rendering markdown",
    "text": "Creating and rendering markdown\nCreate an new cell (you can click the “+” in the top navbar) and then change to markdown by clicking the dropdown next to “Download” in the top navbar. Type in some markdown and the run the cell (see above on how to run cells).",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#running-all-cells-in-a-notebook",
    "href": "topics-skills/02-intro-to-lab.html#running-all-cells-in-a-notebook",
    "title": "Intro to JupyterLab",
    "section": "Running all cells in a notebook",
    "text": "Running all cells in a notebook\nUse the “Run” menu.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#install-packages",
    "href": "topics-skills/02-intro-to-lab.html#install-packages",
    "title": "Intro to JupyterLab",
    "section": "Install packages",
    "text": "Install packages\nUse pip install in a cell. This will not persist between sessions.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-intro-to-lab.html#learn-more",
    "href": "topics-skills/02-intro-to-lab.html#learn-more",
    "title": "Intro to JupyterLab",
    "section": "Learn more",
    "text": "Learn more\nThere are lots of tutorials on JupyterLab out there. Do a search to find content that works for you.",
    "crumbs": [
      "JupyterHub",
      "JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#prerequisites",
    "href": "topics-skills/02-git-terminal.html#prerequisites",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nRead Intro to Git\nHave a GitHub account\nGit Authentication",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#create-a-github-account",
    "href": "topics-skills/02-git-terminal.html#create-a-github-account",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\nFor access to the NMFS Openscapes JupyterHub, you will need at GitHub account. See the main HackHour page on how to request access (NOAA staff). For NMFS staff, you can look at the NMFS OpenSci GitHub Guide information for how to create your user account and you will find lots of information on the NMFS GitHub Governance Team Training Page (visible only to NOAA staff).",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#setting-up-git-authentication",
    "href": "topics-skills/02-git-terminal.html#setting-up-git-authentication",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "Setting up Git Authentication",
    "text": "Setting up Git Authentication\nBefore we can work with Git in the JupyterHub, your need to do some set up. Do the steps here: Git Authentication",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#git-in-the-terminal",
    "href": "topics-skills/02-git-terminal.html#git-in-the-terminal",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "Git in the terminal",
    "text": "Git in the terminal\nYou will need to open a terminal in JupyterLab or RStudio.",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#the-key-skills",
    "href": "topics-skills/02-git-terminal.html#the-key-skills",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "The Key Skills",
    "text": "The Key Skills\n\nSkill 1: Create a blank repo on GitHub\nSkill 2: Clone your GitHub repo\nSkill 3: Make some changes and commit those local changes\nSkill 4: Push the changes to GitHub\nSkill 1b: Copy someone else’s GitHub repository",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#lets-see-it-done",
    "href": "topics-skills/02-git-terminal.html#lets-see-it-done",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "Let’s see it done!",
    "text": "Let’s see it done!\n\nSkill 1: Create a blank repo on GitHub\nThis skill is done on GitHub.com.\n\nClick the + in the upper left from YOUR GitHub page.\nGive your repo the name Test and make sure it is public.\nClick new and check checkbox to add the Readme file and .gitignore\nCopy the URL of your new repo. It’s in the browser where you normally see a URL.\n\n\n\nSkill 2: Clone your repo\nThese skills are done in a terminal from JupyterLab or RStudio.\n\nCopy the URL of your repo. https://www.github.com/yourname/Test\nOpen a terminal.\nMake sure you are at the home directory level. Type this: cd ~\nClone the repo with this command. Replace yourname with your username. git clone https://www.github.com/yourname/Test\n\n\n\nSkill 3: Make some changes and commit your changes\nDo step 1 in your editor, JupyterLab or RStudio.\n\nMake some changes to the README.md file in the Test repo.\nGo to the terminal and make sure you are in your Test repo. cd ~/Test\nSee what has changed. You should see that README.md has changed. git status\nStage the change to the README.md git add README.md\nCommit the change. `git commit -m “small change”\n\n\n\nSkill 4: Push changes to GitHub / Pull changes from GitHub\nTo push changes you committed in Skill #3\n\nFrom the terminal, type git push\n\nTo pull changes on GitHub that are not on your local computer:\n\nMake some changes directly on GitHub.com and commit\nFrom the terminal, type git pull\n\n\n\nActivity 1\nDo steps 1 to 3 in your editor, JupyterLab or RStudio, and steps 4 and 5 in the terminal on the JupyterHub.\n\nMake a copy of README.md\nRename it to .md\nAdd some text.\nStage and commit the added file.\nPush to GitHub.\n\nShow me\n\n\nActivity 2\nDo steps 1-3 on GitHub and step 4 from the terminal on the JupyterHub.\n\nGo to your Test repo on GitHub. https://www.github.com/yourname/Test\nCreate a file called test.md.\nStage and then commit that new file.\nPull in that new file.\n\n\n\nActivity 3\nYou can copy your own or other people’s repos1.\n\nIn a browser, go to the GitHub repository https://github.com/RWorkflow-Workshops/Week5\nCopy its URL.\nNavigate to your GitHub page: click your icon in the upper right and then ‘your repositories’\nClick the + in top right and click import repository. Paste in the URL and give your repo a name.\nUse Skill #1 to clone your new repo to the JupyterHub.",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#clean-up-after-you-are-done",
    "href": "topics-skills/02-git-terminal.html#clean-up-after-you-are-done",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "Clean up after you are done",
    "text": "Clean up after you are done\n\nOpen a Terminal\nType\ncd ~\nrm -rf Test\nrm -rf Week5",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-terminal.html#footnotes",
    "href": "topics-skills/02-git-terminal.html#footnotes",
    "title": "Basic Git/GitHub Skills in the Terminal",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is different from forking. There is no connection to the original repository.↩︎",
    "crumbs": [
      "JupyterHub",
      "Git in the terminal"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#prerequisites",
    "href": "topics-skills/02-git-jupyter.html#prerequisites",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nRead Intro to Git\nHave a GitHub account\nGit Authentication",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#create-a-github-account",
    "href": "topics-skills/02-git-jupyter.html#create-a-github-account",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\nFor access to the NMFS Openscapes JupyterHub, you will need at GitHub account. See the main HackHour page on how to request access (NOAA staff). For NMFS staff, you can look at the NMFS OpenSci GitHub Guide information for how to create your user account and you will find lots of information on the NMFS GitHub Governance Team Training Page (visible only to NOAA staff).",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#setting-up-git-authentication",
    "href": "topics-skills/02-git-jupyter.html#setting-up-git-authentication",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "Setting up Git Authentication",
    "text": "Setting up Git Authentication\nBefore we can work with Git in the JupyterHub, your need to authenticate. Do the steps here: Git Authentication",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#git-extension-in-jupyterlab",
    "href": "topics-skills/02-git-jupyter.html#git-extension-in-jupyterlab",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "Git extension in JupyterLab",
    "text": "Git extension in JupyterLab\nWhen the instructions say to use or open or click the Git GUI, look here:",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#the-key-skills",
    "href": "topics-skills/02-git-jupyter.html#the-key-skills",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "The Key Skills",
    "text": "The Key Skills\n\nSkill 1: Create a blank repo on GitHub\nSkill 2: Clone your GitHub repo\nSkill 3: Make some changes and commit those local changes\nSkill 4: Push the changes to GitHub\nSkill 1b: Copy someone else’s GitHub repository",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#lets-see-it-done",
    "href": "topics-skills/02-git-jupyter.html#lets-see-it-done",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "Let’s see it done!",
    "text": "Let’s see it done!\n\nSkill 1: Create a blank repo on GitHub\n\nClick the + in the upper left from YOUR GitHub account (https://www.github.com/yourusername).\nGive your repo the name Test and make sure it is public.\nClick new and check checkbox to add the Readme file and .gitignore\nCopy the URL of your new repo. It’s in the browser where you normally see a URL.\n\n\n\nSkill 2: Clone your repo\nFirst make sure you are at the home directory level. Look at the folder icon under the blue launcher button. It should show, folder icon only like in this image. If not, then click on the folder icon.\n\n\nCopy the URL of your repo. https://www.github.com/yourname/Test\nClick on the git icon and then click “Clone a Repository” \nPaste in the URL of your repo from Step 1\nClick Clone. You can stay with the defaults for the checkboxes.\n\nShow me\n\n\nSkill 3: Make some changes and commit your changes\nThis writes a note about what changes you have made. It also marks a ‘point’ in time that you can go back to if you need to.\n\nClick on the README.md file in the Test repo.\nMake some changes to the file.\nClick the Git icon (in left navbar), and stage the change(s) by checking the “+” next to the files listed.\nAdd a commit message in the box.\nClick the Commit button at bottom.\n\nShow me\n\n\nSkill 4: Push changes to GitHub / Pull changes from GitHub\nTo push changes you committed in Skill #3\n\nFrom Git icon, look for the little cloud at the top. It is rather small. Click that to push changes.\n\nTo pull changes on GitHub that are not on your local computer:\n\nMake some changes directly on GitHub (not in JupyterLab)\nFrom Git icon, click on the little cloud with a down arrow.\n\n\n\nActivity 1\n\nMake a copy of README.md\nRename it to .md\nAdd some text.\nStage and commit the added file.\nPush to GitHub.\n\nShow me\n\n\nActivity 2\n\nIn the Test repo, create a file called to &lt;yourname&gt;.md.\nStage and then commit that new file.\nPush to GitHub.\nMake some more changes and push to GitHub.\n\n\n\nActivity 3\nYou can copy your own or other people’s repos1.\n\nIn a browser, go to the GitHub repository https://github.com/RWorkflow-Workshops/Week5\nCopy its URL.\nNavigate to your GitHub page: click your icon in the upper right and then ‘your repositories’\nClick the + in top right and click import repository. Paste in the URL and give your repo a name.\nUse Skill #1 to clone your new repo to JupyterLab",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#clean-up-after-you-are-done",
    "href": "topics-skills/02-git-jupyter.html#clean-up-after-you-are-done",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "Clean up after you are done",
    "text": "Clean up after you are done\n\nOpen a Terminal\nType\ncd ~\nrm -rf Test\nrm -rf Week5",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter.html#footnotes",
    "href": "topics-skills/02-git-jupyter.html#footnotes",
    "title": "Basic Git/GitHub Skills in JupyterLab git GUI",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is different from forking. There is no connection to the original repository.↩︎",
    "crumbs": [
      "JupyterHub",
      "Git in JupyterLab"
    ]
  },
  {
    "objectID": "topics-skills/02-git-clinic.html",
    "href": "topics-skills/02-git-clinic.html",
    "title": "Git Clinic",
    "section": "",
    "text": "In this tutorial, we will provide a brief introduction to version control with Git."
  },
  {
    "objectID": "topics-skills/02-git-clinic.html#step-3",
    "href": "topics-skills/02-git-clinic.html#step-3",
    "title": "Git Clinic",
    "section": "Step 3:",
    "text": "Step 3:\nConfigure git with your name and email address.\n``` bash\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\n```\n\n**Note:** This name and email could be different from your github.com credentials. Remember `git` is a program that keeps track of your changes locally (on 2i2c JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by `git`, the email/name used in git configuration will show up next to your contributions on github.com when you `push` your repository to github.com (`git push` is discussed in a later step).\n\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\n\n\nGenerate Personal Access Token on github.com\n\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git JupyterLab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "topics-2025/index.html",
    "href": "topics-2025/index.html",
    "title": "HackHours 2025",
    "section": "",
    "text": "During these stand-alone informal sessions we will get introduced to a variety of tools for ocean data access and analysis in Python and R. We will be using the NOAA Fisheries Openscapes JupyterHub and you will not need to install anything. About the HackHours\nWhen: Fridays 11am Pacific/2pm Eastern. How do I get access? Click here for Video Link and JupyterHub Access (NOAA only)",
    "crumbs": [
      "JupyterHub",
      "HackHours 2025"
    ]
  },
  {
    "objectID": "topics-2025/index.html#schedule",
    "href": "topics-2025/index.html#schedule",
    "title": "HackHours 2025",
    "section": "Schedule",
    "text": "Schedule\n\nFeb 7 - Q&A and Intro to the Ocean Data Science JupyterHub and Friday HackHours\nFeb 14 - Accessing NASA Earth Observation data in Python (Eli Holmes) \nFeb 21 - Accessing NASA Earth Observation data in R (Eli Holmes) \nFeb 28 - Working with ERDDAP data in Python: CoastWatch tutorials (Sunny Hospital, Polarwatch; Daisy Shi, CoastWatch) \nMar 7 - Working with ERDDAP data in R: CoastWatch tutorials (Sunny Hospital, Polarwatch; Daisy Shi, CoastWatch) \nMar 14 - Introduction to the Nautilus HyperCluster for running containerized Big Data Applications (Carl Boettiger, UC Berkeley) \nMar 21 - Parallel processing NODD model data with Coiled (Rich Signell, Open Science Consulting) \nMar 28 - Working with data on OPeNDAP servers in Python & R  \nApr 4 - xarray + GPU integration (Max Jones, Development Seed) \nApr 11 - Accessing CEFI data on OPeNDAP, AWS and Google (Chia-Wei Hsu, NOAA PSL) \nApr 25 - Working with acoustic data in Python: echopype (Wu-Jung Lee, UW APL) \nMay 2 - Coiled demo – parallel processing for big data pipelines (Coiled team)\nMay 9 - PACE Hyperspectral Ocean Color Data Access and Visualization in Python (earthaccess) \nMay 16 - PACE Hyperspectral Ocean Color Data Access and Visualization in R \nMay 19 - EDMW 3-hour Workshop working with PACE hyperspectral data\nMay 30 - Machine-Learning with Ocean Data: gap-filling with CNNs",
    "crumbs": [
      "JupyterHub",
      "HackHours 2025"
    ]
  },
  {
    "objectID": "topics-2024/index.html#select-an-event-to-the-left",
    "href": "topics-2024/index.html#select-an-event-to-the-left",
    "title": "HackHours 2024",
    "section": "Select an event to the left",
    "text": "Select an event to the left\n\nJune 14. CEFI Portal team. (Python)\nMay 31. Another PACE satellite mission tutorial by the NASA OB.DAAC Ocean Color team. (Python)\nMay 24. Accessing NASA Harmonized Landsat data with the e-sensing R package. tutorial Eli Holmes, NOAA (R)\nMay 17. Visualizing the data from the PACE satellite mission by the NASA OB.DAAC Ocean Color team. Ian Carroll, NASA (Python)\nMay 10. Accessing Earthdata in Python. Test run of our Python tutorials for the Openscapes mentors’ EDM workshop. Eli Holmes (Python)\nMay 3. Accessing Earthdata in R. Test run of our R tutorials for the Openscapes mentors’ EDM workshop. Eli Holmes (R)\nApril 26th. More acoustics data with echopype. Wu-Jung Lee from UW/APL (Python) Set-up\nApril 19th. Parallel computing with dask and coiled.io. Eli Holmes (Python) Set-up\nApril 12th. Exploring CMIP6 data with pangeo Python tools. Eli Holmes. Pythia CMIP6 Cookbook\nApril 5th. Using ArcGIS via the arcgis Python API. Tim Haverland from OST/DisMap.\nMarch 29th. Accessing acoustics data from AWS Open Data (echopype examples). Eli Holmes (Python)\nMarch 22nd. 1pm PT CoastWatch tutorials in R. Sunny Hospital and Daisy Shi from CoastWatch (R)\nMarch 15th. CoastWatch tutorials in Python. Sunny Hospital and Dale Robinson from CoastWatch (Python)\nMarch 8th. Using precipitation estimates from IMERG tutorial Eli Holmes (Python)",
    "crumbs": [
      "JupyterHub",
      "HackHours 2024"
    ]
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/oci_data_access.html",
    "href": "topics-2024/2024-05-17-ocean-color/oci_data_access.html",
    "title": "Access Data from the Ocean Color Instrument (OCI)",
    "section": "",
    "text": "Authors: Anna Windle (NASA, SSAI), Ian Carroll (NASA, UMBC), Carina Poulin (NASA, SSAI)"
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/oci_data_access.html#summary",
    "href": "topics-2024/2024-05-17-ocean-color/oci_data_access.html#summary",
    "title": "Access Data from the Ocean Color Instrument (OCI)",
    "section": "Summary",
    "text": "Summary\n\nIn this example we will use the earthaccess package to search for OCI products on NASA Earthdata. The earthaccess package, published on the Python Package Index and conda-forge, facilitates discovery and use of all NASA Earth Science data products by providing an abstraction layer for NASA’s Common Metadata Repository (CMR) API and by simplifying requests to NASA’s Earthdata Cloud. Searching for data is more approachable using earthaccess than low-level HTTP requests, and the same goes for S3 requests.\nIn short, earthaccess helps authenticate with Earthdata Login, makes search easier, and provides a stream-lined way to load data into xarray containers. For more on earthaccess, visit the documentation site. Be aware that earthaccess is under active development.\nTo understand the discussions below on downloading and opening data, we need to clearly understand where our notebook is running. There are three cases to distinguish:\n\nThe notebook is running on the local host. For instance, you started a Jupyter server on your laptop.\nThe notebook is running on a remote host, but it does not have direct access to the NASA Earthdata Cloud. For instance, you are running in GitHub Codespaces.\nThe notebook is running on a remote host that does have direct access to the NASA Earthdata Cloud. At this time, we cannot provide a “for instance” which is available to everyone."
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/oci_data_access.html#learning-objectives",
    "href": "topics-2024/2024-05-17-ocean-color/oci_data_access.html#learning-objectives",
    "title": "Access Data from the Ocean Color Instrument (OCI)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nAt the end of this notebook you will know:\n\nHow to store your NASA Earthdata Login credentials with earthaccess\nHow to use earthaccess to search for OCI data using search filters\nHow to download OCI data, but only when you need to\n\n ## Contents ***\n\nSetup\nNASA Earthdata Authentication\nSearch for Data\nDownload Data\n\n ## 1. Setup ***\nWe begin by importing the only package used in this notebook. If you have created an environment following the guidance provided with this tutorial, then the import will be successful.\n\nimport earthaccess\n\nBack to top  ## 2. NASA Earthdata Authentication ***\nNext, we authenticate using our Earthdata Login credentials. Authentication is not needed to search publicaly available collections in Earthdata, but is always needed to access data. We can use the login method from the earthaccess package. This will create an authenticated session when we provide a valid Earthdata Login username and password. The earthaccess package will search for credentials defined by environmental variables or within a .netrc file saved in the home directory. If credentials are not found, an interactive prompt will allow you to input credentials.\n\nThe persist=True argument ensures any discovered credentials are stored in a .netrc file, so the argument is not necessary (but it’s also harmless) for subsequent calls to earthaccess.login.\n\n\nauth = earthaccess.login(persist=True)\n\nBack to top  ## 3. Search for Data ***\nCollections on NASA Earthdata are discovered with the search_datasets function, which accepts an instrument filter as an easy way to get started. Each of the items in the list of collections returned has a “short-name”.\n\nresults = earthaccess.search_datasets(instrument=\"oci\")\n\n\nfor item in results:\n    summary = item.summary()\n    print(summary[\"short-name\"])\n\nNext, we use the search_data function to find granules within a collection. Let’s use the short_name for the PACE/OCI Level-2 quick-look product for apparent optical properties (although you can search for granules accross collections too).\n\nThe short name can also be found on  Eartdata Search, directly under the collection name, after clicking on the “i” button for a collection in any search result.\n\nThe count argument limits the number of granules returned and stored in the results list.\n\nresults = earthaccess.search_data(\n    short_name=\"PACE_OCI_L2_AOP_NRT\",\n    count=1,\n)\n\nWe can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the temporal parameter to request a date range and the bounding_box parameter to request granules that intersect with a bounding box. We can even provide a cloud_cover threshold to limit files that have a lower percetnage of cloud cover. We do not provide a count, so we’ll get all granules that satisfy the constraints.\n\ntspan = (\"2024-04-01\", \"2024-04-16\")\nbbox = (-76.75, 36.97, -75.74, 39.01)\nclouds = (0, 50)\n\nresults = earthaccess.search_data(\n    short_name=\"PACE_OCI_L2_AOP_NRT\",\n    temporal=tspan,\n    bounding_box=bbox, \n    cloud_cover=clouds,\n)\n\nDisplaying a single result shows a direct download link: try it! The link will download the granule to your local machine, which may or may not be what you want to do. Even if you are running the notebook on a remote host, this download link will open a new browser tab or window and offer to save a file to your local machine. If you are running the notebook locally, this may be of use. However, in the next section we’ll see how to download all the results with one command.\n\nresults[0]\n\nBack to top  ## 4. Download Data ***\nFirst, let’s understand what the alternative is to downloading granules. The earthaccess.open function accepts the list of results from earthaccess.search_data and returns a list of file-like objects, but no actual files are transferred.\n\npaths = earthaccess.open(results)\n\nThe file-like objects held in paths can each be read like a normal file. Here we load the first few bytes without any specialized reader.\n\nwith paths[0] as file:\n    line = file.readline().strip()\nline\n\nOf course that doesn’t mean anything (does it? 😉), because this is a binary file that needs a reader which understands the file format.\nThe earthaccess.open function is used when you want to directly read a bytes from a remote filesystem, but not download a whole file. When running code on a host with direct access to the NASA Earthdata Cloud, you don’t need to download the data and earthaccess.open is the way to go.\nNow, let’s look at the earthaccess.download function, which is used to copy files onto a filesystem local to the machine executing the code. For this function, provide the output of earthaccess.search_data along with a directory where earthaccess will store downloaded granules.\nEven if you only want to read a slice of the data, and downloading seems unncessary, if you use earthaccess.open while not running on a remote host with direct access to the NASA Earthdata Cloud, performance will be very poor. This is not a problem with “the cloud” or with earthaccess, it has to do with the data format and may soon be resolved.\nLet’s continue to downloading the list of granules!\n\npaths = earthaccess.download(results, \"L2_AOP\")\n\nThe paths list now contains paths to actual files on the local filesystem.\n\npaths\n\n\nAnywhere in any of these notebooks where\npaths = earthaccess.open(...)\nis used to read data directly from the NASA Earthdata Cloud, you need to substitute\npaths = earthaccess.download(..., local_path)\nbefore running the notebook on a local host or a remote host that does not have direct access to the NASA Earthdata Cloud.\n\n\n\nYou have completed the notebook on downloading and opening datasets. We now suggest starting the notebook on File Structure at Three Processing Levels."
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "",
    "text": "Jupyter notebook accompanying the manuscript:\nEchopype: A Python library for interoperable and scalable processing of ocean sonar data for biological information\nAuthors: Wu-Jung Lee, Emilio Mayorga, Landung Setiawan, Kavin Nguyen, Imran Majeed, Valentina Staneva"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#introduction",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#introduction",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Introduction",
    "text": "Introduction\n\nGoals\n\nIllustrate a common workflow for echosounder data conversion, calibration and use. This workflow leverages the standardization applied by echopype and the power, ease of use and familiarity of libraries in the scientific Python ecosystem.\nExtract and visualize data with relative ease using geospatial and temporal filters.\n\n\n\nDescription\nThis notebook uses EK60 echosounder data collected during the 2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey (‘Pacific Hake Survey’) to illustrate a common workflow for data conversion, calibration and analysis using echopype and core scientific Python software packages, particularly xarray, GeoPandas, pandas and NumPy.\nTwo days of cloud-hosted .raw data files are accessed by echopype directly from an Amazon Web Services (AWS) S3 “bucket” maintained by the NOAA NCEI Water-Column Sonar Data Archive. The total data used are 170 .raw files at approximately 25 MB each (1 Hz pinging rate from first light to dusk), corresponding to approximately 4.2 GB. With echopype, each file is converted to a standardized representation based on the SONAR-netCDF4 v1.0 convention and saved to the cloud-optimized Zarr format.\nData stored in the netCDF-based SONAR-netCDF4 convention can be conveniently and intuitively manipulated with xarray in combination with related scientific Python packages. Mean Volume Backscattering Strength (MVBS) is computed with echopype from each raw data file and exported to a netCDF file. Here, we define two geographical bounding boxes encompassing two ship tracks and use these to extract corresponding timestamp intervals from the GPS data, and then the corresponding MVBS data based on those intervals. Finally, these extracted MVBS subsets are plotted as track echograms.\n\n\nOutline\n\nEstablish AWS S3 file system connection and generate list of target EK60 .raw files\nProcess S3-hosted raw files with echopype: convert, calibrate and export to standardized files\nExtract and process GPS locations from the Platform group of converted raw files\nRead MVBS and plot track echograms for time periods corresponding to two ship tracks\n\n\n\nRunning the notebook\nThis notebook can be run with a conda environment created using the conda environment file https://github.com/OSOceanAcoustics/echopype-examples/blob/main/binder/environment.yml. The notebook creates two directories, if not already present: ./exports/hakesurvey_convertedzarr and ./exports/hakesurvey_calibratednc. netCDF and Zarr files will be exported there.\n\n\nNote\nWe encourage importing echopype as ep for consistency.\n\nfrom pathlib import Path\n\nimport fsspec\nimport numpy as np\nimport geopandas as gpd\nimport xarray as xr\n\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import box\nimport cartopy.crs as ccrs\nimport cartopy.io.img_tiles as cimgt\nfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n\nimport echopype as ep\nfrom echopype.qc import exist_reversed_time\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)\n\n\nfrom dask.distributed import Client\n\n\nclient = Client()\n\n\nclient\n\n\n     \n    \n        Client\n        Client-0457e919-0407-11ef-80d7-820f588673e5\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: /user/leewujung/proxy/8787/status\n\n\n\n\n\n\n        \n            \n                Launch dashboard in JupyterLab\n            \n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        5abba2b3\n        \n\n\n\nDashboard: /user/leewujung/proxy/8787/status\nWorkers: 4\n\n\nTotal threads: 8\nTotal memory: 31.34 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-b7dda29b-c5bc-4ea7-ab66-7890b5e5cc79\n            \n\n\n\nComm: tcp://127.0.0.1:38903\nWorkers: 4\n\n\nDashboard: /user/leewujung/proxy/8787/status\nTotal threads: 8\n\n\nStarted: Just now\nTotal memory: 31.34 GiB\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:43205\nTotal threads: 2\n\n\nDashboard: /user/leewujung/proxy/43023/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:40977\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-8hk9umex\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:33021\nTotal threads: 2\n\n\nDashboard: /user/leewujung/proxy/33901/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:43227\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-rtm3hewa\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:36503\nTotal threads: 2\n\n\nDashboard: /user/leewujung/proxy/34185/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:42299\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-sq1_hzly\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:32945\nTotal threads: 2\n\n\nDashboard: /user/leewujung/proxy/38863/status\nMemory: 7.84 GiB\n\n\nNanny: tcp://127.0.0.1:38595\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-ewwsz9bc"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#establish-aws-s3-file-system-connection-and-generate-list-of-target-ek60-.raw-files",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#establish-aws-s3-file-system-connection-and-generate-list-of-target-ek60-.raw-files",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Establish AWS S3 file system connection and generate list of target EK60 .raw files",
    "text": "Establish AWS S3 file system connection and generate list of target EK60 .raw files\nAccess and inspect the publicly accessible NCEI WCSD S3 bucket on the AWS cloud as if it were a local file system. This will be done through the Python fsspec file system and bytes storage interface. We will use fsspec.filesystem.glob (fs.glob) to generate a list of all EK60 .raw data files in the bucket, then filter on file names for target dates of interest.\nThe directory path on the ncei-wcsd-archive S3 bucket is s3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/. All .raw files from the 2017 Hake survey cruise are found here.\n\nfs = fsspec.filesystem('s3', anon=True)\n\nbucket = \"ncei-wcsd-archive\"\nrawdirpath = \"data/raw/Bell_M._Shimada/SH1707/EK60\"\n\n\ns3rawfiles = fs.glob(f\"{bucket}/{rawdirpath}/*.raw\")\n\n# print out the last two S3 raw file paths in the list\ns3rawfiles[-2:]\n\n['ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170913-T180733.raw',\n 'ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Winter2017-D20170615-T002629.raw']\n\n\nGenerate list of target EK60 .raw files from AWS S3 bucket based on dates. The dates are found in the middle string token (e.g., “D20170913”). Select files from 2 days, 2017-07-28 and 2017-07-29.\n\ns3rawfiles = [\n    s3path for s3path in s3rawfiles \n    if any([f\"D2017{datestr}\" in s3path for datestr in ['0728', '0729']])\n]\n\nprint(f\"There are {len(s3rawfiles)} target raw files available\")\n\nThere are 170 target raw files available"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#process-s3-hosted-raw-files-with-echopype-convert-calibrate-and-export-to-standardized-files",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#process-s3-hosted-raw-files-with-echopype-convert-calibrate-and-export-to-standardized-files",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Process S3-hosted raw files with echopype: convert, calibrate and export to standardized files",
    "text": "Process S3-hosted raw files with echopype: convert, calibrate and export to standardized files\nLoop through all the selected raw files on S3 and convert, calibrate and generate Mean Volume Backscattering Strength (MVBS). Save the raw converted and MVBS data to local files, as zarr and netCDF, respectively.\n\ndef populate_metadata(ed, raw_fname):\n    \"\"\"\n    Manually populate into the \"ed\" EchoData object \n    additional metadata about the dataset and the platform\n    \"\"\"\n    \n    # -- SONAR-netCDF4 Top-level Group attributes\n    survey_name = (\n        \"2017 Joint U.S.-Canada Integrated Ecosystem and \"\n        \"Pacific Hake Acoustic Trawl Survey ('Pacific Hake Survey')\"\n    )\n    ed['Top-level'].attrs['title'] = f\"{survey_name}, file {raw_fname}\"\n    ed['Top-level'].attrs['summary'] = (\n        f\"EK60 raw file {raw_fname} from the {survey_name}, converted to a SONAR-netCDF4 file using echopype.\"\n        \"Information about the survey program is available at \"\n        \"https://www.fisheries.noaa.gov/west-coast/science-data/\"\n        \"joint-us-canada-integrated-ecosystem-and-pacific-hake-acoustic-trawl-survey\"\n    )\n\n    # -- SONAR-netCDF4 Platform Group attributes\n    # Per SONAR-netCDF4, for platform_type see https://vocab.ices.dk/?ref=311\n    ed['Platform'].attrs['platform_type'] = \"Research vessel\"\n    ed['Platform'].attrs['platform_name'] = \"Bell M. Shimada\"  # A NOAA ship\n    ed['Platform'].attrs['platform_code_ICES'] = \"315\"\n\nCreate the directories where the exported files will be saved, if these directories don’t already exist.\n\nbase_dpath = Path('./exports/notebook2')\nbase_dpath.mkdir(exist_ok=True, parents=True)\n\nconverted_dpath = Path(base_dpath / 'hakesurvey_convertedzarr')\nconverted_dpath.mkdir(exist_ok=True)\ncalibrated_dpath = (base_dpath / 'hakesurvey_calibratednc')\ncalibrated_dpath.mkdir(exist_ok=True)\n\n\nechopype processing\nEchoData is an echopype object for conveniently handling raw converted data from either raw instrument files or previously converted and standardized raw netCDF4 and Zarr files. It is essentially a container for multiple xarray.Dataset objects, each corresponds to one of the netCDF4 groups specified in the SONAR-netCDF4 convention – the convention followed by echopype. The EchoData object can be used to conveniently accesse and explore the echosounder raw data and for calibration and other processing.\nThe cell below contains the main echopype workflow steps. For each raw file: - Access file directly from S3 via ep.open_raw to create a converted EchoData object in memory - Add global and platform attributes to EchoData object - Export to a local Zarr dataset (a collection of files encapsulated in a directory) - Generate calibrated Sv and then MVBS from the raw data in the EchoData object - Export MVBS to a local netcdf file\nNote: Depending on your internet speed, this cell may take some time to run (potentially 20-30 mins).\n\n# %%time\n\n# for s3rawfpath in s3rawfiles:\n#     raw_fpath = Path(s3rawfpath)\n#     try:\n#         # Access file directly from S3 to create a converted EchoData object in memory\n#         ed = ep.open_raw(\n#             f\"s3://{s3rawfpath}\",\n#             sonar_model='EK60',\n#             storage_options={'anon': True}\n#         )\n#         # Manually populate additional metadata about the dataset and the platform\n#         populate_metadata(ed, raw_fpath.name)\n\n#         # Save to converted Zarr format\n#         ed.to_zarr(save_path=converted_dpath, overwrite=True)\n\n#         # Use the EchoData object \"ed\" to generate calibrated and\n#         # computed MVBS files that will be saved to netcdf\n#         ds_Sv = ep.calibrate.compute_Sv(ed)\n#         ds_MVBS = ep.commongrid.compute_MVBS(\n#             ds_Sv,\n#             range_meter_bin=5,  # in meters\n#             ping_time_bin='20s'  # in seconds\n#         )\n#         ds_MVBS.to_netcdf(calibrated_dpath / f\"MVBS_{raw_fpath.stem}.nc\")\n#     except Exception as e:\n#         print(f\"Failed to process raw file {raw_fpath.name}: {e}\")\n\n\n\nTest for time reversals\nSmall time reversals are found in EK60 datasets, including the 2017 Pacific Hake survey, where the ping_time (or GPS time1) value may be lower (older) than the preceding ping_time by a second. Such discontinuities can interfere with concatenating individual raw files to produce an aggregated dataset. The capability to identify and address these reversals is in the echopype.qc subpackage.\n\n%%time\nfor datapath in converted_dpath.glob('*'):\n    ed = ep.open_converted(datapath, chunks={})\n    # Test for a negative ping_time increment in sequential timestamps, in the Sonar/Beam_group1 group\n    if exist_reversed_time(ds=ed['Sonar/Beam_group1'], time_name=\"ping_time\"):\n        print(f\"Reversed time in {datapath}\")\n\nCPU times: user 19.7 s, sys: 6.21 s, total: 25.9 s\nWall time: 2min 9s\n\n\nThere are no time reversals in this two-day dataset, fortunately.\n\n\nExamine the EchoData object for one of the data files\nechopype provides a user-friendly, convenient representation of an EchoData object that leverages the user-friendly xarray Dataset HTML representation. Since an EchoData object is effectively a container for multiple xarray.Dataset objects corresponding to netCDF4 groups, the notebook “print out” provides a summary view of all the groups and interactive access to summaries of each group.\nHere, ed is the last object opened in the time reversal test, in the preceding cell.\n\ned = ep.open_converted(list(converted_dpath.glob('*'))[0], chunks={})\n\n\ned\n\n\n    \n        EchoData: standardized raw data from /home/jovyan/shared/echopype-examples/notebooks/exports/notebook2/hakesurvey_convertedzarr/Summer2017-D20170729-T235813.zarr\n    \n    \n        \n            Top-level: contains metadata about the SONAR-netCDF4 file format.\n            \n            \n                \n                    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  ()\nData variables:\n    *empty*\nAttributes:\n    conventions:                 CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3\n    date_created:                2017-07-29T23:58:13Z\n    keywords:                    EK60\n    processing_level:            Level 1A\n    processing_level_url:        https://echopype.readthedocs.io/en/stable/pr...\n    sonar_convention_authority:  ICES\n    sonar_convention_name:       SONAR-netCDF4\n    sonar_convention_version:    1.0\n    summary:                     EK60 raw file Summer2017-D20170729-T235813.r...\n    title:                       2017 Joint U.S.-Canada Integrated Ecosystem ...xarray.DatasetDimensions:Coordinates: (0)Data variables: (0)Indexes: (0)Attributes: (10)conventions :CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3date_created :2017-07-29T23:58:13Zkeywords :EK60processing_level :Level 1Aprocessing_level_url :https://echopype.readthedocs.io/en/stable/processing-levels.htmlsonar_convention_authority :ICESsonar_convention_name :SONAR-netCDF4sonar_convention_version :1.0summary :EK60 raw file Summer2017-D20170729-T235813.raw from the 2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey ('Pacific Hake Survey'), converted to a SONAR-netCDF4 file using echopype.Information about the survey program is available at https://www.fisheries.noaa.gov/west-coast/science-data/joint-us-canada-integrated-ecosystem-and-pacific-hake-acoustic-trawl-surveytitle :2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey ('Pacific Hake Survey'), file Summer2017-D20170729-T235813.raw\n                \n            \n        \n        \n                    Environment: contains information relevant to acoustic propagation through water.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                 (channel: 3, time1: 534)\nCoordinates:\n  * channel                 (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18...\n  * time1                   (time1) datetime64[ns] 2017-07-29T23:58:13.128697...\nData variables:\n    absorption_indicative   (channel, time1) float64 dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;\n    frequency_nominal       (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    sound_speed_indicative  (channel, time1) float64 dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;xarray.DatasetDimensions:channel: 3time1: 534Coordinates: (2)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')time1(time1)datetime64[ns]2017-07-29T23:58:13.128697856 .....axis :Tcomment :Time coordinate corresponding to environmental variables.long_name :Timestamps for NMEA position datagramsstandard_name :timearray(['2017-07-29T23:58:13.128697856', '2017-07-29T23:58:15.371826176',\n       '2017-07-29T23:58:17.597954048', ..., '2017-07-30T00:17:52.050916864',\n       '2017-07-30T00:17:54.266042880', '2017-07-30T00:17:56.492170240'],\n      dtype='datetime64[ns]')Data variables: (3)absorption_indicative(channel, time1)float64dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;long_name :Indicative acoustic absorptionunits :dB/mvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.52 kiB\n12.52 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\nfrequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nsound_speed_indicative(channel, time1)float64dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;long_name :Indicative sound speedstandard_name :speed_of_sound_in_sea_waterunits :m/svalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.52 kiB\n12.52 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\nIndexes: (2)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-29 23:58:13.128697856',\n               '2017-07-29 23:58:15.371826176',\n               '2017-07-29 23:58:17.597954048',\n               '2017-07-29 23:58:19.813082112',\n                  '2017-07-29 23:58:22.038208',\n               '2017-07-29 23:58:24.254332928',\n               '2017-07-29 23:58:26.470460928',\n               '2017-07-29 23:58:28.696588800',\n               '2017-07-29 23:58:30.912715776',\n               '2017-07-29 23:58:33.138844160',\n               ...\n               '2017-07-30 00:17:36.490025984',\n               '2017-07-30 00:17:38.716151808',\n               '2017-07-30 00:17:40.951281152',\n               '2017-07-30 00:17:43.178409984',\n                  '2017-07-30 00:17:45.393536',\n               '2017-07-30 00:17:47.619662848',\n               '2017-07-30 00:17:49.835790848',\n               '2017-07-30 00:17:52.050916864',\n               '2017-07-30 00:17:54.266042880',\n               '2017-07-30 00:17:56.492170240'],\n              dtype='datetime64[ns]', name='time1', length=534, freq=None))Attributes: (0)\n                        \n                    \n                \n                    Platform: contains information about the platform on which the sonar is installed.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:              (channel: 3, time1: 1676, time2: 534)\nCoordinates:\n  * channel              (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18-11...\n  * time1                (time1) datetime64[ns] 2017-07-29T23:58:13.511395840...\n  * time2                (time2) datetime64[ns] 2017-07-29T23:58:13.128697856...\nData variables: (12/20)\n    MRU_offset_x         float64 ...\n    MRU_offset_y         float64 ...\n    MRU_offset_z         float64 ...\n    MRU_rotation_x       float64 ...\n    MRU_rotation_y       float64 ...\n    MRU_rotation_z       float64 ...\n    ...                   ...\n    sentence_type        (time1) &lt;U3 dask.array&lt;chunksize=(1676,), meta=np.ndarray&gt;\n    transducer_offset_x  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transducer_offset_y  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transducer_offset_z  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    vertical_offset      (time2) float64 dask.array&lt;chunksize=(534,), meta=np.ndarray&gt;\n    water_level          float64 ...\nAttributes:\n    platform_code_ICES:  315\n    platform_name:       Bell M. Shimada\n    platform_type:       Research vesselxarray.DatasetDimensions:channel: 3time1: 1676time2: 534Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')time1(time1)datetime64[ns]2017-07-29T23:58:13.511395840 .....axis :Tcomment :Time coordinate corresponding to NMEA position data.long_name :Timestamps for NMEA datagramsstandard_name :timearray(['2017-07-29T23:58:13.511395840', '2017-07-29T23:58:13.669727232',\n       '2017-07-29T23:58:13.948889088', ..., '2017-07-30T00:17:57.274190848',\n       '2017-07-30T00:17:59.223481856', '2017-07-30T00:17:59.381813248'],\n      dtype='datetime64[ns]')time2(time2)datetime64[ns]2017-07-29T23:58:13.128697856 .....axis :Tcomment :Time coordinate corresponding to platform motion and orientation data.long_name :Timestamps for platform motion and orientation datastandard_name :timearray(['2017-07-29T23:58:13.128697856', '2017-07-29T23:58:15.371826176',\n       '2017-07-29T23:58:17.597954048', ..., '2017-07-30T00:17:52.050916864',\n       '2017-07-30T00:17:54.266042880', '2017-07-30T00:17:56.492170240'],\n      dtype='datetime64[ns]')Data variables: (20)MRU_offset_x()float64...long_name :Distance along the x-axis from the platform coordinate system origin to the motion reference unit sensor originunits :m[1 values with dtype=float64]MRU_offset_y()float64...long_name :Distance along the y-axis from the platform coordinate system origin to the motion reference unit sensor originunits :m[1 values with dtype=float64]MRU_offset_z()float64...long_name :Distance along the z-axis from the platform coordinate system origin to the motion reference unit sensor originunits :m[1 values with dtype=float64]MRU_rotation_x()float64...long_name :Extrinsic rotation about the x-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)[1 values with dtype=float64]MRU_rotation_y()float64...long_name :Extrinsic rotation about the y-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)[1 values with dtype=float64]MRU_rotation_z()float64...long_name :Extrinsic rotation about the z-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)[1 values with dtype=float64]frequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nlatitude(time1)float64dask.array&lt;chunksize=(1676,), meta=np.ndarray&gt;long_name :Platform latitudestandard_name :latitudeunits :degrees_northvalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.09 kiB\n13.09 kiB\n\n\nShape\n(1676,)\n(1676,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1676 1\n\n\n\n\nlongitude(time1)float64dask.array&lt;chunksize=(1676,), meta=np.ndarray&gt;long_name :Platform longitudestandard_name :longitudeunits :degrees_eastvalid_range :(-180.0, 180.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.09 kiB\n13.09 kiB\n\n\nShape\n(1676,)\n(1676,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         1676 1\n\n\n\n\npitch(time2)float64dask.array&lt;chunksize=(534,), meta=np.ndarray&gt;long_name :Platform pitchstandard_name :platform_pitch_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.17 kiB\n4.17 kiB\n\n\nShape\n(534,)\n(534,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 1\n\n\n\n\nposition_offset_x()float64...long_name :Distance along the x-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :m[1 values with dtype=float64]position_offset_y()float64...long_name :Distance along the y-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :m[1 values with dtype=float64]position_offset_z()float64...long_name :Distance along the z-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :m[1 values with dtype=float64]roll(time2)float64dask.array&lt;chunksize=(534,), meta=np.ndarray&gt;long_name :Platform rollstandard_name :platform_roll_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.17 kiB\n4.17 kiB\n\n\nShape\n(534,)\n(534,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 1\n\n\n\n\ntransducer_offset_x(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :x-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_y(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :y-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_z(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :z-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nvertical_offset(time2)float64dask.array&lt;chunksize=(534,), meta=np.ndarray&gt;long_name :Platform vertical offset from nominal water levelunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.17 kiB\n4.17 kiB\n\n\nShape\n(534,)\n(534,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 1\n\n\n\n\nIndexes: (1)beam_groupPandasIndexPandasIndex(Index(['Beam_group1'], dtype='object', name='beam_group'))Attributes: (6)sonar_manufacturer :Simradsonar_model :EK60sonar_serial_number :sonar_software_name :ER60sonar_software_version :2.4.3sonar_type :echosounder\n                        \n                    \n                \n                    Beam_group1: contains backscatter power (uncalibrated) and other beam or channel-specific data, including split-beam angle data when they exist.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                        (channel: 3, ping_time: 534,\n                                    range_sample: 3957)\nCoordinates:\n  * channel                        (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1...\n  * ping_time                      (ping_time) datetime64[ns] 2017-07-29T23:5...\n  * range_sample                   (range_sample) int64 0 1 2 ... 3954 3955 3956\nData variables: (12/29)\n    angle_alongship                (channel, ping_time, range_sample) float32 dask.array&lt;chunksize=(3, 534, 3957), meta=np.ndarray&gt;\n    angle_athwartship              (channel, ping_time, range_sample) float32 dask.array&lt;chunksize=(3, 534, 3957), meta=np.ndarray&gt;\n    angle_offset_alongship         (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    angle_offset_athwartship       (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    angle_sensitivity_alongship    (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    angle_sensitivity_athwartship  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    ...                             ...\n    transmit_bandwidth             (channel, ping_time) float64 dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;\n    transmit_duration_nominal      (channel, ping_time) float64 dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;\n    transmit_frequency_start       (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transmit_frequency_stop        (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transmit_power                 (channel, ping_time) float64 dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;\n    transmit_type                  &lt;U2 ...\nAttributes:\n    beam_mode:              vertical\n    conversion_equation_t:  type_3xarray.DatasetDimensions:channel: 3ping_time: 534range_sample: 3957Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')ping_time(ping_time)datetime64[ns]2017-07-29T23:58:13.128697856 .....axis :Tlong_name :Timestamp of each pingstandard_name :timearray(['2017-07-29T23:58:13.128697856', '2017-07-29T23:58:15.371826176',\n       '2017-07-29T23:58:17.597954048', ..., '2017-07-30T00:17:52.050916864',\n       '2017-07-30T00:17:54.266042880', '2017-07-30T00:17:56.492170240'],\n      dtype='datetime64[ns]')range_sample(range_sample)int640 1 2 3 4 ... 3953 3954 3955 3956long_name :Along-range sample number, base 0array([   0,    1,    2, ..., 3954, 3955, 3956])Data variables: (29)angle_alongship(channel, ping_time, range_sample)float32dask.array&lt;chunksize=(3, 534, 3957), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :electrical alongship angle\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24.18 MiB\n24.18 MiB\n\n\nShape\n(3, 534, 3957)\n(3, 534, 3957)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         3957 534 3\n\n\n\n\nangle_athwartship(channel, ping_time, range_sample)float32dask.array&lt;chunksize=(3, 534, 3957), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :electrical athwartship angle\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24.18 MiB\n24.18 MiB\n\n\nShape\n(3, 534, 3957)\n(3, 534, 3957)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         3957 534 3\n\n\n\n\nangle_offset_alongship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :electrical alongship angle offset of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nangle_offset_athwartship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :electrical athwartship angle offset of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nangle_sensitivity_alongship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :alongship angle sensitivity of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nangle_sensitivity_athwartship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :athwartship angle sensitivity of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbackscatter_r(channel, ping_time, range_sample)float32dask.array&lt;chunksize=(3, 534, 3957), meta=np.ndarray&gt;long_name :Raw backscatter measurements (real part)units :dB\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24.18 MiB\n24.18 MiB\n\n\nShape\n(3, 534, 3957)\n(3, 534, 3957)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         3957 534 3\n\n\n\n\nbeam_direction_x(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :x-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeam_direction_y(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :y-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeam_direction_z(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :z-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeam_stabilisation()int8...flag_meanings :['not stabilised', 'stabilised']flag_values :[0, 1]long_name :Beam stabilisation applied (or not)[1 values with dtype=int8]beam_type(channel)int64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :type of transducer (0-single, 1-split)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeamwidth_twoway_alongship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_minor and beamwidth_transmit_minor), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along alongship axis of beamunits :arc_degreevalid_range :[0.0, 360.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeamwidth_twoway_athwartship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_major and beamwidth_transmit_major), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along athwartship axis of beamunits :arc_degreevalid_range :[0.0, 360.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nchannel_mode(channel, ping_time)int8dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;comment :From transmit_mode in the EK60 datagramflag_meanings :['Unknown', 'Active', 'Passive', 'Test']flag_values :[-1, 0, 1, 2]long_name :Transceiver mode\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.56 kiB\n1.56 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\ndata_type(channel, ping_time)float32dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;flag_meanings :['power only', 'angle only', 'power and angle']flag_values :[1, 2, 3]long_name :recorded data type (1=power only, 2=angle only, 3=power and angle)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n6.26 kiB\n6.26 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\nequivalent_beam_angle(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Equivalent beam angleunits :srvalid_range :[0.0, 12.566370614359172]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nfrequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ngain_correction(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Gain correctionunits :dB\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nnon_quantitative_processing()int16...flag_meanings :['None']flag_values :[0]long_name :Presence or not of non-quantitative processing applied to the backscattering data (sonar specific)[1 values with dtype=int16]sample_interval(channel, ping_time)float64dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;long_name :Interval between recorded raw data samplesunits :svalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.52 kiB\n12.52 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\nsample_time_offset(channel, ping_time)float64dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;long_name :Time offset that is subtracted from the timestamp of each sampleunits :s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.52 kiB\n12.52 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\ntransmit_bandwidth(channel, ping_time)float64dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;long_name :Nominal bandwidth of transmitted pulseunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.52 kiB\n12.52 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\ntransmit_duration_nominal(channel, ping_time)float64dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;long_name :Nominal bandwidth of transmitted pulseunits :svalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.52 kiB\n12.52 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\ntransmit_frequency_start(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Start frequency in transmitted pulsestandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransmit_frequency_stop(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Stop frequency in transmitted pulsestandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransmit_power(channel, ping_time)float64dask.array&lt;chunksize=(3, 534), meta=np.ndarray&gt;long_name :Nominal transmit powerunits :Wvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.52 kiB\n12.52 kiB\n\n\nShape\n(3, 534)\n(3, 534)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         534 3\n\n\n\n\ntransmit_type()&lt;U2...flag_meanings :['Continuous Wave – a pulse nominally of one frequency']flag_values :['CW']long_name :Type of transmitted pulse[1 values with dtype=&lt;U2]Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-29 23:58:13.128697856',\n               '2017-07-29 23:58:15.371826176',\n               '2017-07-29 23:58:17.597954048',\n               '2017-07-29 23:58:19.813082112',\n                  '2017-07-29 23:58:22.038208',\n               '2017-07-29 23:58:24.254332928',\n               '2017-07-29 23:58:26.470460928',\n               '2017-07-29 23:58:28.696588800',\n               '2017-07-29 23:58:30.912715776',\n               '2017-07-29 23:58:33.138844160',\n               ...\n               '2017-07-30 00:17:36.490025984',\n               '2017-07-30 00:17:38.716151808',\n               '2017-07-30 00:17:40.951281152',\n               '2017-07-30 00:17:43.178409984',\n                  '2017-07-30 00:17:45.393536',\n               '2017-07-30 00:17:47.619662848',\n               '2017-07-30 00:17:49.835790848',\n               '2017-07-30 00:17:52.050916864',\n               '2017-07-30 00:17:54.266042880',\n               '2017-07-30 00:17:56.492170240'],\n              dtype='datetime64[ns]', name='ping_time', length=534, freq=None))range_samplePandasIndexPandasIndex(Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n            ...\n            3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956],\n           dtype='int64', name='range_sample', length=3957))Attributes: (2)beam_mode :verticalconversion_equation_t :type_3\n                        \n                    \n                \n                    Vendor_specific: contains vendor-specific information about the sonar and the data.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (channel: 3, pulse_length_bin: 5)\nCoordinates:\n  * channel            (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18-11' ...\n  * pulse_length_bin   (pulse_length_bin) int64 0 1 2 3 4\nData variables:\n    frequency_nominal  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    gain_correction    (channel, pulse_length_bin) float64 dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n    pulse_length       (channel, pulse_length_bin) float64 dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n    sa_correction      (channel, pulse_length_bin) float64 dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;xarray.DatasetDimensions:channel: 3pulse_length_bin: 5Coordinates: (2)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')pulse_length_bin(pulse_length_bin)int640 1 2 3 4array([0, 1, 2, 3, 4])Data variables: (4)frequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ngain_correction(channel, pulse_length_bin)float64dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n120 B\n120 B\n\n\nShape\n(3, 5)\n(3, 5)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         5 3\n\n\n\n\npulse_length(channel, pulse_length_bin)float64dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n120 B\n120 B\n\n\nShape\n(3, 5)\n(3, 5)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         5 3\n\n\n\n\nsa_correction(channel, pulse_length_bin)float64dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n120 B\n120 B\n\n\nShape\n(3, 5)\n(3, 5)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         5 3\n\n\n\n\nIndexes: (2)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))pulse_length_binPandasIndexPandasIndex(Int64Index([0, 1, 2, 3, 4], dtype='int64', name='pulse_length_bin'))Attributes: (0)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#extract-and-process-gps-locations-from-the-platform-group-of-converted-raw-files",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#extract-and-process-gps-locations-from-the-platform-group-of-converted-raw-files",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Extract and process GPS locations from the Platform group of converted raw files",
    "text": "Extract and process GPS locations from the Platform group of converted raw files\nUse xarray.open_mfdataset to open the Platform group from all the converted raw netcdf files as a single concatenated (combined) xarray dataset. Then extract GPS time1 (time stamp), latitude and longitude from this group and transform that data into a GeoPandas GeoDataFrame containing point-geometry objects that are readily manipulated via geospatial operations. A GeoDataFrame adds geospatial capabilities to a Pandas DataFrame.\nDue to the presence of multiple time coordinates in this group, care must be taken in defining how the concatenation (combine) operation is to be performed. This is captured in the arguments passed to open_mfdataset.\n\n%%time\nplatform_ds = xr.open_mfdataset(\n    str(converted_dpath / '*.zarr'), group='Platform', \n    engine='zarr',\n    data_vars='minimal', coords='minimal',\n    combine='nested', chunks={}\n)\n\nCPU times: user 1min 52s, sys: 12.3 s, total: 2min 5s\nWall time: 3min 34s\n\n\n\nplatform_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:              (channel: 3, time1: 244846, time2: 88959)\nCoordinates:\n  * channel              (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18-11...\n  * time1                (time1) datetime64[ns] 2017-07-28T00:05:36.103314944...\n  * time2                (time2) datetime64[ns] 2017-07-28T00:05:34.897271808...\nData variables: (12/20)\n    MRU_offset_x         float64 nan\n    MRU_offset_y         float64 nan\n    MRU_offset_z         float64 nan\n    MRU_rotation_x       float64 nan\n    MRU_rotation_y       float64 nan\n    MRU_rotation_z       float64 nan\n    ...                   ...\n    sentence_type        (time1) object dask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;\n    transducer_offset_x  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transducer_offset_y  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transducer_offset_z  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    vertical_offset      (time2) float64 dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;\n    water_level          float64 9.15\nAttributes:\n    platform_code_ICES:  315\n    platform_name:       Bell M. Shimada\n    platform_type:       Research vesselxarray.DatasetDimensions:channel: 3time1: 244846time2: 88959Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')time1(time1)datetime64[ns]2017-07-28T00:05:36.103314944 .....axis :Tcomment :Time coordinate corresponding to NMEA position data.long_name :Timestamps for NMEA datagramsstandard_name :timearray(['2017-07-28T00:05:36.103314944', '2017-07-28T00:05:37.511096832',\n       '2017-07-28T00:05:37.669428224', ..., '2017-07-30T00:17:57.274190848',\n       '2017-07-30T00:17:59.223481856', '2017-07-30T00:17:59.381813248'],\n      dtype='datetime64[ns]')time2(time2)datetime64[ns]2017-07-28T00:05:34.897271808 .....axis :Tcomment :Time coordinate corresponding to platform motion and orientation data.long_name :Timestamps for platform motion and orientation datastandard_name :timearray(['2017-07-28T00:05:34.897271808', '2017-07-28T00:05:37.162400768',\n       '2017-07-28T00:05:38.404471808', ..., '2017-07-30T00:17:52.050916864',\n       '2017-07-30T00:17:54.266042880', '2017-07-30T00:17:56.492170240'],\n      dtype='datetime64[ns]')Data variables: (20)MRU_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_rotation_x()float64nanlong_name :Extrinsic rotation about the x-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_y()float64nanlong_name :Extrinsic rotation about the y-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_z()float64nanlong_name :Extrinsic rotation about the z-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)frequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nlatitude(time1)float64dask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;long_name :Platform latitudestandard_name :latitudeunits :degrees_northvalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.87 MiB\n1.87 MiB\n\n\nShape\n(244846,)\n(244846,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         244846 1\n\n\n\n\nlongitude(time1)float64dask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;long_name :Platform longitudestandard_name :longitudeunits :degrees_eastvalid_range :(-180.0, 180.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.87 MiB\n1.87 MiB\n\n\nShape\n(244846,)\n(244846,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         244846 1\n\n\n\n\npitch(time2)float64dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;long_name :Platform pitchstandard_name :platform_pitch_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n694.99 kiB\n694.99 kiB\n\n\nShape\n(88959,)\n(88959,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         88959 1\n\n\n\n\nposition_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)roll(time2)float64dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;long_name :Platform rollstandard_name :platform_roll_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n694.99 kiB\n694.99 kiB\n\n\nShape\n(88959,)\n(88959,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         88959 1\n\n\n\n\nsentence_type(time1)objectdask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;long_name :NMEA sentence type\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.87 MiB\n1.87 MiB\n\n\nShape\n(244846,)\n(244846,)\n\n\nDask graph\n1 chunks in 1859 graph layers\n\n\nData type\nobject numpy.ndarray\n\n\n\n\n         244846 1\n\n\n\n\ntransducer_offset_x(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :x-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_y(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :y-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_z(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :z-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nvertical_offset(time2)float64dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;long_name :Platform vertical offset from nominal water levelunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n694.99 kiB\n694.99 kiB\n\n\nShape\n(88959,)\n(88959,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         88959 1\n\n\n\n\nwater_level()float649.15long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(9.14999962)Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:36.103314944',\n               '2017-07-28 00:05:37.511096832',\n               '2017-07-28 00:05:37.669428224',\n               '2017-07-28 00:05:37.948589056',\n               '2017-07-28 00:05:39.000582144',\n               '2017-07-28 00:05:39.158913024',\n               '2017-07-28 00:05:40.353559040',\n               '2017-07-28 00:05:41.152783872',\n               '2017-07-28 00:05:41.311114752',\n               '2017-07-28 00:05:42.003654144',\n               ...\n               '2017-07-30 00:17:52.538341888',\n               '2017-07-30 00:17:53.276961792',\n               '2017-07-30 00:17:53.926177792',\n               '2017-07-30 00:17:54.084509184',\n               '2017-07-30 00:17:55.277079040',\n               '2017-07-30 00:17:55.924213248',\n               '2017-07-30 00:17:56.082544128',\n               '2017-07-30 00:17:57.274190848',\n               '2017-07-30 00:17:59.223481856',\n               '2017-07-30 00:17:59.381813248'],\n              dtype='datetime64[ns]', name='time1', length=244846, freq=None))time2PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:34.897271808',\n               '2017-07-28 00:05:37.162400768',\n               '2017-07-28 00:05:38.404471808',\n               '2017-07-28 00:05:40.670601216',\n               '2017-07-28 00:05:42.906728960',\n               '2017-07-28 00:05:45.152857088',\n               '2017-07-28 00:05:47.387984896',\n               '2017-07-28 00:05:49.643113984',\n               '2017-07-28 00:05:51.899244032',\n               '2017-07-28 00:05:54.145372160',\n               ...\n               '2017-07-30 00:17:36.490025984',\n               '2017-07-30 00:17:38.716151808',\n               '2017-07-30 00:17:40.951281152',\n               '2017-07-30 00:17:43.178409984',\n                  '2017-07-30 00:17:45.393536',\n               '2017-07-30 00:17:47.619662848',\n               '2017-07-30 00:17:49.835790848',\n               '2017-07-30 00:17:52.050916864',\n               '2017-07-30 00:17:54.266042880',\n               '2017-07-30 00:17:56.492170240'],\n              dtype='datetime64[ns]', name='time2', length=88959, freq=None))Attributes: (3)platform_code_ICES :315platform_name :Bell M. Shimadaplatform_type :Research vessel\n\n\nWe can use time1 (the timestamps for NMEA datagrams, or GPS timestamps) to examine the exact timestamp interval spanned by the combined dataset.\n\nprint(f\"{platform_ds.time1.values.min()}, {platform_ds.time1.values.max()}\")\n\n2017-07-28T00:05:36.103314944, 2017-07-30T00:17:59.381813248\n\n\nTo create the GeoPandas GeoDataFrame, first transform the latitude and longitude arrays to a single Pandas DataFrame that retains the time1 coordinate as a common index. This is done by using the DataFrame to_dataframe method together with a Pandas join operation. Then, a point GeoDataFrame is created from this DataFrame.\n\ngps_df = platform_ds.latitude.to_dataframe().join(platform_ds.longitude.to_dataframe())\n\ngps_df.head(3)\n\n/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 637.80 MiB.\nThis may cause some slowdown.\nConsider scattering data ahead of time and using futures.\n  warnings.warn(\n/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 637.80 MiB.\nThis may cause some slowdown.\nConsider scattering data ahead of time and using futures.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nlatitude\nlongitude\n\n\ntime1\n\n\n\n\n\n\n2017-07-28 00:05:36.103314944\n43.533072\n-124.683998\n\n\n2017-07-28 00:05:37.511096832\n43.533080\n-124.684005\n\n\n2017-07-28 00:05:37.669428224\n43.533167\n-124.684000\n\n\n\n\n\n\n\n\ngps_gdf = gpd.GeoDataFrame(\n    gps_df,\n    geometry=gpd.points_from_xy(gps_df['longitude'], gps_df['latitude']), \n    crs=\"epsg:4326\"\n)\n\nA simple, easily generated map plot of the point GeoDataFrame\n\ngps_gdf.plot(markersize=2)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#read-mvbs-and-plot-track-echograms-for-time-periods-corresponding-to-two-ship-tracks",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#read-mvbs-and-plot-track-echograms-for-time-periods-corresponding-to-two-ship-tracks",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Read MVBS and plot track echograms for time periods corresponding to two ship tracks",
    "text": "Read MVBS and plot track echograms for time periods corresponding to two ship tracks\n\nRead MVBS as a concatenated dataset\nUse xarray.open_mfdataset again to read and concatenate (combine) data files into a single xarray Dataset. This time, we’re reading the MVBS netCDF files.\n\n%%time\nMVBS_ds = xr.open_mfdataset(\n    str(calibrated_dpath / 'MVBS_*.nc'), \n    data_vars='minimal', coords='minimal',\n    combine='by_coords'\n)\n\nCPU times: user 6.77 s, sys: 601 ms, total: 7.38 s\nWall time: 20.3 s\n\n\n\nMVBS_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (channel: 3, ping_time: 8819, echo_range: 150)\nCoordinates:\n  * channel            (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18-11' ...\n  * ping_time          (ping_time) datetime64[ns] 2017-07-28T00:05:20 ... 201...\n  * echo_range         (echo_range) float64 0.0 5.0 10.0 ... 735.0 740.0 745.0\nData variables:\n    Sv                 (channel, ping_time, echo_range) float64 dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;\n    frequency_nominal  (channel) float64 dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.1\n    processing_time:              2024-03-22T16:12:57Z\n    processing_function:          commongrid.compute_MVBSxarray.DatasetDimensions:channel: 3ping_time: 8819echo_range: 150Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')ping_time(ping_time)datetime64[ns]2017-07-28T00:05:20 ... 2017-07-...long_name :Ping timestandard_name :timeaxis :Tarray(['2017-07-28T00:05:20.000000000', '2017-07-28T00:05:40.000000000',\n       '2017-07-28T00:06:00.000000000', ..., '2017-07-30T00:17:00.000000000',\n       '2017-07-30T00:17:20.000000000', '2017-07-30T00:17:40.000000000'],\n      dtype='datetime64[ns]')echo_range(echo_range)float640.0 5.0 10.0 ... 735.0 740.0 745.0long_name :Range distanceunits :marray([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,  55.,\n        60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105., 110., 115.,\n       120., 125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175.,\n       180., 185., 190., 195., 200., 205., 210., 215., 220., 225., 230., 235.,\n       240., 245., 250., 255., 260., 265., 270., 275., 280., 285., 290., 295.,\n       300., 305., 310., 315., 320., 325., 330., 335., 340., 345., 350., 355.,\n       360., 365., 370., 375., 380., 385., 390., 395., 400., 405., 410., 415.,\n       420., 425., 430., 435., 440., 445., 450., 455., 460., 465., 470., 475.,\n       480., 485., 490., 495., 500., 505., 510., 515., 520., 525., 530., 535.,\n       540., 545., 550., 555., 560., 565., 570., 575., 580., 585., 590., 595.,\n       600., 605., 610., 615., 620., 625., 630., 635., 640., 645., 650., 655.,\n       660., 665., 670., 675., 680., 685., 690., 695., 700., 705., 710., 715.,\n       720., 725., 730., 735., 740., 745.])Data variables: (2)Sv(channel, ping_time, echo_range)float64dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;long_name :Mean volume backscattering strength (MVBS, mean Sv re 1 m-1)units :dBactual_range :[-98.92  -1.67]cell_methods :ping_time: mean (interval: 20 second comment: ping_time is the interval start) echo_range: mean (interval: 5 meter comment: echo_range is the interval start)binning_mode :physical unitsrange_meter_interval :5mping_time_interval :20s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n30.28 MiB\n362.11 kiB\n\n\nShape\n(3, 8819, 150)\n(3, 103, 150)\n\n\nDask graph\n170 chunks in 341 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             150 8819 3\n\n\n\n\nfrequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequency\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nIndexes: (3)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:20', '2017-07-28 00:05:40',\n               '2017-07-28 00:06:00', '2017-07-28 00:06:20',\n               '2017-07-28 00:06:40', '2017-07-28 00:07:00',\n               '2017-07-28 00:07:20', '2017-07-28 00:07:40',\n               '2017-07-28 00:08:00', '2017-07-28 00:08:20',\n               ...\n               '2017-07-30 00:14:40', '2017-07-30 00:15:00',\n               '2017-07-30 00:15:20', '2017-07-30 00:15:40',\n               '2017-07-30 00:16:00', '2017-07-30 00:16:20',\n               '2017-07-30 00:16:40', '2017-07-30 00:17:00',\n               '2017-07-30 00:17:20', '2017-07-30 00:17:40'],\n              dtype='datetime64[ns]', name='ping_time', length=8819, freq=None))echo_rangePandasIndexPandasIndex(Float64Index([  0.0,   5.0,  10.0,  15.0,  20.0,  25.0,  30.0,  35.0,  40.0,\n               45.0,\n              ...\n              700.0, 705.0, 710.0, 715.0, 720.0, 725.0, 730.0, 735.0, 740.0,\n              745.0],\n             dtype='float64', name='echo_range', length=150))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.1processing_time :2024-03-22T16:12:57Zprocessing_function :commongrid.compute_MVBS\n\n\nReplace the channel dimension and coordinate with the frequency_nominal variable containing actual frequency values. Note that this step is possible only because there are no duplicated frequencies present.\n\n%%time\nMVBS_ds = ep.consolidate.swap_dims_channel_frequency(MVBS_ds)\n\nCPU times: user 1.54 s, sys: 193 ms, total: 1.74 s\nWall time: 11.6 s\n\n\n\nMVBS_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (frequency_nominal: 3, ping_time: 8819, echo_range: 150)\nCoordinates:\n  * ping_time          (ping_time) datetime64[ns] 2017-07-28T00:05:20 ... 201...\n  * echo_range         (echo_range) float64 0.0 5.0 10.0 ... 735.0 740.0 745.0\n  * frequency_nominal  (frequency_nominal) float64 1.8e+04 3.8e+04 1.2e+05\nData variables:\n    Sv                 (frequency_nominal, ping_time, echo_range) float64 dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;\n    channel            (frequency_nominal) &lt;U37 'GPT  18 kHz 009072058c8d 1-1...\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.1\n    processing_time:              2024-03-22T16:12:57Z\n    processing_function:          commongrid.compute_MVBSxarray.DatasetDimensions:frequency_nominal: 3ping_time: 8819echo_range: 150Coordinates: (3)ping_time(ping_time)datetime64[ns]2017-07-28T00:05:20 ... 2017-07-...long_name :Ping timestandard_name :timeaxis :Tarray(['2017-07-28T00:05:20.000000000', '2017-07-28T00:05:40.000000000',\n       '2017-07-28T00:06:00.000000000', ..., '2017-07-30T00:17:00.000000000',\n       '2017-07-30T00:17:20.000000000', '2017-07-30T00:17:40.000000000'],\n      dtype='datetime64[ns]')echo_range(echo_range)float640.0 5.0 10.0 ... 735.0 740.0 745.0long_name :Range distanceunits :marray([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,  55.,\n        60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105., 110., 115.,\n       120., 125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175.,\n       180., 185., 190., 195., 200., 205., 210., 215., 220., 225., 230., 235.,\n       240., 245., 250., 255., 260., 265., 270., 275., 280., 285., 290., 295.,\n       300., 305., 310., 315., 320., 325., 330., 335., 340., 345., 350., 355.,\n       360., 365., 370., 375., 380., 385., 390., 395., 400., 405., 410., 415.,\n       420., 425., 430., 435., 440., 445., 450., 455., 460., 465., 470., 475.,\n       480., 485., 490., 495., 500., 505., 510., 515., 520., 525., 530., 535.,\n       540., 545., 550., 555., 560., 565., 570., 575., 580., 585., 590., 595.,\n       600., 605., 610., 615., 620., 625., 630., 635., 640., 645., 650., 655.,\n       660., 665., 670., 675., 680., 685., 690., 695., 700., 705., 710., 715.,\n       720., 725., 730., 735., 740., 745.])frequency_nominal(frequency_nominal)float641.8e+04 3.8e+04 1.2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 18000.,  38000., 120000.])Data variables: (2)Sv(frequency_nominal, ping_time, echo_range)float64dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;long_name :Mean volume backscattering strength (MVBS, mean Sv re 1 m-1)units :dBactual_range :[-98.92  -1.67]cell_methods :ping_time: mean (interval: 20 second comment: ping_time is the interval start) echo_range: mean (interval: 5 meter comment: echo_range is the interval start)binning_mode :physical unitsrange_meter_interval :5mping_time_interval :20s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n30.28 MiB\n362.11 kiB\n\n\nShape\n(3, 8819, 150)\n(3, 103, 150)\n\n\nDask graph\n170 chunks in 341 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             150 8819 3\n\n\n\n\nchannel(frequency_nominal)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')Indexes: (3)ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:20', '2017-07-28 00:05:40',\n               '2017-07-28 00:06:00', '2017-07-28 00:06:20',\n               '2017-07-28 00:06:40', '2017-07-28 00:07:00',\n               '2017-07-28 00:07:20', '2017-07-28 00:07:40',\n               '2017-07-28 00:08:00', '2017-07-28 00:08:20',\n               ...\n               '2017-07-30 00:14:40', '2017-07-30 00:15:00',\n               '2017-07-30 00:15:20', '2017-07-30 00:15:40',\n               '2017-07-30 00:16:00', '2017-07-30 00:16:20',\n               '2017-07-30 00:16:40', '2017-07-30 00:17:00',\n               '2017-07-30 00:17:20', '2017-07-30 00:17:40'],\n              dtype='datetime64[ns]', name='ping_time', length=8819, freq=None))echo_rangePandasIndexPandasIndex(Float64Index([  0.0,   5.0,  10.0,  15.0,  20.0,  25.0,  30.0,  35.0,  40.0,\n               45.0,\n              ...\n              700.0, 705.0, 710.0, 715.0, 720.0, 725.0, 730.0, 735.0, 740.0,\n              745.0],\n             dtype='float64', name='echo_range', length=150))frequency_nominalPandasIndexPandasIndex(Float64Index([18000.0, 38000.0, 120000.0], dtype='float64', name='frequency_nominal'))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.1processing_time :2024-03-22T16:12:57Zprocessing_function :commongrid.compute_MVBS\n\n\n\n\nExtract MVBS along two N-S tracks selected via geographical bounding boxes\nDefine rectangular bounding boxes around two tracks oriented North-South, then plot a reference map showing all the GPS points (in red), the two bounding boxes (black), and the OOI mooring location (CE04 Oregon Offshore, yellow star) examined in the accompanying Jupyter notebook.\n\ntracksouth_bbox = gpd.GeoSeries(box(-125.17, 43.65, -125.14, 43.84), crs=gps_gdf.crs)\ntracknorth_bbox = gpd.GeoSeries(box(-125.17, 43.98, -125.14, 44.17), crs=gps_gdf.crs)\n\n\nbasemap = cimgt.OSM()\n\n_, ax = plt.subplots(\n    figsize=(7, 7), subplot_kw={\"projection\": basemap.crs}\n)\nbnd = gps_gdf.geometry.bounds\nax.set_extent([bnd.minx.min() - 1, bnd.maxx.max() + 2, \n               bnd.miny.min() - 0.8, bnd.maxy.max() + 2.2])\nax.add_image(basemap, 7)\nax.gridlines(draw_labels=True, xformatter=LONGITUDE_FORMATTER, yformatter=LATITUDE_FORMATTER)\n\n# GPS points\ngps_gdf.plot(ax=ax, markersize=0.1, color='red', \n             transform=ccrs.PlateCarree())\n\n# Bounding box for selected tracks\ntracksouth_bbox.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, facecolor='none', \n                     transform=ccrs.PlateCarree())\ntracknorth_bbox.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, facecolor='none', \n                     transform=ccrs.PlateCarree())\n\n# OOI CE04 Oregon Offshore mooring location\nplt.plot(-124.95, 44.37, marker='*', color='yellow', markersize=13, \n         transform=ccrs.PlateCarree());\n\n\n\n\n\n\n\n\nClip the GPS locations GeoPandas GeoDataFrame gps_gdf generated from the Platform group with the two rectangular regions, tracksouth_bbox and tracknorth_bbox. Extract from those clipped GeoDataFrames (tracksouth_gps_gdf and tracknorth_gps_gdf) the minimum and maximum time1 timestamps for each track and use them to select the corresponding time span in the MVBS data.\nFinally, create a MVBS Dataset subset for each track (tracksouth_MVBS_ds and tracknorth_MVBS_ds) by taking advantage of xarray’s “label”-based selection capability via the sel method. We select MVBS_ds data with ping_time values within the timestamp interval “slice” extracted from the geographical track. As we can see above, ping_time is a coordinate variable in the MVBS_ds Dataset.\n\ntracksouth_gps_gdf = gpd.clip(gps_gdf, tracksouth_bbox)\ntracksouth_MVBS_ds = MVBS_ds.sel(\n    ping_time=slice(tracksouth_gps_gdf.index.min(), tracksouth_gps_gdf.index.max())\n)\n\ntracknorth_gps_gdf = gpd.clip(gps_gdf, tracknorth_bbox)\ntracknorth_MVBS_ds = MVBS_ds.sel(\n    ping_time=slice(tracknorth_gps_gdf.index.min(), tracknorth_gps_gdf.index.max())\n)\n\n\n\nPlot MVBS echograms for the two N-S tracks, for all 3 frequencies\nThe final step is to create echogram plots (range vs ping_time) for each echosounder frequency and each of the two selected ship tracks. That’s 6 subplots. We first define two functions to simplify the task. plot_echograms plots the echograms of the 3 frequencies as a column of subplots, extracting the data for each frequency by using xarray’s isel index selector method, which uses index counts rather than values. As we can see above, frequency_nominal is a coordinate of the Sv (MVBS) DataArray.\n\ndef track_interval_str(trackdt):\n    \"\"\" Create the timestamp interval title string for a plot column\n    \"\"\"\n    track_interval_title_str = (\n        f\"{trackdt.index.min().strftime('%b-%d %H:%MZ')}\"\n        f\" to {trackdt.index.max().strftime('%b-%d %H:%MZ')}\"\n    )\n    return track_interval_title_str\n\ndef plot_echograms(ds, freq_len, column_idx):\n    \"\"\"Plot echograms of the 3 frequencies for xarray dataset ds,\n       as a column of subplots\"\"\"\n    for f in range(freq_len):\n        ax = axes[f][column_idx]\n        # Select Sv data by frequency using the frequency_nominal coordinate index \"f\",\n        # then plot the echogram of the selected data\n        ds.Sv.isel(frequency_nominal=f).plot(\n            ax=ax, \n            x='ping_time',\n            y='echo_range',\n            yincrease=False,\n            vmin=-80,\n            vmax=-50,\n        )\n        if f &lt; 2:\n            ax.set_xlabel(None);\n\n\nfreq_len = len(MVBS_ds.frequency_nominal)\n\nfig, axes = plt.subplots(nrows=freq_len, ncols=2, constrained_layout=True, figsize=(16, 16))\n\nfig.suptitle(\n    (f\"    South Track, {track_interval_str(tracksouth_gps_gdf)}\"\n     \"                                         \"\n     f\"North Track, {track_interval_str(tracknorth_gps_gdf)}\"),\n    fontsize=16)\n\nplot_echograms(tracksouth_MVBS_ds, freq_len, column_idx=0) # left column\nplot_echograms(tracknorth_MVBS_ds, freq_len, column_idx=1) # right column"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#package-versions",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks-dask.html#package-versions",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Package versions",
    "text": "Package versions\n\nimport datetime, s3fs\nprint(f\"echopype: {ep.__version__}, xarray: {xr.__version__}, geopandas: {gpd.__version__}, \"\n      f\"fsspec: {fsspec.__version__}, s3fs: {s3fs.__version__}\")\n\nprint(f\"\\n{datetime.datetime.utcnow()} +00:00\")\n\nechopype: 0.8.4, xarray: 2023.12.0, geopandas: 0.14.2, fsspec: 2023.12.2, s3fs: 2023.12.2\n\n2024-04-26 15:56:06.174336 +00:00"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/echopype_tour.html",
    "href": "topics-2024/2024-04-26-echopype/echopype_tour.html",
    "title": "echopype Tour",
    "section": "",
    "text": "https://github.com/OSOceanAcoustics/echopype-examples/blob/main/notebooks/\nA quick tour of core echopype capabilities."
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/echopype_tour.html#introduction",
    "href": "topics-2024/2024-04-26-echopype/echopype_tour.html#introduction",
    "title": "echopype Tour",
    "section": "Introduction",
    "text": "Introduction\n\nGoals\n\nIllustrate a common workflow for echosounder data conversion, calibration and use. This workflow leverages the standardization applied by echopype and the power, ease of use and familiarity of libraries in the scientific Python ecosystem.\nExtract and visualize data with relative ease.\n\n\n\nDescription\nThis notebook uses EK60 echosounder data collected during the 2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey (‘Pacific Hake Survey’) to illustrate a common workflow for data conversion, calibration and analysis using echopype and core scientific Python software packages, particularly xarray, GeoPandas and pandas.\nTwo days of cloud-hosted .raw data files are accessed by echopype directly from an Amazon Web Services (AWS) S3 “bucket” maintained by the NOAA NCEI Water-Column Sonar Data Archive. With echopype, each file is converted to a standardized representation based on the SONAR-netCDF4 v1.0 convention and saved to the Zarr cloud-optimized file format.\nData stored in the Zarr (or netCDF) file format using the SONAR-netCDF4 convention can be conveniently and intuitively manipulated with xarray in combination with related scientific Python packages. Mean Volume Backscattering Strength (MVBS) is computed with echopype from the combined, converted raw data files, after calibration. The GPS location track and MVBS echograms are visualized.\n\n\nRunning the notebook\nThis notebook can be run with a conda environment created using the conda environment file https://github.com/OSOceanAcoustics/echopype-examples/blob/main/binder/environment.yml. The notebook creates the ./exports directory, if not already present. Zarr files will be exported there.\n\nfrom pathlib import Path\n\nimport fsspec\nimport geopandas as gpd\nimport xarray as xr\n\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.io.img_tiles as cimgt\nfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\nimport hvplot.xarray\n\nimport echopype as ep\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/echopype_tour.html#compile-list-of-raw-files-to-read-from-the-ncei-wcsd-s3-bucket",
    "href": "topics-2024/2024-04-26-echopype/echopype_tour.html#compile-list-of-raw-files-to-read-from-the-ncei-wcsd-s3-bucket",
    "title": "echopype Tour",
    "section": "Compile list of raw files to read from the NCEI WCSD S3 bucket",
    "text": "Compile list of raw files to read from the NCEI WCSD S3 bucket\nWe’ll compile a list of several EK60 .raw files from the 2017 Pacific Hake survey, available via open, anonymous access from an AWS S3 bucket managed by the NCEI WCSD.\nAfter using fsspec to establish an S3 “file system” access point, extract a list of .raw files in the target directory.\n\nfs = fsspec.filesystem('s3', anon=True)\n\nbucket = \"ncei-wcsd-archive\"\nrawdirpath = \"data/raw/Bell_M._Shimada/SH1707/EK60\"\n\n\ns3rawfiles = fs.glob(f\"{bucket}/{rawdirpath}/*.raw\")\n\n\nprint(f\"There are {len(s3rawfiles)} raw files in the directory\")\n\nThere are 4343 raw files in the directory\n\n\n\n# print out the last two S3 raw file paths in the list\ns3rawfiles[-2:]\n\n['ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170913-T180733.raw',\n 'ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Winter2017-D20170615-T002629.raw']\n\n\nEach of these .raw files is typically about 25 MB. To select a reasonably small but meaningful target for this demo, let’s select all files from 2017-07-28 collected over a two hour period, 18:00 to 19:59 UTC. This is done through string matching on the time stamps found in the file names.\n\ns3rawfiles = [\n    s3path for s3path in s3rawfiles \n    if any([f\"D2017{dtstr}\" in s3path for dtstr in ['0728-T18', '0728-T19']])\n]\n\nprint(f\"There are {len(s3rawfiles)} target raw files available\")\n\nThere are 5 target raw files available\n\n\n\ns3rawfiles\n\n['ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T181619.raw',\n 'ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T184131.raw',\n 'ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T190728.raw',\n 'ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T193459.raw',\n 'ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T195219.raw']"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/echopype_tour.html#read-target-raw-files-directly-from-aws-s3-bucket-and-convert-to-netcdf",
    "href": "topics-2024/2024-04-26-echopype/echopype_tour.html#read-target-raw-files-directly-from-aws-s3-bucket-and-convert-to-netcdf",
    "title": "echopype Tour",
    "section": "Read target raw files directly from AWS S3 bucket and convert to netcdf",
    "text": "Read target raw files directly from AWS S3 bucket and convert to netcdf\nCreate the directory where the exported files will be saved, if this directory doesn’t already exist.\n\nbase_dpath = Path('./exports/notebook1')\nbase_dpath.mkdir(exist_ok=True, parents=True)\n\nEchoData is an echopype object for conveniently handling raw converted data from either raw instrument files or previously converted and standardized raw netCDF4 and Zarr files. It is essentially a container for multiple xarray.Dataset objects, each corresponds to one of the netCDF4 groups specified in the SONAR-netCDF4 convention – the convention followed by echopype. The EchoData object can be used to conveniently accesse and explore the echosounder raw data and for calibration and other processing.\nFor each raw file: - Access file directly from S3 via ep.open_raw to create a converted EchoData object in memory - Add global and platform attributes to EchoData object - Export to a local Zarr file\n\nfor s3rawfpath in s3rawfiles:\n    raw_fpath = Path(s3rawfpath)\n    try:\n        # Access file directly from S3 to create a converted EchoData object in memory\n        ed = ep.open_raw(\n            f\"s3://{s3rawfpath}\",\n            sonar_model='EK60',\n            storage_options={'anon': True}\n        )\n        # Manually populate additional metadata about the dataset and the platform\n        # -- SONAR-netCDF4 Top-level Group attributes\n        ed['Top-level'].attrs['title'] = \"2017 Pacific Hake Acoustic Trawl Survey\"\n        ed['Top-level'].attrs['summary'] = (\n            f\"EK60 raw file from the {ed['Top-level'].attrs['title']}, \"\n            \"converted to a SONAR-netCDF4 file using echopype.\"\n        )\n        # -- SONAR-netCDF4 Platform Group attributes\n        ed['Platform'].attrs['platform_type'] = \"Research vessel\"\n        ed['Platform'].attrs['platform_name'] = \"Bell M. Shimada\"  # A NOAA ship\n        ed['Platform'].attrs['platform_code_ICES'] = \"315\"        \n        \n        # Save to converted Zarr format \n        # Use the same base file name as the raw file but with a \".zarr\" extension        \n        ed.to_zarr(save_path=base_dpath, overwrite=True)\n    except Exception as e:\n        print(f\"Failed to process raw file {raw_fpath.name}: {e}\")\n\nLet’s examine the last EchoData object created above, ed. This summary shows a collapsed view of the netCDF4 groups that make up the EchoData object, where each group corresponds to an xarray Dataset. The backscatter data is in the Sonar/Beam_group1 group, accessible as ed['Sonar/Beam_group1'].\n\ned\n\n\n    \n        EchoData: standardized raw data from exports/notebook1/Summer2017-D20170728-T195219.zarr\n    \n    \n        \n            Top-level: contains metadata about the SONAR-netCDF4 file format.\n            \n            \n                \n                    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  ()\nData variables:\n    *empty*\nAttributes:\n    conventions:                 CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3\n    keywords:                    EK60\n    sonar_convention_authority:  ICES\n    sonar_convention_name:       SONAR-netCDF4\n    sonar_convention_version:    1.0\n    summary:                     EK60 raw file from the 2017 Pacific Hake Aco...\n    title:                       2017 Pacific Hake Acoustic Trawl Survey\n    date_created:                2017-07-28T19:52:19Z\n    processing_level:            Level 1A\n    processing_level_url:        https://echopype.readthedocs.io/en/stable/pr...xarray.DatasetDimensions:Coordinates: (0)Data variables: (0)Indexes: (0)Attributes: (10)conventions :CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3keywords :EK60sonar_convention_authority :ICESsonar_convention_name :SONAR-netCDF4sonar_convention_version :1.0summary :EK60 raw file from the 2017 Pacific Hake Acoustic Trawl Survey, converted to a SONAR-netCDF4 file using echopype.title :2017 Pacific Hake Acoustic Trawl Surveydate_created :2017-07-28T19:52:19Zprocessing_level :Level 1Aprocessing_level_url :https://echopype.readthedocs.io/en/stable/processing-levels.html\n                \n            \n        \n        \n                    Environment: contains information relevant to acoustic propagation through water.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                 (channel: 3, time1: 523)\nCoordinates:\n  * channel                 (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18...\n  * time1                   (time1) datetime64[ns] 2017-07-28T19:52:19.120310...\nData variables:\n    absorption_indicative   (channel, time1) float64 0.002822 ... 0.03259\n    sound_speed_indicative  (channel, time1) float64 1.481e+03 ... 1.481e+03\n    frequency_nominal       (channel) float64 1.8e+04 3.8e+04 1.2e+05xarray.DatasetDimensions:channel: 3time1: 523Coordinates: (2)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')time1(time1)datetime64[ns]2017-07-28T19:52:19.120310 ... 2...axis :Tlong_name :Timestamps for NMEA position datagramsstandard_name :timecomment :Time coordinate corresponding to environmental variables.array(['2017-07-28T19:52:19.120310000', '2017-07-28T19:52:23.078535000',\n       '2017-07-28T19:52:26.898323000', ..., '2017-07-28T20:25:56.435997000',\n       '2017-07-28T20:26:00.352222000', '2017-07-28T20:26:04.278446000'],\n      dtype='datetime64[ns]')Data variables: (3)absorption_indicative(channel, time1)float640.002822 0.002822 ... 0.03259long_name :Indicative acoustic absorptionunits :dB/mvalid_min :0.0array([[0.00282171, 0.00282171, 0.00282171, ..., 0.00282171, 0.00282171,\n        0.00282171],\n       [0.00985526, 0.00985526, 0.00985526, ..., 0.00985526, 0.00985526,\n        0.00985526],\n       [0.03259379, 0.03259379, 0.03259379, ..., 0.03259379, 0.03259379,\n        0.03259379]])sound_speed_indicative(channel, time1)float641.481e+03 1.481e+03 ... 1.481e+03long_name :Indicative sound speedstandard_name :speed_of_sound_in_sea_waterunits :m/svalid_min :0.0array([[1480.62597656, 1480.62597656, 1480.62597656, ..., 1480.62597656,\n        1480.62597656, 1480.62597656],\n       [1480.62597656, 1480.62597656, 1480.62597656, ..., 1480.62597656,\n        1480.62597656, 1480.62597656],\n       [1480.62597656, 1480.62597656, 1480.62597656, ..., 1480.62597656,\n        1480.62597656, 1480.62597656]])frequency_nominal(channel)float641.8e+04 3.8e+04 1.2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 18000.,  38000., 120000.])Indexes: (2)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 19:52:19.120310', '2017-07-28 19:52:23.078535',\n               '2017-07-28 19:52:26.898323', '2017-07-28 19:52:30.693539',\n               '2017-07-28 19:52:34.503756', '2017-07-28 19:52:38.321976',\n               '2017-07-28 19:52:42.129192', '2017-07-28 19:52:45.938410',\n               '2017-07-28 19:52:49.745628', '2017-07-28 19:52:53.564848',\n               ...\n               '2017-07-28 20:25:28.984426', '2017-07-28 20:25:32.900650',\n               '2017-07-28 20:25:36.826876', '2017-07-28 20:25:40.742100',\n               '2017-07-28 20:25:44.668324', '2017-07-28 20:25:48.594547',\n               '2017-07-28 20:25:52.519773', '2017-07-28 20:25:56.435997',\n               '2017-07-28 20:26:00.352222', '2017-07-28 20:26:04.278446'],\n              dtype='datetime64[ns]', name='time1', length=523, freq=None))Attributes: (0)\n                        \n                    \n                \n                    Platform: contains information about the platform on which the sonar is installed.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:              (time1: 2769, time2: 523, channel: 3)\nCoordinates:\n  * time1                (time1) datetime64[ns] 2017-07-28T19:52:22.001629 .....\n  * time2                (time2) datetime64[ns] 2017-07-28T19:52:19.120310 .....\n  * channel              (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18-11...\nData variables: (12/20)\n    latitude             (time1) float64 43.69 43.69 43.69 ... 43.78 43.78 43.78\n    longitude            (time1) float64 -125.2 -125.2 -125.2 ... -125.2 -125.2\n    sentence_type        (time1) &lt;U3 'GGA' 'GLL' 'GGA' ... 'GGA' 'GLL' 'GGA'\n    pitch                (time2) float64 -0.4641 -0.2911 ... -1.072 -0.3782\n    roll                 (time2) float64 0.58 -0.4938 0.4407 ... 0.6955 -0.03356\n    vertical_offset      (time2) float64 -0.1959 -0.00136 ... 0.16 -0.1182\n    ...                   ...\n    position_offset_y    float64 nan\n    position_offset_z    float64 nan\n    transducer_offset_x  (channel) float64 0.0 0.0 0.0\n    transducer_offset_y  (channel) float64 0.0 0.0 0.0\n    transducer_offset_z  (channel) float64 0.0 0.0 0.0\n    frequency_nominal    (channel) float64 1.8e+04 3.8e+04 1.2e+05\nAttributes:\n    platform_name:       Bell M. Shimada\n    platform_type:       Research vessel\n    platform_code_ICES:  315xarray.DatasetDimensions:time1: 2769time2: 523channel: 3Coordinates: (3)time1(time1)datetime64[ns]2017-07-28T19:52:22.001629 ... 2...axis :Tlong_name :Timestamps for NMEA datagramsstandard_name :timecomment :Time coordinate corresponding to NMEA position data.array(['2017-07-28T19:52:22.001629000', '2017-07-28T19:52:22.159962000',\n       '2017-07-28T19:52:23.456533000', ..., '2017-07-28T20:26:09.036873000',\n       '2017-07-28T20:26:09.195204000', '2017-07-28T20:26:10.437775000'],\n      dtype='datetime64[ns]')time2(time2)datetime64[ns]2017-07-28T19:52:19.120310 ... 2...axis :Tlong_name :Timestamps for platform motion and orientation datastandard_name :timecomment :Time coordinate corresponding to platform motion and orientation data.array(['2017-07-28T19:52:19.120310000', '2017-07-28T19:52:23.078535000',\n       '2017-07-28T19:52:26.898323000', ..., '2017-07-28T20:25:56.435997000',\n       '2017-07-28T20:26:00.352222000', '2017-07-28T20:26:04.278446000'],\n      dtype='datetime64[ns]')channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')Data variables: (20)latitude(time1)float6443.69 43.69 43.69 ... 43.78 43.78long_name :Platform latitudestandard_name :latitudeunits :degrees_northvalid_range :(-90.0, 90.0)array([43.68714833, 43.68716667, 43.68718   , ..., 43.77531   ,\n       43.77533333, 43.77535667])longitude(time1)float64-125.2 -125.2 ... -125.2 -125.2long_name :Platform longitudestandard_name :longitudeunits :degrees_eastvalid_range :(-180.0, 180.0)array([-125.159965  , -125.16      , -125.159965  , ..., -125.154635  ,\n       -125.15466667, -125.15462167])sentence_type(time1)&lt;U3'GGA' 'GLL' 'GGA' ... 'GLL' 'GGA'long_name :NMEA sentence typearray(['GGA', 'GLL', 'GGA', ..., 'GGA', 'GLL', 'GGA'], dtype='&lt;U3')pitch(time2)float64-0.4641 -0.2911 ... -1.072 -0.3782long_name :Platform pitchstandard_name :platform_pitch_angleunits :arc_degreevalid_range :(-90.0, 90.0)array([-0.46414915, -0.29106733, -1.35324407,  0.28543144, -0.49895924,\n       -0.69796586, -0.34305751, -1.01976168, -0.04      , -0.73263419,\n       -1.00628507,  0.30000001, -0.55409586, -0.60708082, -0.20009582,\n       -0.69847667, -0.77516168, -0.76696169, -0.56190413, -0.18000001,\n       -0.88999999, -0.14687543, -0.87770593, -0.4097085 , -0.23276971,\n       -0.91171914, -0.74000001, -0.52796578, -0.61938083, -0.11596964,\n        0.05040418, -1.23996162,  0.39050275, -0.76862389, -1.17743719,\n       -0.54832333, -0.52548087, -1.03190422,  0.40808085, -0.92023003,\n       -1.581285  ,  0.21659583, -0.35781819, -0.62903827, -0.15561917,\n       -0.84685749, -0.40481916, -0.79000002, -0.54688084, -0.69999999,\n       -0.85177046, -0.73797959, -0.21684243, -0.64017922, -0.85526866,\n       -0.41822281, -0.54173416, -1.26194465, -0.21716167, -0.88863415,\n       -0.75708497,  0.15171455, -1.0697341 , -0.96286589,  0.1       ,\n       -0.61509585, -0.41999999, -0.70087665, -1.0645808 , -0.02      ,\n       -1.00533414, -0.68254697, -0.13947679, -1.56140423,  0.34615329,\n       -0.41513416, -1.23548079, -0.41166589, -0.40560293, -0.98078072,\n       -0.56661981, -0.09697327, -1.49982953, -0.30271903, -1.11363828,\n       -0.57986581, -0.26188084, -0.64609587, -0.90468085, -0.2209425 ,\n       -1.25      , -0.08890419, -0.48451501, -0.69341916, -0.11759581,\n       -1.21245754, -0.34041244, -0.66523832, -0.73254251, -0.19      ,\n...\n       -1.03343832, -0.71488082, -0.883901  , -0.96842468, -0.67573369,\n       -0.11344167, -0.86604756, -0.52465874, -0.88168085,  0.14687666,\n       -1.03505325, -1.12694561, -0.28965104, -0.65035182, -0.6896767 ,\n       -1.13463831, -0.59018081, -1.0282191 , -0.7592575 , -1.37990415,\n       -0.56858081, -0.94184273, -0.83999997, -0.83713895, -1.1230998 ,\n       -0.22094199, -0.93047667, -1.33490419, -0.21516168, -0.65943831,\n       -0.89763123, -0.84990859, -1.03000402, -0.56621683, -0.95999998,\n       -0.79619676, -0.11618084, -1.42999995, -1.10072756,  0.14178875,\n       -1.39754081, -0.79312336, -0.72000003, -0.97345752, -0.77565753,\n       -1.09007668, -0.70796168, -0.86474252, -0.78581917, -0.98632336,\n       -0.16636167, -1.1846987 , -1.31847095, -0.35135594, -1.09000003,\n       -0.33766645, -0.48559579, -1.32853508, -0.59028292, -0.32723832,\n       -0.97407663, -0.86474252, -0.1980326 , -1.03456295, -0.82866585,\n       -0.59392333, -0.56527668, -1.03638089, -0.33203831, -1.03709579,\n       -1.20624244, -0.65219206, -1.03610802, -0.87146533, -0.60151917,\n       -0.74414253, -0.52195752, -1.3052808 , -0.50547862, -0.54189324,\n       -0.76682615, -0.84631515, -1.54695296, -0.07032997, -1.05059576,\n       -1.1464808 , -0.67586583, -0.3956961 , -0.70208085, -0.85638505,\n       -0.81      , -0.42596167, -0.46078083, -1.09000003, -0.48411918,\n       -0.74251914, -1.07183838, -0.37821916])roll(time2)float640.58 -0.4938 ... 0.6955 -0.03356long_name :Platform rollstandard_name :platform_roll_angleunits :arc_degreevalid_range :(-90.0, 90.0)array([ 0.57999998, -0.49378654,  0.44070238, -0.43543145, -0.08156113,\n       -0.20343833,  0.08203834,  0.20011917,  0.11058084, -0.72992331,\n        1.41438079, -1.25355744,  0.14691502, -0.02583834,  0.49201918,\n       -0.78635752,  0.5820958 , -0.63303834,  0.86923832, -0.68759584,\n        0.35727665, -0.30968687, -0.31229407,  0.53481781, -1.09425652,\n        0.61515749, -0.16828084,  0.14484249, -0.37123832,  0.75080609,\n       -1.06991911,  0.85003835, -0.68949723,  0.38426605, -0.67537695,\n        0.99541914, -0.74451917,  0.76361918, -0.28575751, -0.41986582,\n        0.8556425 , -0.40463832, -0.61913633,  0.47730783, -0.9131425 ,\n        0.38247666,  0.08072334, -0.43890417,  0.91128504, -0.77583665,\n        0.70371592,  0.04398979,  0.04631516, -0.02678614,  0.12526868,\n        0.05355436, -0.19763833,  0.08027669,  0.30716166, -0.56896168,\n        0.23381917, -0.21757182,  0.10845748,  0.33694252, -0.47098085,\n        0.63392335, -0.75832331,  0.47434253,  0.08541917,  0.12644249,\n       -0.62552333,  0.81254697, -0.42842054, -0.7005617 ,  1.04490423,\n       -0.83494252,  0.60451919, -0.42785749,  0.44999999, -0.5915615 ,\n        1.11827481, -1.16042137,  0.99678034, -0.05135951,  0.1954575 ,\n        0.48994249,  0.48623833, -0.15721917, -0.08      ,  0.56792331,\n       -0.5079028 ,  0.16356167, -0.56290418,  0.59316164, -0.63999999,\n        0.21327665, -0.07991751,  0.07761917,  0.14836167, -0.04820262,\n...\n       -0.88640416,  0.82071501,  0.32439604, -0.16842465,  0.90382242,\n       -0.39967498,  0.64604753,  0.19720475, -0.35336167,  0.90984249,\n       -0.54000002,  1.15305436, -0.69104689,  0.28311571,  0.45967668,\n       -0.03623417, -0.55162746,  0.38890418, -0.37790418,  0.92990422,\n       -0.62      ,  0.81184274, -0.042715  ,  0.48856488, -0.15338005,\n        0.39094201,  0.08238083,  0.52003831, -0.54241914,  0.80112332,\n       -0.99000001,  1.15196347, -1.25      ,  1.30621684, -0.91791517,\n        0.57140964, -0.38291496,  0.20405109,  1.20048499, -0.64821124,\n        0.56622958, -0.08578084,  0.52527606, -0.25345749,  0.44521916,\n       -0.13748084,  0.33305749, -0.03577253,  0.14163834, -0.14341916,\n       -0.30454251,  0.79424107, -1.18694186,  1.155339  , -0.86868167,\n        0.72933424, -0.14471497,  0.01267539,  0.28      , -0.06447665,\n        0.22407664,  0.97000003, -0.46622816,  0.64912587,  0.19190416,\n       -0.66000003,  1.15631914, -0.96361917,  0.57305747, -0.50941914,\n        0.70959586, -0.78684783,  1.2890625 , -1.31853461, -0.630885  ,\n       -1.22033417, -0.74072331, -0.67943829, -0.46226069,  0.08378647,\n        0.92000002, -0.62894547,  2.02609396,  0.84983504, -0.11447664,\n        1.78167248, -0.01807666,  0.28713074, -0.63583833,  0.18000001,\n       -0.91129261, -0.25798082,  0.02234248, -0.32309583,  0.31235749,\n       -0.23007667,  0.69551498, -0.03356168])vertical_offset(time2)float64-0.1959 -0.00136 ... 0.16 -0.1182long_name :Platform vertical offset from nominal water levelunits :marray([-1.95850864e-01, -1.35960290e-03,  3.33244085e-01, -5.79999983e-01,\n        1.44219443e-01,  9.48425159e-02, -7.89808258e-02,  2.59642512e-01,\n       -4.39999998e-01,  4.32557523e-01, -2.63714969e-01, -3.21923345e-01,\n        3.22819173e-01,  4.70808297e-02, -5.17980814e-01,  3.10595840e-01,\n        1.62742510e-01,  1.08480833e-01, -1.78476691e-01, -1.44961655e-01,\n        1.83180839e-01, -3.30000013e-01,  3.05901974e-01, -3.70145738e-01,\n       -2.29737218e-02,  1.19999997e-01,  4.48425151e-02, -2.45157510e-01,\n        1.00619167e-01, -4.62418228e-01, -1.00404181e-01,  1.99942499e-01,\n       -4.09999996e-01, -8.53209198e-03,  5.52562833e-01, -3.72515023e-01,\n        4.51916223e-03,  1.25523344e-01, -6.32323325e-01,  5.70076704e-01,\n        2.11284995e-01, -5.40000021e-01,  7.39090964e-02, -1.13653913e-01,\n       -5.87616600e-02,  3.40000004e-01, -3.75180840e-01,  3.01561654e-01,\n       -3.79999995e-01,  3.43540847e-01,  3.17704529e-02, -7.60102049e-02,\n       -1.89999998e-01, -3.21386452e-03,  1.80000007e-01, -1.43554360e-01,\n        4.09583654e-03,  4.93889332e-01, -3.96419168e-01,  1.22076660e-01,\n        2.04723328e-01, -2.95857280e-01,  3.72819155e-01, -3.05748568e-03,\n       -3.60980839e-01, -8.29425007e-02,  2.57919163e-01,  6.52191639e-02,\n        1.44580826e-01, -4.20961678e-01,  4.67238337e-01, -2.14544207e-01,\n       -2.43682131e-01,  7.71123350e-01, -7.88076639e-01,  1.14983442e-04,\n        1.90961659e-01, -9.04766396e-02, -1.26638249e-01,  4.21561480e-01,\n...\n       -1.12057485e-01, -8.58083088e-03,  2.90786438e-02, -7.28808343e-02,\n        4.57129739e-02,  2.16479808e-01, -4.79999989e-01,  2.17619166e-01,\n        9.99616757e-02, -1.42419159e-01, -3.30561668e-01,  3.40000004e-01,\n       -3.34018290e-01,  4.03336018e-01, -4.30000007e-01,  2.17220202e-01,\n       -5.76064326e-02, -2.72361666e-01,  6.15784645e-01, -5.29514968e-01,\n       -2.37154976e-01,  3.90655637e-01,  5.73425218e-02, -2.19999999e-01,\n        1.15638331e-01,  1.09999999e-01,  2.92519152e-01, -5.30574843e-02,\n       -2.09999993e-01, -9.83616635e-02,  1.89742506e-01, -2.55457491e-01,\n        8.62890854e-02,  5.26353180e-01, -6.45339012e-01,  3.22893888e-01,\n       -2.42333546e-01, -2.44041942e-02,  4.00000006e-01, -3.39858532e-01,\n       -2.89142519e-01,  3.81019175e-01, -8.20958018e-02, -2.37869620e-01,\n        1.89999998e-01, -2.44857505e-01,  8.90191644e-02, -2.03680828e-01,\n        3.19999993e-01, -3.60000014e-01,  4.08257484e-01, -8.16766769e-02,\n       -2.65760943e-02,  3.92613597e-02, -6.37069345e-02, -1.71519160e-01,\n       -1.31380841e-01, -1.26808342e-02,  1.50000006e-01, -3.92260700e-01,\n        7.99999982e-02, -1.48782566e-01,  2.92630315e-01,  2.43905976e-01,\n       -7.09670007e-01,  3.30595791e-01,  3.92404139e-01, -2.96057492e-01,\n       -3.74303907e-01,  2.00000003e-01, -3.36149521e-02,  1.29999995e-01,\n       -5.20191640e-02, -2.19999999e-01,  1.43238336e-01, -3.30000013e-01,\n        1.15038335e-01,  1.59999996e-01, -1.18219160e-01])water_level()float649.15long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(9.14999962)MRU_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_rotation_x()float64nanlong_name :Extrinsic rotation about the x-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_y()float64nanlong_name :Extrinsic rotation about the y-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_z()float64nanlong_name :Extrinsic rotation about the z-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)position_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)transducer_offset_x(channel)float640.0 0.0 0.0long_name :x-axis distance from the platform coordinate system origin to the sonar transducerunits :marray([0., 0., 0.])transducer_offset_y(channel)float640.0 0.0 0.0long_name :y-axis distance from the platform coordinate system origin to the sonar transducerunits :marray([0., 0., 0.])transducer_offset_z(channel)float640.0 0.0 0.0long_name :z-axis distance from the platform coordinate system origin to the sonar transducerunits :marray([0., 0., 0.])frequency_nominal(channel)float641.8e+04 3.8e+04 1.2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 18000.,  38000., 120000.])Indexes: (3)time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 19:52:22.001629', '2017-07-28 19:52:22.159962',\n               '2017-07-28 19:52:23.456533', '2017-07-28 19:52:24.249680',\n               '2017-07-28 19:52:24.408010', '2017-07-28 19:52:24.963188',\n               '2017-07-28 19:52:26.212439', '2017-07-28 19:52:26.370770',\n               '2017-07-28 19:52:27.013306', '2017-07-28 19:52:28.264477',\n               ...\n               '2017-07-28 20:26:04.437431', '2017-07-28 20:26:05.236656',\n               '2017-07-28 20:26:05.394987', '2017-07-28 20:26:06.487549',\n               '2017-07-28 20:26:07.290693', '2017-07-28 20:26:07.449024',\n               '2017-07-28 20:26:08.287653', '2017-07-28 20:26:09.036873',\n               '2017-07-28 20:26:09.195204', '2017-07-28 20:26:10.437775'],\n              dtype='datetime64[ns]', name='time1', length=2769, freq=None))time2PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 19:52:19.120310', '2017-07-28 19:52:23.078535',\n               '2017-07-28 19:52:26.898323', '2017-07-28 19:52:30.693539',\n               '2017-07-28 19:52:34.503756', '2017-07-28 19:52:38.321976',\n               '2017-07-28 19:52:42.129192', '2017-07-28 19:52:45.938410',\n               '2017-07-28 19:52:49.745628', '2017-07-28 19:52:53.564848',\n               ...\n               '2017-07-28 20:25:28.984426', '2017-07-28 20:25:32.900650',\n               '2017-07-28 20:25:36.826876', '2017-07-28 20:25:40.742100',\n               '2017-07-28 20:25:44.668324', '2017-07-28 20:25:48.594547',\n               '2017-07-28 20:25:52.519773', '2017-07-28 20:25:56.435997',\n               '2017-07-28 20:26:00.352222', '2017-07-28 20:26:04.278446'],\n              dtype='datetime64[ns]', name='time2', length=523, freq=None))channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))Attributes: (3)platform_name :Bell M. Shimadaplatform_type :Research vesselplatform_code_ICES :315\n                        \n                    \n                \n                    NMEA: contains information specific to the NMEA protocol.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:        (time1: 29194)\nCoordinates:\n  * time1          (time1) datetime64[ns] 2017-07-28T19:52:19.120310 ... 2017...\nData variables:\n    NMEA_datagram  (time1) &lt;U73 '$SDVLW,5063.975,N,5063.975,N' ... '$INHDT,7....\nAttributes:\n    description:  All NMEA sensor datagramsxarray.DatasetDimensions:time1: 29194Coordinates: (1)time1(time1)datetime64[ns]2017-07-28T19:52:19.120310 ... 2...axis :Tlong_name :Timestamps for NMEA datagramsstandard_name :timecomment :Time coordinate corresponding to NMEA sensor data.array(['2017-07-28T19:52:19.120310000', '2017-07-28T19:52:21.858847000',\n       '2017-07-28T19:52:21.971268000', ..., '2017-07-28T20:26:10.596106000',\n       '2017-07-28T20:26:10.678192000', '2017-07-28T20:26:10.778200000'],\n      dtype='datetime64[ns]')Data variables: (1)NMEA_datagram(time1)&lt;U73'$SDVLW,5063.975,N,5063.975,N' ....long_name :NMEA datagramarray(['$SDVLW,5063.975,N,5063.975,N', '$INHDT,1.7,T',\n       '$SDVLW,5063.980,N,5063.980,N', ..., '$GPHDT,,T', '$INHDT,7.6,T',\n       '$INHDT,7.6,T'], dtype='&lt;U73')Indexes: (1)time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 19:52:19.120310', '2017-07-28 19:52:21.858847',\n               '2017-07-28 19:52:21.971268', '2017-07-28 19:52:21.956854',\n               '2017-07-28 19:52:22.056858', '2017-07-28 19:52:22.156864',\n               '2017-07-28 19:52:22.256870', '2017-07-28 19:52:21.909964',\n               '2017-07-28 19:52:22.001629', '2017-07-28 19:52:22.159962',\n               ...\n               '2017-07-28 20:26:10.278172', '2017-07-28 20:26:10.315586',\n               '2017-07-28 20:26:10.378176', '2017-07-28 20:26:10.478182',\n               '2017-07-28 20:26:10.578188', '2017-07-28 20:26:10.346109',\n               '2017-07-28 20:26:10.437775', '2017-07-28 20:26:10.596106',\n               '2017-07-28 20:26:10.678192', '2017-07-28 20:26:10.778200'],\n              dtype='datetime64[ns]', name='time1', length=29194, freq=None))Attributes: (1)description :All NMEA sensor datagrams\n                        \n                    \n                \n                    Provenance: contains metadata about how the SONAR-netCDF4 version of the data were obtained.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (filenames: 1)\nCoordinates:\n  * filenames         (filenames) int64 0\nData variables:\n    source_filenames  (filenames) &lt;U92 's3://ncei-wcsd-archive/data/raw/Bell_...\nAttributes:\n    conversion_software_name:     echopype\n    conversion_software_version:  0.8.4\n    conversion_time:              2024-04-26T16:05:40Zxarray.DatasetDimensions:filenames: 1Coordinates: (1)filenames(filenames)int640long_name :Index for data and metadata source filenamesarray([0])Data variables: (1)source_filenames(filenames)&lt;U92's3://ncei-wcsd-archive/data/raw...long_name :Source filenamesarray(['s3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T195219.raw'],\n      dtype='&lt;U92')Indexes: (1)filenamesPandasIndexPandasIndex(Int64Index([0], dtype='int64', name='filenames'))Attributes: (3)conversion_software_name :echopypeconversion_software_version :0.8.4conversion_time :2024-04-26T16:05:40Z\n                        \n                    \n                \n                    Sonar: contains sonar system metadata and sonar beam groups.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (beam_group: 1)\nCoordinates:\n  * beam_group        (beam_group) &lt;U11 'Beam_group1'\nData variables:\n    beam_group_descr  (beam_group) &lt;U131 'contains backscatter power (uncalib...\nAttributes:\n    sonar_manufacturer:      Simrad\n    sonar_model:             EK60\n    sonar_serial_number:     \n    sonar_software_name:     ER60\n    sonar_software_version:  2.4.3\n    sonar_type:              echosounderxarray.DatasetDimensions:beam_group: 1Coordinates: (1)beam_group(beam_group)&lt;U11'Beam_group1'long_name :Beam group namearray(['Beam_group1'], dtype='&lt;U11')Data variables: (1)beam_group_descr(beam_group)&lt;U131'contains backscatter power (unc...long_name :Beam group descriptionarray(['contains backscatter power (uncalibrated) and other beam or channel-specific data, including split-beam angle data when they exist.'],\n      dtype='&lt;U131')Indexes: (1)beam_groupPandasIndexPandasIndex(Index(['Beam_group1'], dtype='object', name='beam_group'))Attributes: (6)sonar_manufacturer :Simradsonar_model :EK60sonar_serial_number :sonar_software_name :ER60sonar_software_version :2.4.3sonar_type :echosounder\n                        \n                    \n                \n                    Beam_group1: contains backscatter power (uncalibrated) and other beam or channel-specific data, including split-beam angle data when they exist.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                        (channel: 3, ping_time: 523,\n                                    range_sample: 3957)\nCoordinates:\n  * channel                        (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1...\n  * ping_time                      (ping_time) datetime64[ns] 2017-07-28T19:5...\n  * range_sample                   (range_sample) int64 0 1 2 ... 3954 3955 3956\nData variables: (12/29)\n    frequency_nominal              (channel) float64 1.8e+04 3.8e+04 1.2e+05\n    beam_type                      (channel) int64 1 1 1\n    beamwidth_twoway_alongship     (channel) float64 10.9 6.81 6.58\n    beamwidth_twoway_athwartship   (channel) float64 10.82 6.85 6.52\n    beam_direction_x               (channel) float64 nan nan nan\n    beam_direction_y               (channel) float64 nan nan nan\n    ...                             ...\n    data_type                      (channel, ping_time) int8 3 3 3 3 ... 3 3 3 3\n    sample_time_offset             (channel, ping_time) float64 0.0 0.0 ... 0.0\n    channel_mode                   (channel, ping_time) int8 0 0 0 0 ... 0 0 0 0\n    backscatter_r                  (channel, ping_time, range_sample) float32 ...\n    angle_athwartship              (channel, ping_time, range_sample) int8 -3...\n    angle_alongship                (channel, ping_time, range_sample) int8 3 ...\nAttributes:\n    beam_mode:              vertical\n    conversion_equation_t:  type_3xarray.DatasetDimensions:channel: 3ping_time: 523range_sample: 3957Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')ping_time(ping_time)datetime64[ns]2017-07-28T19:52:19.120310 ... 2...long_name :Timestamp of each pingstandard_name :timeaxis :Tarray(['2017-07-28T19:52:19.120310000', '2017-07-28T19:52:23.078535000',\n       '2017-07-28T19:52:26.898323000', ..., '2017-07-28T20:25:56.435997000',\n       '2017-07-28T20:26:00.352222000', '2017-07-28T20:26:04.278446000'],\n      dtype='datetime64[ns]')range_sample(range_sample)int640 1 2 3 4 ... 3953 3954 3955 3956long_name :Along-range sample number, base 0array([   0,    1,    2, ..., 3954, 3955, 3956])Data variables: (29)frequency_nominal(channel)float641.8e+04 3.8e+04 1.2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 18000.,  38000., 120000.])beam_type(channel)int641 1 1long_name :type of transducer (0-single, 1-split)array([1, 1, 1])beamwidth_twoway_alongship(channel)float6410.9 6.81 6.58long_name :Half power two-way beam width along alongship axis of beamunits :arc_degreevalid_range :(0.0, 360.0)comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_minor and beamwidth_transmit_minor), but Simrad echosounders record two-way beamwidth in the data.array([10.89999962,  6.80999994,  6.57999992])beamwidth_twoway_athwartship(channel)float6410.82 6.85 6.52long_name :Half power two-way beam width along athwartship axis of beamunits :arc_degreevalid_range :(0.0, 360.0)comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_major and beamwidth_transmit_major), but Simrad echosounders record two-way beamwidth in the data.array([10.81999969,  6.8499999 ,  6.51999998])beam_direction_x(channel)float64nan nan nanlong_name :x-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :(-1.0, 1.0)array([nan, nan, nan])beam_direction_y(channel)float64nan nan nanlong_name :y-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :(-1.0, 1.0)array([nan, nan, nan])beam_direction_z(channel)float64nan nan nanlong_name :z-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :(-1.0, 1.0)array([nan, nan, nan])angle_offset_alongship(channel)float64-0.18 -0.08 -0.05long_name :electrical alongship angle offset of the transducercomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([-0.18000001, -0.08      , -0.05      ])angle_offset_athwartship(channel)float640.25 0.0 0.37long_name :electrical athwartship angle offset of the transducercomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([0.25, 0.  , 0.37])angle_sensitivity_alongship(channel)float6413.89 21.97 23.12long_name :alongship angle sensitivity of the transducercomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([13.89000034, 21.96999931, 23.12000084])angle_sensitivity_athwartship(channel)float6413.89 21.97 23.12long_name :athwartship angle sensitivity of the transducercomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([13.89000034, 21.96999931, 23.12000084])equivalent_beam_angle(channel)float64-17.37 -21.01 -20.47long_name :Equivalent beam angleunits :srvalid_range :(0.0, 12.566370614359172)array([-17.37000084, -21.01000023, -20.46999931])gain_correction(channel)float6422.95 26.07 26.55long_name :Gain correctionunits :dBarray([22.95000076, 26.06999969, 26.54999924])gpt_software_version(channel)&lt;U6'070413' '070413' '070413'array(['070413', '070413', '070413'], dtype='&lt;U6')transmit_frequency_start(channel)float641.8e+04 3.8e+04 1.2e+05long_name :Start frequency in transmitted pulseunits :Hzstandard_name :sound_frequencyvalid_min :0.0array([ 18000.,  38000., 120000.])transmit_frequency_stop(channel)float641.8e+04 3.8e+04 1.2e+05long_name :Stop frequency in transmitted pulseunits :Hzstandard_name :sound_frequencyvalid_min :0.0array([ 18000.,  38000., 120000.])transmit_type()&lt;U2'CW'long_name :Type of transmitted pulseflag_values :['CW']flag_meanings :['Continuous Wave – a pulse nominally of one frequency']array('CW', dtype='&lt;U2')beam_stabilisation()int80long_name :Beam stabilisation applied (or not)flag_values :[0, 1]flag_meanings :['not stabilised', 'stabilised']array(0, dtype=int8)non_quantitative_processing()int160long_name :Presence or not of non-quantitative processing applied to the backscattering data (sonar specific)flag_values :[0]flag_meanings :['None']array(0, dtype=int16)sample_interval(channel, ping_time)float640.000256 0.000256 ... 0.000256long_name :Interval between recorded raw data samplesunits :svalid_min :0.0array([[0.000256, 0.000256, 0.000256, ..., 0.000256, 0.000256, 0.000256],\n       [0.000256, 0.000256, 0.000256, ..., 0.000256, 0.000256, 0.000256],\n       [0.000256, 0.000256, 0.000256, ..., 0.000256, 0.000256, 0.000256]])transmit_bandwidth(channel, ping_time)float641.574e+03 1.574e+03 ... 3.026e+03long_name :Nominal bandwidth of transmitted pulseunits :Hzvalid_min :0.0array([[1573.66552734, 1573.66552734, 1573.66552734, ..., 1573.66552734,\n        1573.66552734, 1573.66552734],\n       [2425.1496582 , 2425.1496582 , 2425.1496582 , ..., 2425.1496582 ,\n        2425.1496582 , 2425.1496582 ],\n       [3026.39160156, 3026.39160156, 3026.39160156, ..., 3026.39160156,\n        3026.39160156, 3026.39160156]])transmit_duration_nominal(channel, ping_time)float640.001024 0.001024 ... 0.001024long_name :Nominal bandwidth of transmitted pulseunits :svalid_min :0.0array([[0.001024, 0.001024, 0.001024, ..., 0.001024, 0.001024, 0.001024],\n       [0.001024, 0.001024, 0.001024, ..., 0.001024, 0.001024, 0.001024],\n       [0.001024, 0.001024, 0.001024, ..., 0.001024, 0.001024, 0.001024]])transmit_power(channel, ping_time)float642e+03 2e+03 2e+03 ... 250.0 250.0long_name :Nominal transmit powerunits :Wvalid_min :0.0array([[2000., 2000., 2000., ..., 2000., 2000., 2000.],\n       [2000., 2000., 2000., ..., 2000., 2000., 2000.],\n       [ 250.,  250.,  250., ...,  250.,  250.,  250.]])data_type(channel, ping_time)int83 3 3 3 3 3 3 3 ... 3 3 3 3 3 3 3 3long_name :recorded data type (1=power only, 2=angle only, 3=power and angle)flag_values :[1, 2, 3]flag_meanings :['power only', 'angle only', 'power and angle']array([[3, 3, 3, ..., 3, 3, 3],\n       [3, 3, 3, ..., 3, 3, 3],\n       [3, 3, 3, ..., 3, 3, 3]], dtype=int8)sample_time_offset(channel, ping_time)float640.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0long_name :Time offset that is subtracted from the timestamp of each sampleunits :sarray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])channel_mode(channel, ping_time)int80 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0long_name :Transceiver modeflag_values :[-1, 0, 1, 2]flag_meanings :['Unknown', 'Active', 'Passive', 'Test']comment :From transmit_mode in the EK60 datagramarray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)backscatter_r(channel, ping_time, range_sample)float3215.79 26.34 26.27 ... -161.2 -160.8long_name :Raw backscatter measurements (real part)units :dBarray([[[  15.7923155,   26.340124 ,   26.269571 , ..., -144.2945   ,\n         -149.93881  , -144.5767   ],\n        [  15.7923155,   26.340124 ,   26.269571 , ..., -169.45872  ,\n         -144.58847  , -143.45961  ],\n        [  15.7923155,   26.340124 ,   26.269571 , ..., -141.47234  ,\n         -148.26903  , -143.03629  ],\n        ...,\n        [  15.7923155,   26.340124 ,   26.269571 , ..., -140.46106  ,\n         -142.07205  , -151.56154  ],\n        [  15.7923155,   26.340124 ,   26.269571 , ..., -141.77808  ,\n         -140.9667   , -142.57768  ],\n        [  15.7923155,   26.340124 ,   26.269571 , ..., -154.91286  ,\n         -140.81383  , -146.45815  ]],\n\n       [[  17.379778 ,   26.72817  ,   27.175013 , ..., -158.89915  ,\n         -160.0045   , -155.50081  ],\n        [  17.379778 ,   26.72817  ,   27.175013 , ..., -165.83696  ,\n         -155.88885  , -166.8835   ],\n        [  17.379778 ,   26.72817  ,   27.175013 , ..., -152.00839  ,\n         -148.96281  , -148.52773  ],\n...\n        [  17.379778 ,   26.72817  ,   27.175013 , ..., -141.2254   ,\n         -149.40965  , -147.25775  ],\n        [  17.379778 ,   26.72817  ,   27.175013 , ..., -147.78691  ,\n         -157.053    , -170.75221  ],\n        [  17.379778 ,   26.72817  ,   27.175013 , ..., -147.55173  ,\n         -152.00839  , -160.7806   ]],\n\n       [[  12.39397  ,   18.073559 ,   18.050041 , ..., -165.70761  ,\n         -161.05104  , -159.66348  ],\n        [  12.417487 ,   18.073559 ,   18.050041 , ..., -162.30925  ,\n         -173.95065  , -162.10936  ],\n        [  12.417487 ,   18.073559 ,   18.050041 , ..., -160.20439  ,\n         -165.16669  , -169.24706  ],\n        ...,\n        [  12.417487 ,   18.073559 ,   18.050041 , ..., -167.93005  ,\n         -162.34453  , -160.93346  ],\n        [  12.417487 ,   18.073559 ,   18.0618   , ..., -157.64095  ,\n         -166.70712  , -162.73257  ],\n        [  12.417487 ,   18.073559 ,   18.050041 , ..., -163.46164  ,\n         -161.2392   , -160.80411  ]]], dtype=float32)angle_athwartship(channel, ping_time, range_sample)int8-3 -3 -4 -4 -4 ... 99 103 28 -30 19long_name :electrical athwartship anglecomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([[[  -3,   -3,   -4, ...,  109,  -54,   -1],\n        [  -3,   -3,   -4, ..., -102,   21,   10],\n        [  -3,   -3,   -4, ...,   22,  112,   48],\n        ...,\n        [  -3,   -3,   -4, ..., -120,  -92,  -97],\n        [  -3,   -3,   -4, ...,   21,  -10,   24],\n        [  -3,   -3,   -4, ..., -123,  -49,  -90]],\n\n       [[  -1,   -2,   -2, ...,  -62,  -60,  -66],\n        [  -1,   -2,   -2, ..., -118,  -38, -118],\n        [  -1,   -2,   -2, ...,   41,   33,   24],\n        ...,\n        [  -1,   -2,   -2, ...,   15,   50,   44],\n        [  -1,   -2,   -2, ...,   22,   89, -120],\n        [  -1,   -2,   -2, ...,  -16,  -48,  -92]],\n\n       [[  -2,   -3,   -3, ..., -117,   62,  -74],\n        [  -2,   -3,   -3, ...,  -99, -121,    5],\n        [  -2,   -3,   -3, ...,  -38,  -37,   87],\n        ...,\n        [  -2,   -3,   -3, ...,  -36,   92,  -72],\n        [  -2,   -3,   -3, ...,   30,   93,   86],\n        [  -2,   -3,   -3, ...,   28,  -30,   19]]], dtype=int8)angle_alongship(channel, ping_time, range_sample)int83 2 3 3 3 7 ... 53 -98 -51 -5 37long_name :electrical alongship anglecomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([[[   3,    2,    3, ...,  108,  -91,    1],\n        [   3,    2,    3, ...,  119,   81,   76],\n        [   3,    2,    3, ...,  -15,   10,   60],\n        ...,\n        [   3,    2,    3, ...,   72,  -68,  105],\n        [   3,    2,    3, ...,   11,  -30,  -82],\n        [   3,    2,    3, ...,  -99,  -57,  -75]],\n\n       [[   0,    0,   -1, ...,   10,   92,   58],\n        [   0,    0,   -1, ...,   81,  -65,  102],\n        [   0,    0,   -1, ...,   54,   16,   23],\n        ...,\n        [   0,    0,   -1, ...,    0,  -13,   28],\n        [   0,    0,   -1, ...,   28,   77, -117],\n        [   0,    0,   -1, ...,  -14,   16,   21]],\n\n       [[  -1,   -1,   -1, ...,   66,  -71,   54],\n        [  -1,   -1,   -1, ..., -108,  123,  -51],\n        [  -1,   -1,   -1, ...,   92,   81,  -89],\n        ...,\n        [  -1,   -1,   -1, ...,  114,   74,  -50],\n        [  -1,   -1,   -1, ...,   95,  -58,   50],\n        [  -1,   -1,   -1, ...,  -51,   -5,   37]]], dtype=int8)Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 19:52:19.120310', '2017-07-28 19:52:23.078535',\n               '2017-07-28 19:52:26.898323', '2017-07-28 19:52:30.693539',\n               '2017-07-28 19:52:34.503756', '2017-07-28 19:52:38.321976',\n               '2017-07-28 19:52:42.129192', '2017-07-28 19:52:45.938410',\n               '2017-07-28 19:52:49.745628', '2017-07-28 19:52:53.564848',\n               ...\n               '2017-07-28 20:25:28.984426', '2017-07-28 20:25:32.900650',\n               '2017-07-28 20:25:36.826876', '2017-07-28 20:25:40.742100',\n               '2017-07-28 20:25:44.668324', '2017-07-28 20:25:48.594547',\n               '2017-07-28 20:25:52.519773', '2017-07-28 20:25:56.435997',\n               '2017-07-28 20:26:00.352222', '2017-07-28 20:26:04.278446'],\n              dtype='datetime64[ns]', name='ping_time', length=523, freq=None))range_samplePandasIndexPandasIndex(Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n            ...\n            3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956],\n           dtype='int64', name='range_sample', length=3957))Attributes: (2)beam_mode :verticalconversion_equation_t :type_3\n                        \n                    \n                \n                    Vendor_specific: contains vendor-specific information about the sonar and the data.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (channel: 3, pulse_length_bin: 5)\nCoordinates:\n  * channel            (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18-11' ...\n  * pulse_length_bin   (pulse_length_bin) int64 0 1 2 3 4\nData variables:\n    frequency_nominal  (channel) float64 1.8e+04 3.8e+04 1.2e+05\n    sa_correction      (channel, pulse_length_bin) float64 0.0 -0.7 ... 0.0 -0.3\n    gain_correction    (channel, pulse_length_bin) float64 20.3 22.95 ... 26.55\n    pulse_length       (channel, pulse_length_bin) float64 0.000512 ... 0.001024xarray.DatasetDimensions:channel: 3pulse_length_bin: 5Coordinates: (2)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')pulse_length_bin(pulse_length_bin)int640 1 2 3 4array([0, 1, 2, 3, 4])Data variables: (4)frequency_nominal(channel)float641.8e+04 3.8e+04 1.2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 18000.,  38000., 120000.])sa_correction(channel, pulse_length_bin)float640.0 -0.7 0.0 0.0 ... 0.0 0.0 -0.3array([[ 0.  , -0.7 ,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  , -0.52,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  ,  0.  , -0.3 ]])gain_correction(channel, pulse_length_bin)float6420.3 22.95 22.9 ... 27.0 27.0 26.55array([[20.299999, 22.950001, 22.9     , 23.      , 23.      ],\n       [24.      , 26.      , 26.07    , 26.5     , 26.5     ],\n       [25.5     , 26.799999, 27.      , 27.      , 26.549999]])pulse_length(channel, pulse_length_bin)float640.000512 0.001024 ... 0.001024array([[5.120e-04, 1.024e-03, 2.048e-03, 4.096e-03, 8.192e-03],\n       [2.560e-04, 5.120e-04, 1.024e-03, 2.048e-03, 4.096e-03],\n       [6.400e-05, 1.280e-04, 2.560e-04, 5.120e-04, 1.024e-03]])Indexes: (2)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))pulse_length_binPandasIndexPandasIndex(Int64Index([0, 1, 2, 3, 4], dtype='int64', name='pulse_length_bin'))Attributes: (0)\n                        \n                    \n                \n    \n\n\n\n\nprint(f\"Number of ping times in this EchoData object: {len(ed['Sonar/Beam_group1'].ping_time)}\")\n\nNumber of ping times in this EchoData object: 523\n\n\nAssemble a list of EchoData objects from the converted Zarr files and combine them into a single EchoData object using the combine_echodata function. By default open_converted lazy loads individual Zarr files and only metadata are read into memory, until more operations are executed, which in this case is the combine_echodata function.\n\ned_list = []\nfor converted_file in sorted(base_dpath.glob(\"*.zarr\")):\n    ed_list.append(ep.open_converted(converted_file))\n\ncombined_ed = ep.combine_echodata(ed_list)\n\n\nprint(f\"Number of ping times in the combined EchoData object: {len(combined_ed['Sonar/Beam_group1'].ping_time)}\")\n\nNumber of ping times in the combined EchoData object: 2379\n\n\nThe Provenance group now of the combined EchoData object contains some helpful information compiled from the source files.\n\ncombined_ed['Provenance']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                      (filenames: 5, echodata_filename: 5)\nCoordinates:\n  * filenames                    (filenames) int64 0 1 2 3 4\n  * echodata_filename            (echodata_filename) &lt;U33 'Summer2017-D201707...\nData variables: (12/26)\n    source_filenames             (filenames) &lt;U92 's3://ncei-wcsd-archive/dat...\n    conventions                  (echodata_filename) &lt;U35 'CF-1.7, SONAR-netC...\n    date_created                 (echodata_filename) &lt;U20 '2017-07-28T18:16:1...\n    keywords                     (echodata_filename) &lt;U4 'EK60' ... 'EK60'\n    processing_level             (echodata_filename) &lt;U8 'Level 1A' ... 'Leve...\n    processing_level_url         (echodata_filename) &lt;U64 'https://echopype.r...\n    ...                           ...\n    sonar_serial_number          (echodata_filename) &lt;U1 '' '' '' '' ''\n    sonar_software_name          (echodata_filename) &lt;U4 'ER60' ... 'ER60'\n    sonar_software_version       (echodata_filename) &lt;U5 '2.4.3' ... '2.4.3'\n    sonar_type                   (echodata_filename) &lt;U11 'echosounder' ... '...\n    beam_mode                    (echodata_filename) &lt;U8 'vertical' ... 'vert...\n    conversion_equation_t        (echodata_filename) &lt;U6 'type_3' ... 'type_3'\nAttributes:\n    conversion_software_name:      echopype\n    conversion_software_version:   0.8.4\n    conversion_time:               2024-04-26T16:04:52Z\n    is_combined:                   True\n    combination_software_name:     echopype\n    combination_software_version:  0.8.4\n    combination_time:              2024-04-26T16:05:54Zxarray.DatasetDimensions:filenames: 5echodata_filename: 5Coordinates: (2)filenames(filenames)int640 1 2 3 4long_name :Index for data and metadata source filenamesarray([0, 1, 2, 3, 4])echodata_filename(echodata_filename)&lt;U33'Summer2017-D20170728-T181619.za...array(['Summer2017-D20170728-T181619.zarr',\n       'Summer2017-D20170728-T184131.zarr',\n       'Summer2017-D20170728-T190728.zarr',\n       'Summer2017-D20170728-T193459.zarr',\n       'Summer2017-D20170728-T195219.zarr'], dtype='&lt;U33')Data variables: (26)source_filenames(filenames)&lt;U92's3://ncei-wcsd-archive/data/raw...long_name :Source filenamesarray(['s3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T181619.raw',\n       's3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T184131.raw',\n       's3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T190728.raw',\n       's3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T193459.raw',\n       's3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170728-T195219.raw'],\n      dtype='&lt;U92')conventions(echodata_filename)&lt;U35'CF-1.7, SONAR-netCDF4-1.0, ACDD...echodata_group :Top-levelarray(['CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3',\n       'CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3',\n       'CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3',\n       'CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3',\n       'CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3'], dtype='&lt;U35')date_created(echodata_filename)&lt;U20'2017-07-28T18:16:19Z' ... '2017...echodata_group :Top-levelarray(['2017-07-28T18:16:19Z', '2017-07-28T18:41:31Z',\n       '2017-07-28T19:07:28Z', '2017-07-28T19:34:59Z',\n       '2017-07-28T19:52:19Z'], dtype='&lt;U20')keywords(echodata_filename)&lt;U4'EK60' 'EK60' 'EK60' 'EK60' 'EK60'echodata_group :Top-levelarray(['EK60', 'EK60', 'EK60', 'EK60', 'EK60'], dtype='&lt;U4')processing_level(echodata_filename)&lt;U8'Level 1A' ... 'Level 1A'echodata_group :Top-levelarray(['Level 1A', 'Level 1A', 'Level 1A', 'Level 1A', 'Level 1A'],\n      dtype='&lt;U8')processing_level_url(echodata_filename)&lt;U64'https://echopype.readthedocs.io...echodata_group :Top-levelarray(['https://echopype.readthedocs.io/en/stable/processing-levels.html',\n       'https://echopype.readthedocs.io/en/stable/processing-levels.html',\n       'https://echopype.readthedocs.io/en/stable/processing-levels.html',\n       'https://echopype.readthedocs.io/en/stable/processing-levels.html',\n       'https://echopype.readthedocs.io/en/stable/processing-levels.html'],\n      dtype='&lt;U64')sonar_convention_authority(echodata_filename)&lt;U4'ICES' 'ICES' 'ICES' 'ICES' 'ICES'echodata_group :Top-levelarray(['ICES', 'ICES', 'ICES', 'ICES', 'ICES'], dtype='&lt;U4')sonar_convention_name(echodata_filename)&lt;U13'SONAR-netCDF4' ... 'SONAR-netCDF4'echodata_group :Top-levelarray(['SONAR-netCDF4', 'SONAR-netCDF4', 'SONAR-netCDF4', 'SONAR-netCDF4',\n       'SONAR-netCDF4'], dtype='&lt;U13')sonar_convention_version(echodata_filename)&lt;U3'1.0' '1.0' '1.0' '1.0' '1.0'echodata_group :Top-levelarray(['1.0', '1.0', '1.0', '1.0', '1.0'], dtype='&lt;U3')summary(echodata_filename)&lt;U113'EK60 raw file from the 2017 Pac...echodata_group :Top-levelarray(['EK60 raw file from the 2017 Pacific Hake Acoustic Trawl Survey, converted to a SONAR-netCDF4 file using echopype.',\n       'EK60 raw file from the 2017 Pacific Hake Acoustic Trawl Survey, converted to a SONAR-netCDF4 file using echopype.',\n       'EK60 raw file from the 2017 Pacific Hake Acoustic Trawl Survey, converted to a SONAR-netCDF4 file using echopype.',\n       'EK60 raw file from the 2017 Pacific Hake Acoustic Trawl Survey, converted to a SONAR-netCDF4 file using echopype.',\n       'EK60 raw file from the 2017 Pacific Hake Acoustic Trawl Survey, converted to a SONAR-netCDF4 file using echopype.'],\n      dtype='&lt;U113')title(echodata_filename)&lt;U39'2017 Pacific Hake Acoustic Traw...echodata_group :Top-levelarray(['2017 Pacific Hake Acoustic Trawl Survey',\n       '2017 Pacific Hake Acoustic Trawl Survey',\n       '2017 Pacific Hake Acoustic Trawl Survey',\n       '2017 Pacific Hake Acoustic Trawl Survey',\n       '2017 Pacific Hake Acoustic Trawl Survey'], dtype='&lt;U39')platform_code_ICES(echodata_filename)&lt;U3'315' '315' '315' '315' '315'echodata_group :Platformarray(['315', '315', '315', '315', '315'], dtype='&lt;U3')platform_name(echodata_filename)&lt;U15'Bell M. Shimada' ... 'Bell M. S...echodata_group :Platformarray(['Bell M. Shimada', 'Bell M. Shimada', 'Bell M. Shimada',\n       'Bell M. Shimada', 'Bell M. Shimada'], dtype='&lt;U15')platform_type(echodata_filename)&lt;U15'Research vessel' ... 'Research ...echodata_group :Platformarray(['Research vessel', 'Research vessel', 'Research vessel',\n       'Research vessel', 'Research vessel'], dtype='&lt;U15')description(echodata_filename)&lt;U25'All NMEA sensor datagrams' ... ...echodata_group :Platform/NMEAarray(['All NMEA sensor datagrams', 'All NMEA sensor datagrams',\n       'All NMEA sensor datagrams', 'All NMEA sensor datagrams',\n       'All NMEA sensor datagrams'], dtype='&lt;U25')conversion_software_name(echodata_filename)&lt;U8'echopype' ... 'echopype'echodata_group :Provenancearray(['echopype', 'echopype', 'echopype', 'echopype', 'echopype'],\n      dtype='&lt;U8')conversion_software_version(echodata_filename)&lt;U5'0.8.4' '0.8.4' ... '0.8.4' '0.8.4'echodata_group :Provenancearray(['0.8.4', '0.8.4', '0.8.4', '0.8.4', '0.8.4'], dtype='&lt;U5')conversion_time(echodata_filename)&lt;U20'2024-04-26T16:04:52Z' ... '2024...echodata_group :Provenancearray(['2024-04-26T16:04:52Z', '2024-04-26T16:05:04Z',\n       '2024-04-26T16:05:16Z', '2024-04-26T16:05:28Z',\n       '2024-04-26T16:05:40Z'], dtype='&lt;U20')sonar_manufacturer(echodata_filename)&lt;U6'Simrad' 'Simrad' ... 'Simrad'echodata_group :Sonararray(['Simrad', 'Simrad', 'Simrad', 'Simrad', 'Simrad'], dtype='&lt;U6')sonar_model(echodata_filename)&lt;U4'EK60' 'EK60' 'EK60' 'EK60' 'EK60'echodata_group :Sonararray(['EK60', 'EK60', 'EK60', 'EK60', 'EK60'], dtype='&lt;U4')sonar_serial_number(echodata_filename)&lt;U1'' '' '' '' ''echodata_group :Sonararray(['', '', '', '', ''], dtype='&lt;U1')sonar_software_name(echodata_filename)&lt;U4'ER60' 'ER60' 'ER60' 'ER60' 'ER60'echodata_group :Sonararray(['ER60', 'ER60', 'ER60', 'ER60', 'ER60'], dtype='&lt;U4')sonar_software_version(echodata_filename)&lt;U5'2.4.3' '2.4.3' ... '2.4.3' '2.4.3'echodata_group :Sonararray(['2.4.3', '2.4.3', '2.4.3', '2.4.3', '2.4.3'], dtype='&lt;U5')sonar_type(echodata_filename)&lt;U11'echosounder' ... 'echosounder'echodata_group :Sonararray(['echosounder', 'echosounder', 'echosounder', 'echosounder',\n       'echosounder'], dtype='&lt;U11')beam_mode(echodata_filename)&lt;U8'vertical' ... 'vertical'echodata_group :Sonar/Beam_group1array(['vertical', 'vertical', 'vertical', 'vertical', 'vertical'],\n      dtype='&lt;U8')conversion_equation_t(echodata_filename)&lt;U6'type_3' 'type_3' ... 'type_3'echodata_group :Sonar/Beam_group1array(['type_3', 'type_3', 'type_3', 'type_3', 'type_3'], dtype='&lt;U6')Indexes: (2)filenamesPandasIndexPandasIndex(Int64Index([0, 1, 2, 3, 4], dtype='int64', name='filenames'))echodata_filenamePandasIndexPandasIndex(Index(['Summer2017-D20170728-T181619.zarr',\n       'Summer2017-D20170728-T184131.zarr',\n       'Summer2017-D20170728-T190728.zarr',\n       'Summer2017-D20170728-T193459.zarr',\n       'Summer2017-D20170728-T195219.zarr'],\n      dtype='object', name='echodata_filename'))Attributes: (7)conversion_software_name :echopypeconversion_software_version :0.8.4conversion_time :2024-04-26T16:04:52Zis_combined :Truecombination_software_name :echopypecombination_software_version :0.8.4combination_time :2024-04-26T16:05:54Z"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/echopype_tour.html#extract-and-plot-gps-locations-from-platform-group",
    "href": "topics-2024/2024-04-26-echopype/echopype_tour.html#extract-and-plot-gps-locations-from-platform-group",
    "title": "echopype Tour",
    "section": "Extract and plot GPS locations from Platform group",
    "text": "Extract and plot GPS locations from Platform group\nExtract and join the latitude and longitude variables from the Platform group in the combined_ed EchoData object. Convert to a Pandas DataFrame first, then to a GeoPandas GeoDataFrame for convenient viewing and manipulation.\n\ngps_df = combined_ed['Platform'].latitude.to_dataframe().join(combined_ed['Platform'].longitude.to_dataframe())\ngps_df.head(3)\n\n\n\n\n\n\n\n\nlatitude\nlongitude\n\n\ntime1\n\n\n\n\n\n\n2017-07-28 18:16:21.476992\n43.657532\n-124.887015\n\n\n2017-07-28 18:16:21.635323\n43.657500\n-124.887000\n\n\n2017-07-28 18:16:22.169931\n43.657532\n-124.887080\n\n\n\n\n\n\n\n\ngps_gdf = gpd.GeoDataFrame(\n    gps_df,\n    geometry=gpd.points_from_xy(gps_df['longitude'], gps_df['latitude']), \n    crs=\"epsg:4326\"\n)\n\nCreate a cartopy reference map from the point GeoDataFrame, to place the GPS track in its geographical context.\n\nbasemap = cimgt.OSM()\n_, ax = plt.subplots(\n    figsize=(7, 7), subplot_kw={\"projection\": basemap.crs}\n)\nbnd = gps_gdf.geometry.bounds\nax.set_extent([bnd.minx.min() - 1, bnd.maxx.max() + 3, \n               bnd.miny.min() - 1, bnd.maxy.max() + 2])\nax.add_image(basemap, 7)\nax.gridlines(draw_labels=True, xformatter=LONGITUDE_FORMATTER, yformatter=LATITUDE_FORMATTER)\ngps_gdf.plot(ax=ax, markersize=0.1, color='red', \n             transform=ccrs.PlateCarree());"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/echopype_tour.html#compute-mean-volume-backscattering-strength-textmvbs-and-plot-interactive-echograms-using-hvplot",
    "href": "topics-2024/2024-04-26-echopype/echopype_tour.html#compute-mean-volume-backscattering-strength-textmvbs-and-plot-interactive-echograms-using-hvplot",
    "title": "echopype Tour",
    "section": "Compute mean volume backscattering strength (\\(\\text{MVBS}\\)) and plot interactive echograms using hvplot",
    "text": "Compute mean volume backscattering strength (\\(\\text{MVBS}\\)) and plot interactive echograms using hvplot\nechopype supports basic processing funcionalities including calibration (from raw instrument data records to volume backscattering strength, \\(S_V\\)), denoising, and computing mean volume backscattering strength, \\(\\overline{S_V}\\) or \\(\\text{MVBS}\\). The EchoData object can be passed into various calibration and preprocessing functions without having to write out any intermediate files.\nWe’ll calibrate the combined backscatter data to obtain \\(S_V\\). For EK60 data, by default the function uses environmental (sound speed and absorption) and calibration parameters stored in the data file. Users can optionally specify other parameter choices. \\(S_V\\) is then binned along range (depth) and ping time to generate \\(\\text{MVBS}\\).\n\nSv_ds = ep.calibrate.compute_Sv(combined_ed).compute()\nMVBS_ds = ep.commongrid.compute_MVBS(\n    Sv_ds,\n    range_bin= '5m',  # in meters\n    ping_time_bin='20s'  # in seconds\n)\n\n\nSv_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                        (channel: 3, ping_time: 2379,\n                                    range_sample: 3957, filenames: 1)\nCoordinates:\n  * channel                        (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1...\n  * ping_time                      (ping_time) datetime64[ns] 2017-07-28T18:1...\n  * range_sample                   (range_sample) int64 0 1 2 ... 3954 3955 3956\n  * filenames                      (filenames) int64 0\nData variables: (12/16)\n    Sv                             (channel, ping_time, range_sample) float64 ...\n    echo_range                     (channel, ping_time, range_sample) float64 ...\n    frequency_nominal              (channel) float64 1.8e+04 3.8e+04 1.2e+05\n    sound_speed                    (channel, ping_time) float64 1.481e+03 ......\n    sound_absorption               (channel, ping_time) float64 0.002822 ... ...\n    sa_correction                  (channel, ping_time) float64 -0.7 ... -0.3\n    ...                             ...\n    angle_sensitivity_alongship    (channel) float64 13.89 21.97 23.12\n    angle_sensitivity_athwartship  (channel) float64 13.89 21.97 23.12\n    beamwidth_alongship            (channel) float64 10.9 6.81 6.58\n    beamwidth_athwartship          (channel) float64 10.82 6.85 6.52\n    source_filenames               (filenames) &lt;U26 'SOURCE FILE NOT IDENTIFIED'\n    water_level                    float64 9.15\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.4\n    processing_time:              2024-04-26T16:05:57Z\n    processing_function:          calibrate.compute_Svxarray.DatasetDimensions:channel: 3ping_time: 2379range_sample: 3957filenames: 1Coordinates: (4)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')ping_time(ping_time)datetime64[ns]2017-07-28T18:16:19.314791 ... 2...axis :Tlong_name :Timestamp of each pingstandard_name :timearray(['2017-07-28T18:16:19.314791000', '2017-07-28T18:16:22.143955000',\n       '2017-07-28T18:16:24.963251000', ..., '2017-07-28T20:25:56.435997000',\n       '2017-07-28T20:26:00.352222000', '2017-07-28T20:26:04.278446000'],\n      dtype='datetime64[ns]')range_sample(range_sample)int640 1 2 3 4 ... 3953 3954 3955 3956long_name :Along-range sample number, base 0array([   0,    1,    2, ..., 3954, 3955, 3956])filenames(filenames)int640long_name :Index for data and metadata source filenamesarray([0])Data variables: (16)Sv(channel, ping_time, range_sample)float64nan nan nan ... -51.8 -49.56 -49.11long_name :Volume backscattering strength (Sv re 1 m-1)units :dBactual_range :[-165.1, 9.3]array([[[          nan,           nan,           nan, ...,\n          -98.8814902 , -100.19522443,  -93.13656847],\n        [          nan,           nan,           nan, ...,\n          -98.62279269,  -99.73662152,  -87.69215624],\n        [          nan,           nan,           nan, ...,\n          -95.01277682,  -95.84439435,  -99.89798204],\n        ...,\n        [          nan,           nan,           nan, ...,\n          -94.00150057,  -95.60922589, -105.09544603],\n        [          nan,           nan,           nan, ...,\n          -95.31851717,  -94.50387921,  -96.11158983],\n        [          nan,           nan,           nan, ...,\n         -108.45329806,  -94.35100141,  -99.99205248]],\n\n       [[          nan,           nan,           nan, ...,\n          -91.17684394,  -95.33360004, -100.91317774],\n        [          nan,           nan,           nan, ...,\n         -103.06518012, -101.74224567, -100.81910731],\n        [          nan,           nan,           nan, ...,\n          -95.46888191,  -87.10230732,  -93.55204798],\n...\n        [          nan,           nan,           nan, ...,\n          -80.6995948 ,  -88.87791157,  -86.72007777],\n        [          nan,           nan,           nan, ...,\n          -87.26110297,  -96.52125263, -110.21453883],\n        [          nan,           nan,           nan, ...,\n          -87.02591926,  -91.47665119, -100.24292017]],\n\n       [[          nan,           nan,           nan, ...,\n          -68.69306027,  -48.58240849,  -51.66046271],\n        [          nan,           nan,           nan, ...,\n          -71.3741058 ,  -50.80485112,  -46.0514234 ],\n        [          nan,           nan,           nan, ...,\n          -54.33533322,  -55.7201038 ,  -58.33957037],\n        ...,\n        [          nan,           nan,           nan, ...,\n          -56.26381528,  -50.66373784,  -49.23811469],\n        [          nan,           nan,           nan, ...,\n          -45.974707  ,  -55.02633244,  -51.03723273],\n        [          nan,           nan,           nan, ...,\n          -51.79540097,  -49.55840642,  -49.10876593]]])echo_range(channel, ping_time, range_sample)float640.0 0.1895 0.379 ... 749.6 749.7long_name :Range distanceunits :marray([[[0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        ...,\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02]],\n\n       [[0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n...\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02]],\n\n       [[0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        ...,\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02],\n        [0.00000000e+00, 1.89520125e-01, 3.79040249e-01, ...,\n         7.49362572e+02, 7.49552092e+02, 7.49741613e+02]]])frequency_nominal(channel)float641.8e+04 3.8e+04 1.2e+05long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0array([ 18000.,  38000., 120000.])sound_speed(channel, ping_time)float641.481e+03 1.481e+03 ... 1.481e+03long_name :Indicative sound speedstandard_name :speed_of_sound_in_sea_waterunits :m/svalid_min :0.0array([[1480.62597656, 1480.62597656, 1480.62597656, ..., 1480.62597656,\n        1480.62597656, 1480.62597656],\n       [1480.62597656, 1480.62597656, 1480.62597656, ..., 1480.62597656,\n        1480.62597656, 1480.62597656],\n       [1480.62597656, 1480.62597656, 1480.62597656, ..., 1480.62597656,\n        1480.62597656, 1480.62597656]])sound_absorption(channel, ping_time)float640.002822 0.002822 ... 0.03259long_name :Indicative acoustic absorptionunits :dB/mvalid_min :0.0array([[0.00282171, 0.00282171, 0.00282171, ..., 0.00282171, 0.00282171,\n        0.00282171],\n       [0.00985526, 0.00985526, 0.00985526, ..., 0.00985526, 0.00985526,\n        0.00985526],\n       [0.03259379, 0.03259379, 0.03259379, ..., 0.03259379, 0.03259379,\n        0.03259379]])sa_correction(channel, ping_time)float64-0.7 -0.7 -0.7 ... -0.3 -0.3 -0.3array([[-0.7 , -0.7 , -0.7 , ..., -0.7 , -0.7 , -0.7 ],\n       [-0.52, -0.52, -0.52, ..., -0.52, -0.52, -0.52],\n       [-0.3 , -0.3 , -0.3 , ..., -0.3 , -0.3 , -0.3 ]])gain_correction(channel, ping_time)float6422.95 22.95 22.95 ... 26.55 26.55array([[22.950001, 22.950001, 22.950001, ..., 22.950001, 22.950001,\n        22.950001],\n       [26.07    , 26.07    , 26.07    , ..., 26.07    , 26.07    ,\n        26.07    ],\n       [26.549999, 26.549999, 26.549999, ..., 26.549999, 26.549999,\n        26.549999]])equivalent_beam_angle(channel)float64-17.37 -21.01 -20.47long_name :Equivalent beam angleunits :srvalid_range :[0.0, 12.566370614359172]array([-17.37000084, -21.01000023, -20.46999931])angle_offset_alongship(channel)float64-0.18 -0.08 -0.05comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :electrical alongship angle offset of the transducerarray([-0.18000001, -0.08      , -0.05      ])angle_offset_athwartship(channel)float640.25 0.0 0.37comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :electrical athwartship angle offset of the transducerarray([0.25, 0.  , 0.37])angle_sensitivity_alongship(channel)float6413.89 21.97 23.12comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :alongship angle sensitivity of the transducerarray([13.89000034, 21.96999931, 23.12000084])angle_sensitivity_athwartship(channel)float6413.89 21.97 23.12comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :athwartship angle sensitivity of the transducerarray([13.89000034, 21.96999931, 23.12000084])beamwidth_alongship(channel)float6410.9 6.81 6.58comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_minor and beamwidth_transmit_minor), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along alongship axis of beamunits :arc_degreevalid_range :[0.0, 360.0]array([10.89999962,  6.80999994,  6.57999992])beamwidth_athwartship(channel)float6410.82 6.85 6.52comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_major and beamwidth_transmit_major), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along athwartship axis of beamunits :arc_degreevalid_range :[0.0, 360.0]array([10.81999969,  6.8499999 ,  6.51999998])source_filenames(filenames)&lt;U26'SOURCE FILE NOT IDENTIFIED'long_name :Source filenamesarray(['SOURCE FILE NOT IDENTIFIED'], dtype='&lt;U26')water_level()float649.15long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(9.14999962)Indexes: (4)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 18:16:19.314791', '2017-07-28 18:16:22.143955',\n               '2017-07-28 18:16:24.963251', '2017-07-28 18:16:27.769411',\n               '2017-07-28 18:16:30.586573', '2017-07-28 18:16:33.394732',\n               '2017-07-28 18:16:36.211893', '2017-07-28 18:16:39.030056',\n               '2017-07-28 18:16:41.850218', '2017-07-28 18:16:44.657377',\n               ...\n               '2017-07-28 20:25:28.984426', '2017-07-28 20:25:32.900650',\n               '2017-07-28 20:25:36.826876', '2017-07-28 20:25:40.742100',\n               '2017-07-28 20:25:44.668324', '2017-07-28 20:25:48.594547',\n               '2017-07-28 20:25:52.519773', '2017-07-28 20:25:56.435997',\n               '2017-07-28 20:26:00.352222', '2017-07-28 20:26:04.278446'],\n              dtype='datetime64[ns]', name='ping_time', length=2379, freq=None))range_samplePandasIndexPandasIndex(Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n            ...\n            3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956],\n           dtype='int64', name='range_sample', length=3957))filenamesPandasIndexPandasIndex(Int64Index([0], dtype='int64', name='filenames'))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.4processing_time :2024-04-26T16:05:57Zprocessing_function :calibrate.compute_Sv\n\n\n\nMVBS_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:            (channel: 3, ping_time: 391, echo_range: 150)\nCoordinates:\n  * ping_time          (ping_time) datetime64[ns] 2017-07-28T18:16:00 ... 201...\n  * channel            (channel) &lt;U37 'GPT  18 kHz 009072058c8d 1-1 ES18-11' ...\n  * echo_range         (echo_range) float64 0.0 5.0 10.0 ... 735.0 740.0 745.0\nData variables:\n    Sv                 (channel, ping_time, echo_range) float64 -15.13 ... -5...\n    water_level        float64 9.15\n    frequency_nominal  (channel) float64 1.8e+04 3.8e+04 1.2e+05\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.4\n    processing_time:              2024-04-26T16:06:00Z\n    processing_function:          commongrid.compute_MVBSxarray.DatasetDimensions:channel: 3ping_time: 391echo_range: 150Coordinates: (3)ping_time(ping_time)datetime64[ns]2017-07-28T18:16:00 ... 2017-07-...long_name :Ping timestandard_name :timeaxis :Tarray(['2017-07-28T18:16:00.000000000', '2017-07-28T18:16:20.000000000',\n       '2017-07-28T18:16:40.000000000', ..., '2017-07-28T20:25:20.000000000',\n       '2017-07-28T20:25:40.000000000', '2017-07-28T20:26:00.000000000'],\n      dtype='datetime64[ns]')channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')echo_range(echo_range)float640.0 5.0 10.0 ... 735.0 740.0 745.0long_name :Range distanceunits :marray([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,  55.,\n        60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105., 110., 115.,\n       120., 125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175.,\n       180., 185., 190., 195., 200., 205., 210., 215., 220., 225., 230., 235.,\n       240., 245., 250., 255., 260., 265., 270., 275., 280., 285., 290., 295.,\n       300., 305., 310., 315., 320., 325., 330., 335., 340., 345., 350., 355.,\n       360., 365., 370., 375., 380., 385., 390., 395., 400., 405., 410., 415.,\n       420., 425., 430., 435., 440., 445., 450., 455., 460., 465., 470., 475.,\n       480., 485., 490., 495., 500., 505., 510., 515., 520., 525., 530., 535.,\n       540., 545., 550., 555., 560., 565., 570., 575., 580., 585., 590., 595.,\n       600., 605., 610., 615., 620., 625., 630., 635., 640., 645., 650., 655.,\n       660., 665., 670., 675., 680., 685., 690., 695., 700., 705., 710., 715.,\n       720., 725., 730., 735., 740., 745.])Data variables: (3)Sv(channel, ping_time, echo_range)float64-15.13 -73.94 ... -50.64 -51.18long_name :Mean volume backscattering strength (MVBS, mean Sv re 1 m-1)units :dBactual_range :[-100.73, -1.67]cell_methods :ping_time: mean (interval: 20 second comment: ping_time is the interval start) echo_range: mean (interval: 5.0 meter comment: echo_range is the interval start)binning_mode :physical unitsrange_meter_interval :5.0mping_time_interval :20sarray([[[-15.12755105, -73.93975947, -75.74086907, ..., -93.03124081,\n         -87.02957209, -90.30810872],\n        [-15.13058841, -74.52868038, -75.98431574, ..., -90.5690002 ,\n         -87.94549366, -89.58626984],\n        [-15.12958206, -74.38786876, -76.12919869, ..., -85.76499213,\n         -91.65698849, -88.49834984],\n        ...,\n        [-15.13839927, -72.72861208, -70.57554807, ..., -90.68965523,\n         -90.18589901, -89.85266089],\n        [-15.13839871, -73.40887546, -71.53144589, ..., -86.52093706,\n         -90.71777208, -87.64862994],\n        [-15.13932726, -74.81824587, -72.0065677 , ..., -90.24106793,\n         -90.15103191, -93.05420488]],\n\n       [[-10.75980127, -72.34105201, -74.54237123, ..., -83.95164854,\n         -91.77006804, -92.60016908],\n        [-10.75916309, -72.46743574, -74.39065032, ..., -87.34469437,\n         -91.030697  , -91.45743269],\n        [-10.75661285, -71.85014821, -72.02975436, ..., -89.96313605,\n         -91.9425157 , -89.53742718],\n...\n        [-10.75890029, -64.45446892, -60.89731531, ..., -89.13387326,\n         -89.223176  , -89.89205309],\n        [-10.75888588, -66.07530203, -61.38727711, ..., -88.36793762,\n         -91.46099879, -90.27813254],\n        [-10.75979404, -65.52028556, -59.86088553, ..., -92.64408601,\n         -93.54302178, -89.32144523]],\n\n       [[ -1.67282374, -62.71791101, -64.36119162, ..., -50.0234789 ,\n         -49.46005503, -51.11570652],\n        [ -1.67121509, -64.26188288, -63.39382457, ..., -51.4255711 ,\n         -50.03031324, -50.57221522],\n        [ -1.6704099 , -64.61572799, -63.39782062, ..., -51.85364677,\n         -51.19651354, -51.05297295],\n        ...,\n        [ -1.66831095, -63.00943992, -64.01089954, ..., -50.94176909,\n         -50.8757988 , -49.921782  ],\n        [ -1.66944116, -62.79660958, -64.01665757, ..., -51.14671829,\n         -51.31675455, -50.39075499],\n        [ -1.67000329, -61.49884016, -63.58243215, ..., -50.95437822,\n         -50.64152543, -51.1839124 ]]])water_level()float649.15long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(9.14999962)frequency_nominal(channel)float641.8e+04 3.8e+04 1.2e+05long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0array([ 18000.,  38000., 120000.])Indexes: (3)ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 18:16:00', '2017-07-28 18:16:20',\n               '2017-07-28 18:16:40', '2017-07-28 18:17:00',\n               '2017-07-28 18:17:20', '2017-07-28 18:17:40',\n               '2017-07-28 18:18:00', '2017-07-28 18:18:20',\n               '2017-07-28 18:18:40', '2017-07-28 18:19:00',\n               ...\n               '2017-07-28 20:23:00', '2017-07-28 20:23:20',\n               '2017-07-28 20:23:40', '2017-07-28 20:24:00',\n               '2017-07-28 20:24:20', '2017-07-28 20:24:40',\n               '2017-07-28 20:25:00', '2017-07-28 20:25:20',\n               '2017-07-28 20:25:40', '2017-07-28 20:26:00'],\n              dtype='datetime64[ns]', name='ping_time', length=391, freq=None))channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))echo_rangePandasIndexPandasIndex(Float64Index([  0.0,   5.0,  10.0,  15.0,  20.0,  25.0,  30.0,  35.0,  40.0,\n               45.0,\n              ...\n              700.0, 705.0, 710.0, 715.0, 720.0, 725.0, 730.0, 735.0, 740.0,\n              745.0],\n             dtype='float64', name='echo_range', length=150))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.4processing_time :2024-04-26T16:06:00Zprocessing_function :commongrid.compute_MVBS\n\n\nReplace the channel dimension and coordinate with the frequency_nominal variable containing actual frequency values. Note that this step is possible only because there are no duplicated frequencies present.\n\nMVBS_ds = ep.consolidate.swap_dims_channel_frequency(MVBS_ds)\n\nList the three frequencies used by the echosounder\n\nMVBS_ds.frequency_nominal.values\n\narray([ 18000.,  38000., 120000.])\n\n\nGenerate an interactive plot of the three \\(\\text{MVBS}\\) echograms, one for each frequency. The frequency can be changed via the slider widget.\n\nMVBS_ds[\"Sv\"].hvplot.image(\n    x='ping_time', y='echo_range', \n    color='Sv', rasterize=True, \n    cmap='jet', clim=(-80, -50),\n    xlabel='Time (UTC)',\n    ylabel='Depth (m)'\n).options(width=500, invert_yaxis=True)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/echopype_tour.html#package-versions",
    "href": "topics-2024/2024-04-26-echopype/echopype_tour.html#package-versions",
    "title": "echopype Tour",
    "section": "Package versions",
    "text": "Package versions\n\nimport datetime\nimport numba, numpy, datashader, holoviews, s3fs, aiobotocore, botocore\nprint(f\"echopype: {ep.__version__}\")\nprint(\n    f\"numpy: {numpy.__version__}, numba: {numba.__version__}, xarray: {xr.__version__}, geopandas: {gpd.__version__}\\n\"\n    f\"fsspec: {fsspec.__version__}, s3fs: {s3fs.__version__}, aiobotocore: {aiobotocore.__version__}, botocore: {botocore.__version__}\\n\"\n    f\"datashader: {datashader.__version__}, holoviews: {holoviews.__version__}, hvplot: {hvplot.__version__}\"\n)\n\nprint(f\"\\n{datetime.datetime.utcnow()} +00:00\")\n\nechopype: 0.8.4\nnumpy: 1.26.3, numba: 0.58.1, xarray: 2023.12.0, geopandas: 0.14.2\nfsspec: 2023.12.2, s3fs: 2023.12.2, aiobotocore: 2.9.0, botocore: 1.33.13\ndatashader: 0.16.1, holoviews: 1.18.3, hvplot: 0.9.2\n\n2024-04-26 16:06:01.346987 +00:00"
  },
  {
    "objectID": "topics-2024/2024-04-19-dask/Parallel_compute_coiled.html",
    "href": "topics-2024/2024-04-19-dask/Parallel_compute_coiled.html",
    "title": "Run simple coiled example",
    "section": "",
    "text": "Run simple example with coiled\nThis will spin up virtual machines on our behalf.\nSet-up\n\nGo to coiled.io and set-up an account\n\nYou need to associate it with a cloud account on AWS, Azure or GCP (Google). You can get a free 12 month trial on these.\nI find the Google Cloud dashboard more intuitive to use. But the set up for coiled was difficult. I had to do it from my computer using Python and then it asked for me to install Google Cloud sdk CLI. I stopped at that point.\nAWS was easier. I already had a AWS account. I clicked buttons on coiled.io, logged into AWS as instructed, and got it linked.\n\nNow back to the Jupyter notebook.\n\nGo to a terminal and make sure you are in the same conda environment that you will run your notebook in\nRun coiled setup aws. I assume you have coiled module installed. If not do pip install coiled.\nIt is going to send you to the AWS Cloud Shell and will give you a link for that.\nIt will give you some code to run in the shell. Note I had to clean up the code to remove some extra spaces. I couldn’t just paste and run.\nWhen it is good, it will say it is authenticated.\n\nNow run `coiled\n\nExample of the output\n(coiled) jovyan@jupyter-eeholmes:~$ coiled setup aws\n╭────────────────────────────────────────────────────────────────────────────────────────╮\n│ Introduction                                                                           │\n│                                                                                        │\n│ This uses your AWS credentials to set up Coiled.                                       │\n│                                                                                        │\n│ This will do the following ...                                                         │\n│ 1. Create limited IAM roles and grant them to Coiled                                   │\n│ 2. Check and expand your AWS quota if needed                                           │\n│ 3. Create initial resources to deploy clusters                                         │\n│                                                                                        │\n│ This will not ...                                                                      │\n│ 1. Create resources that cost money                                                    │\n│ 2. Grant Coiled access to your data                                                    │\n╰────────────────────────────────────────────────────────────────────────────────────────╯\nMissing: You don't have local AWS credentials.\nThat's ok, you can run setup from AWS CloudShell.\n\nRun setup from AWS CloudShell with the following steps:\n\n1. Go to https://console.aws.amazon.com/cloudshell\n2. Sign in to your AWS account\n   (if you usually switch role or profile, you should do this)\n3. Run the following command in CloudShell:\n\n  pip3 install coiled && \\\n  coiled login \\\n    --token b2bfb56 \\\n    --token 42713203-d \\\n    --token b82f66c && \\\n  coiled setup aws --region us-east-1\nNow that we have coiled set up, we can run a coiled cluster in Python.\n\n# import needed modules\nimport time, random\n\n# define our functions\ndef inc(x):\n    time.sleep(random.random())\n    return x + 1\n\ndef dec(x):\n    time.sleep(random.random())\n    return x - 1\n\ndef add(x, y):\n    time.sleep(random.random())\n    return x + y\n\n\n%%time\n\n# a sequential example with no parallelization\nresults = []\nfor x in range(20):\n    result = inc(x)\n    result = dec(result)\n    results.append(result)\n\nprint(results)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\nCPU times: user 0 ns, sys: 3.51 ms, total: 3.51 ms\nWall time: 22.5 s\n\n\n\nimport coiled # use a Coiled cluster\n\nSet up cluster in the cloud where we can grab more workers. These 15 workers will cost about 5 cents a minute and this job from start (set-up) to finish is like 5 minutes so 25 cents. Almost all the time is the set-up of the workers. You can go to your dashboard on coiled to see how much compute time you used up.\n\ncluster = coiled.Cluster(n_workers=15) # run on a cluster in the cloud\nclient = cluster.get_client()\n\n\n\n\nmyst-parser 0.18.1 has requirement mdit-py-plugins~=0.3.1, but you have mdit-py-plugins 0.4.0.\n\n\n\nPackage - myst-parser, Pip check had the following issues that need resolving: \nmyst-parser 0.18.1 has requirement mdit-py-plugins~=0.3.1, but you have mdit-py-plugins 0.4.0.\n\n\n\n\n\n\n╭──────────────────────────────── Package Info ────────────────────────────────╮\n│                            ╷                                                 │\n│   Package                  │ Note                                            │\n│ ╶──────────────────────────┼───────────────────────────────────────────────╴ │\n│   coiled_local_jovyan      │ Source wheel built from /home/jovyan            │\n│                            ╵                                                 │\n╰──────────────────────────────────────────────────────────────────────────────╯\n\n\n\n╭────────────────────────── Not Synced with Cluster ───────────────────────────╮\n│               ╷                                                  ╷           │\n│   Package     │ Error                                            │ Risk      │\n│ ╶─────────────┼──────────────────────────────────────────────────┼─────────╴ │\n│   myst-parser │ Pip check had the following issues that need     │ Warning   │\n│               │ resolving:                                       │           │\n│               │ myst-parser 0.18.1 has requirement               │           │\n│               │ mdit-py-plugins~=0.3.1, but you have             │           │\n│               │ mdit-py-plugins 0.4.0.                           │           │\n│               ╵                                                  ╵           │\n╰──────────────────────────────────────────────────────────────────────────────╯\n\n\n\n\n\n\n\n\n\n\n%%time\nresults = []\nfor x in range(20): # scale 100x\n    result = client.submit(inc, x)\n    result = client.submit(dec, result)\n    results.append(result)\n\nresults = client.gather(results)\nprint(results)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\nCPU times: user 140 ms, sys: 1.54 ms, total: 141 ms\nWall time: 2.18 s\n\n\n\n# Close our cluster as soon as we are done because running it uses $\nclient.close()\ncluster.close()"
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Intro_to_Cloud_Python.html",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Intro_to_Cloud_Python.html",
    "title": "Introduction to Geospatial Analyses in Python in the Cloud",
    "section": "",
    "text": "This is based on the “Examining Environmental Justice through Open Source, Cloud-Native Tools” notebook from Carl Boettiger. Please follow Carl’s notebook for the background. This tutorial just focuses on the code."
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Intro_to_Cloud_Python.html#data-discovery",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Intro_to_Cloud_Python.html#data-discovery",
    "title": "Introduction to Geospatial Analyses in Python in the Cloud",
    "section": "Data discovery",
    "text": "Data discovery\nHere we use a STAC Catalog API to recover a list of candidate data. This example searches for images in a lon-lat bounding box from a collection of Cloud-Optimized-GeoTIFF (COG) images taken by Sentinel2 satellite mission. This function will not download any imagery, it merely gives us a list of metadata about available images.\n\nbox = [-122.51, 37.71, -122.36, 37.81]\nitems = (\n  Client.\n  open(\"https://earth-search.aws.element84.com/v1\").\n  search(\n    collections = ['sentinel-2-l2a'],\n    bbox = box,\n    datetime = \"2022-06-01/2022-08-01\",\n    query={\"eo:cloud_cover\": {\"lt\": 20}}).\n  item_collection()\n)\n\nWe pass this list of images to a high-level utilty (gdalcubes) that will do all of the heavy lifting:\n\nsubsetting by date\nsubsetting by bounding box\naggregating by time P1D\nreproject into the desired coordinate system\nresampling to a desired spatial resolution\n\n\ndata = odc.stac.load(\n    items,\n    crs=\"EPSG:4326\",\n    bands=[\"nir08\", \"red\"],\n    resolution=0.0001,\n    bbox=box\n)\n\nCalculate NDVI, a widely used measure of greenness that can be used to determine tree cover.\n\nred = data.red\nnir = data.nir08\n\nndvi = (((nir - red) / (red + nir)).\n        resample(time=\"MS\").\n        median(\"time\", keep_attrs=True).\n        compute()\n)\n\n# mask out bad pixels\nndvi = ndvi.where(ndvi &lt;= 1)\n\nPlot the result. The long rectangle of Golden Gate Park is clearly visible in the North-West.\n\nimport matplotlib as plt\ncmap = plt.colormaps.get_cmap('viridis')  # viridis is the default colormap for imshow\ncmap.set_bad(color='black')\n\nndvi.plot.imshow(row=\"time\", cmap=cmap, add_colorbar=False, size=5)\n\n\n\n\n\n\n\n\nAdd the 1937 “red-lining” zones from the Mapping Inequality project. The red-lined zones are spatial vectors.\n\nndvi.rio.to_raster(raster_path=\"ndvi.tif\", driver=\"COG\")\nsf_url = \"/vsicurl/https://dsl.richmond.edu/panorama/redlining/static/citiesData/CASanFrancisco1937/geojson.json\"\nmean_ndvi = zonal_stats(sf_url, \"ndvi.tif\", stats=\"mean\")\n\nNow we can plot\n\nsf = gpd.read_file(sf_url)\nsf[\"ndvi\"] = [x[\"mean\"] for x in mean_ndvi ]\nsf.plot(column=\"ndvi\", legend=True)\n\n\n\n\n\n\n\n\nCompute the mean current greenness by 1937 zone.\n\nimport geopolars as gpl\nimport polars as pl\n\n(gpl.\n  from_geopandas(sf).\n  group_by(\"grade\").\n  agg(pl.col(\"ndvi\").mean()).\n  sort(\"grade\")\n)\n\n\nshape: (5, 2)\n\n\n\ngrade\nndvi\n\n\nstr\nf64\n\n\n\n\nnull\n0.157821\n\n\n\"A\"\n0.338723\n\n\n\"B\"\n0.247344\n\n\n\"C\"\n0.231182\n\n\n\"D\"\n0.225696"
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#summary",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#summary",
    "title": "Data discovery with earthaccess",
    "section": "Summary",
    "text": "Summary\nIn this example we will use the earthaccess library to search for data collections from NASA Earthdata. earthaccess is a Python library that simplifies data discovery and access to NASA Earth science data by providing an abstraction layer for NASA’s Common Metadata Repository (CMR) API Search API. The library makes searching for data more approachable by using a simpler notation instead of low level HTTP queries. earthaccess takes the trouble out of Earthdata Login authentication, makes search easier, and provides a stream-line way to download or stream search results into an xarray object.\nFor more on earthaccess visit the earthaccess GitHub page and/or the earthaccess documentation site. Be aware that earthaccess is under active development."
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#prerequisites",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#prerequisites",
    "title": "Data discovery with earthaccess",
    "section": "Prerequisites",
    "text": "Prerequisites\nAn Earthdata Login account is required to access data from NASA Earthdata. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up."
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#learning-objectives",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#learning-objectives",
    "title": "Data discovery with earthaccess",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nHow to authenticate with earthaccess\nHow to use earthaccess to search for data using spatial and temporal filters\nHow to explore and work with search results"
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#get-started",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#get-started",
    "title": "Data discovery with earthaccess",
    "section": "Get Started",
    "text": "Get Started\n\nImport Required Packages\n\nimport earthaccess \nfrom pprint import pprint\nimport xarray as xr\nimport geopandas as gpd\n\n\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\nWe are already authenticated with NASA EDL\n\n\n\n\nSearch for data\nThere are multiple keywords we can use to discovery data from collections. The table below contains the short_name, concept_id, and doi for some collections we are interested in for other exercises. Each of these can be used to search for data or information related to the collection we are interested in.\n\n\n\nShortname\nCollection Concept ID\nDOI\n\n\n\n\nGPM_3IMERGDF\nC2723754864-GES_DISC\n10.5067/GPM/IMERGDF/DAY/07\n\n\nMOD10C1\nC1646609808-NSIDC_ECS\n10.5067/MODIS/MOD10C1.061\n\n\nSPL4SMGP\nC2531308461-NSIDC_ECS\n10.5067/EVKPQZ4AFC4D\n\n\nSPL4SMAU\nC2537927247-NSIDC_ECS\n10.5067/LWJ6TF5SZRG3\n\n\n\nBut wait…You may be asking “how can we find the shortname, concept_id, and doi for collections not in the table above?”. Let’s take a quick detour.\nhttps://search.earthdata.nasa.gov/search?q=GPM_3IMERGDF\n\nSearch by collection\n\n#collection_id = 'C2723754864-GES_DISC'\ncollection_id = 'C1598621096-GES_DISC'\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    count = 10    # Restricting to 10 records returned\n)\n\nGranules found: 7792\n\n\nIn this example we used the concept_id parameter to search from our desired collection. However, there are multiple ways to specify the collection(s) we are interested in. Alternative parameters include:\n\ndoi - request collection by digital object identifier (e.g., doi = ‘10.5067/GPM/IMERGDF/DAY/07’)\n\nshort_name - request collection by CMR shortname (e.g., short_name = ‘GPM_3IMERGDF’)\n\nNOTE: Each Earthdata collect has a unique concept_id and doi. This is not the case with short_name. A shortname can be associated with multiple versions of a collection. If multiple versions of a collection are publicaly available, using the short_name parameter with return all versions available. It is advised to use the version parameter in conjunction with the short_name parameter with searching.\nWe can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the temporal parameter to request a date range and the bounding_box parameter to request granules that intersect with a bounding box.\nFor our bounding box, we are going to read in a GeoJSON file containing a single feature and extract the coordinate pairs for the southeast corner and the northwest corner (or lowerleft and upperright corners) of the bounding box around the feature.\n\ninGeojson = gpd.read_file('../../NOAAHackDay-Dec-2023/data/sf_to_sierranvmt.geojson')\n\n\nxmin, ymin, xmax, ymax = inGeojson.total_bounds\n\nWe will assign our start date and end date to a variable named date_range and we’ll assign the southeast and the northwest corner coordinates to a variable named bbox to be passed to our earthaccess search request.\n\n#date_range = (\"2022-11-19\", \"2023-04-06\")\ndate_range = (\"2019-11-19\", \"2019-12-06\")\nbbox = (xmin, ymin, xmax, ymax)\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 18\n\n\n\nThe short_name and concept_id search parameters can be used to request one or multiple collections per request, but the doi parameter can only request a single collection.\n&gt; concept_ids = [‘C2723754864-GES_DISC’, ‘C1646609808-NSIDC_ECS’]\n\nUse the cloud_hosted search parameter only to search for data assets available from NASA’s Earthdata Cloud.\nThere are even more search parameters that can be passed to help refine our search, however those parameters do have to be populated in the CMR record to be leveraged. A non exhaustive list of examples are below:\n\nday_night_flag = 'day'\n\ncloud_cover = (0, 10)\n\n\n\n# col_ids = ['C2723754864-GES_DISC', 'C1646609808-NSIDC_ECS', 'C2531308461-NSIDC_ECS', 'C2537927247-NSIDC_ECS']    # Specify a list of collections to pass to the search\n\n# results = earthaccess.search_data(\n#     concept_id = col_ids,\n#     #cloud_hosted = True,\n#     temporal = date_range,\n#     bounding_box = bbox,\n# )\n\n\n\n\nWorking with earthaccess returns\nearthaccess provides several convenience methods to help streamline processes that historically have be painful when done using traditional methods. Following the search for data, you’ll likely take one of two pathways with those results. You may choose to download the assets that have been returned to you or you may choose to continue working with the search results within the Python environment.\n\nDownload earthaccess results\nIn some cases you may want to download your assets. earthaccess makes downloading the data from the search results very easy using the earthaccess.download() function.\n\ndownloaded_files = earthaccess.download(\n    results[0:9],\n    local_path='../../NOAAHackDay-Dec-2023/data',\n)\n\n Getting 9 granules, approx download size: 0.27 GB\n\n\n\n\n\n\n\n\n\n\n\nearthaccess did a lot of heavy lifting for us. It identified the downloadable links, passed our Earthdata Login credentials, and save off the file with the proper name. Amazing right!?\nWe’re going to remove those files to keep our space clean.\n\n!rm ../../NOAAHackDay-Dec-2023/data/*.nc4\n\n\n\nExplore earthaccess search response\n\nprint(f'The results variable is a {type(results)} of {type(results[0])}')\n\nThe results variable is a &lt;class 'list'&gt; of &lt;class 'earthaccess.results.DataGranule'&gt;\n\n\n\nlen(results)\n\n18\n\n\nWe can explore the first item (earthaccess.results.DataGranule) in our list.\n\nitem = results[0]\ntype(item)\n\nearthaccess.results.DataGranule\n\n\nEach item contains three keys that can be used to explore the item\n\nitem.keys()\n\ndict_keys(['meta', 'umm', 'size'])\n\n\n\nitem['umm']\n\n{'RelatedUrls': [{'URL': 'https://data.gesdisc.earthdata.nasa.gov/data/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'GET DATA', 'Description': 'Download 3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4'}, {'URL': 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'GET DATA VIA DIRECT ACCESS', 'Description': 'This link provides direct download access via S3 to the granule'}, {'URL': 'https://gpm1.gesdisc.eosdis.nasa.gov/opendap/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'USE SERVICE API', 'Subtype': 'OPENDAP DATA', 'Description': 'The OPENDAP location for the granule.', 'MimeType': 'application/x-netcdf-4'}, {'URL': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials', 'Type': 'VIEW RELATED INFORMATION', 'Description': 'api endpoint to retrieve temporary credentials valid for same-region direct s3 access'}], 'SpatialExtent': {'HorizontalSpatialDomain': {'Geometry': {'BoundingRectangles': [{'WestBoundingCoordinate': -180.0, 'EastBoundingCoordinate': 180.0, 'NorthBoundingCoordinate': 90.0, 'SouthBoundingCoordinate': -90.0}]}}}, 'ProviderDates': [{'Date': '2020-02-27T16:10:05.000Z', 'Type': 'Insert'}, {'Date': '2020-02-27T16:10:05.000Z', 'Type': 'Update'}], 'CollectionReference': {'ShortName': 'GPM_3IMERGDF', 'Version': '06'}, 'DataGranule': {'DayNightFlag': 'Unspecified', 'Identifiers': [{'Identifier': '3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'IdentifierType': 'ProducerGranuleId'}], 'ProductionDateTime': '2020-02-27T16:10:05.000Z', 'ArchiveAndDistributionInformation': [{'Name': 'Not provided', 'Size': 29.92357635498047, 'SizeUnit': 'MB'}]}, 'TemporalExtent': {'RangeDateTime': {'BeginningDateTime': '2019-11-19T00:00:00.000Z', 'EndingDateTime': '2019-11-19T23:59:59.999Z'}}, 'GranuleUR': 'GPM_3IMERGDF.06:3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'MetadataSpecification': {'URL': 'https://cdn.earthdata.nasa.gov/umm/granule/v1.6.5', 'Name': 'UMM-G', 'Version': '1.6.5'}}\n\n\n\n\nGet data URLs / S3 URIs\nGet links to data. The data_links() method is used to return the URL(s)/data link(s) for the item. By default the method returns the HTTPS URL to download or access the item.\n\nitem.data_links()\n\n['https://data.gesdisc.earthdata.nasa.gov/data/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4']\n\n\nThe data_links() method can also be used to get the s3 URI when we want to perform direct s3 access of the data in the cloud. To get the s3 URI, pass access = 'direct' to the method.\n\nitem.data_links(access='direct')\n\n['s3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4']\n\n\nIf we want to extract all of the data links from our search results and add or save them to a list, we can.\n\ndata_link_list = []\n\nfor granule in results:\n    for asset in granule.data_links(access='direct'):\n        data_link_list.append(asset)\n        \n\n\ndata_link_list[0:9]\n\n['s3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191120-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191121-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191122-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191123-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191124-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191125-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191126-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191127-S000000-E235959.V06.nc4']\n\n\nWe can pass or read these lists of data links into libraries like xarray, rioxarray, or gdal, but earthaccess has a built-in module for easily reading these data links in.\n\n\nOpen results in xarray\nWe use earthaccess’s open() method to make a connection to and open the files from our search result.\n\nfileset = earthaccess.open(results)\n\n Opening 18 granules, approx size: 0.53 GB\n\n\n\n\n\n\n\n\n\n\n\nThen we pass the fileset object to xarray.\n\nds = xr.open_mfdataset(fileset, chunks = {})\n\nSome really cool things just happened here! Not only were we able to seamlessly stream our earthaccess search results into a xarray dataset using the open_mfdataset() (multi-file) method, but earthaccess whether we were working from within AWS us-west-2 and could use direct S3 access or if not, would use https. We didn’t have to create a session or a filesystem to authenticate and connect to the data. earthaccess did this for us using the auth object we created at the beginning of this tutorial.\nLet’s take a quick lock at our xarray dataset\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                    (time: 18, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                        (lon) float32 -179.9 -179.8 ... 179.9 179.9\n  * lat                        (lat) float32 -89.95 -89.85 ... 89.85 89.95\n  * time                       (time) object 2019-11-19 00:00:00 ... 2019-12-...\nDimensions without coordinates: nv\nData variables:\n    precipitationCal           (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt       (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt_cond  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation            (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt_cond   (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt            (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                  (time, nv) object dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes:\n    BeginDate:       2019-11-19\n    BeginTime:       00:00:00.000Z\n    EndDate:         2019-11-19\n    EndTime:         23:59:59.999Z\n    FileHeader:      StartGranuleDateTime=2019-11-19T00:00:00.000Z;\\nStopGran...\n    InputPointer:    3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B....\n    title:           GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 ...\n    DOI:             10.5067/GPM/IMERGDF/DAY/06\n    ProductionTime:  2020-02-27T16:09:48.308Zxarray.DatasetDimensions:time: 18lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.8 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95   , -179.84999, -179.75   , ...,  179.75002,  179.85002,\n        179.95   ], dtype=float32)lat(lat)float32-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95    , -89.85    , -89.75    , ...,  89.75    ,  89.850006,\n        89.95001 ], dtype=float32)time(time)object2019-11-19 00:00:00 ... 2019-12-...standard_name :timebounds :time_bndsarray([cftime.DatetimeJulian(2019, 11, 19, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 20, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 21, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 22, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 23, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 24, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 25, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 26, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 27, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 28, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 29, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 30, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 1, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 2, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 3, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 4, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 5, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 6, 0, 0, 0, 0, has_year_zero=False)],\n      dtype=object)Data variables: (9)precipitationCal(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mmlong_name :Daily accumulated precipitation (combined microwave-IR) estimate\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\nprecipitationCal_cnt(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of all valid half-hourly precipitationCal retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\nprecipitationCal_cnt_cond(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of valid half-hourly precipitationCal retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\nHQprecipitation(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mmlong_name :Daily accumulated High Quality precipitation from all available MW sources\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\nHQprecipitation_cnt(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of all valid half-hourly HQprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\nHQprecipitation_cnt_cond(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of valid half-hourly HQprecipitation retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\nrandomError(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mmlong_name :Daily total error of precipitation estimate\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\nrandomError_cnt(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\ntime_bnds(time, nv)objectdask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;coordinates :time nv\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n288 B\n16 B\n\n\nShape\n(18, 2)\n(1, 2)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nobject numpy.ndarray\n\n\n\n\n                          2 18\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.84999084472656,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.34999084472656,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.15000915527344,  179.25001525878906,\n                179.3500213623047,   179.4499969482422,   179.5500030517578,\n               179.65000915527344,  179.75001525878906,   179.8500213623047,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([-89.94999694824219,  -89.8499984741211,             -89.75,\n              -89.64999389648438, -89.54999542236328, -89.44999694824219,\n               -89.3499984741211,             -89.25, -89.14999389648438,\n              -89.04999542236328,\n              ...\n               89.05000305175781,  89.15000915527344,              89.25,\n               89.35000610351562,  89.45001220703125,  89.55000305175781,\n               89.65000915527344,              89.75,  89.85000610351562,\n               89.95001220703125],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(CFTimeIndex([2019-11-19 00:00:00, 2019-11-20 00:00:00, 2019-11-21 00:00:00,\n             2019-11-22 00:00:00, 2019-11-23 00:00:00, 2019-11-24 00:00:00,\n             2019-11-25 00:00:00, 2019-11-26 00:00:00, 2019-11-27 00:00:00,\n             2019-11-28 00:00:00, 2019-11-29 00:00:00, 2019-11-30 00:00:00,\n             2019-12-01 00:00:00, 2019-12-02 00:00:00, 2019-12-03 00:00:00,\n             2019-12-04 00:00:00, 2019-12-05 00:00:00, 2019-12-06 00:00:00],\n            dtype='object', length=18, calendar='julian', freq='D'))Attributes: (9)BeginDate :2019-11-19BeginTime :00:00:00.000ZEndDate :2019-11-19EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2019-11-19T00:00:00.000Z;\nStopGranuleDateTime=2019-11-19T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S003000-E005959.0030.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S010000-E012959.0060.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S013000-E015959.0090.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S020000-E022959.0120.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S023000-E025959.0150.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S030000-E032959.0180.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S033000-E035959.0210.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S040000-E042959.0240.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S043000-E045959.0270.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S050000-E052959.0300.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S053000-E055959.0330.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S060000-E062959.0360.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S063000-E065959.0390.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S070000-E072959.0420.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S073000-E075959.0450.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S080000-E082959.0480.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S083000-E085959.0510.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S090000-E092959.0540.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S093000-E095959.0570.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S100000-E102959.0600.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S103000-E105959.0630.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S110000-E112959.0660.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S113000-E115959.0690.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S120000-E122959.0720.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S123000-E125959.0750.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S130000-E132959.0780.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S133000-E135959.0810.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S140000-E142959.0840.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S143000-E145959.0870.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S150000-E152959.0900.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S153000-E155959.0930.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S160000-E162959.0960.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S163000-E165959.0990.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S170000-E172959.1020.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S173000-E175959.1050.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S180000-E182959.1080.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S183000-E185959.1110.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S190000-E192959.1140.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S193000-E195959.1170.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S200000-E202959.1200.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S203000-E205959.1230.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S210000-E212959.1260.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S213000-E215959.1290.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S220000-E222959.1320.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S223000-E225959.1350.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S230000-E232959.1380.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S233000-E235959.1410.V06B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/06ProductionTime :2020-02-27T16:09:48.308Z"
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#resources",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Search_Discovery.html#resources",
    "title": "Data discovery with earthaccess",
    "section": "Resources",
    "text": "Resources\n\nNASA’s Common Metadata Repository (CMR) API\n\nearthaccess repository\nearthaccess documentation\nEarthdata Search"
  },
  {
    "objectID": "content/workshops.html",
    "href": "content/workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "The NMFS Openscapes JupyterHub supports workshops and trainings run by NOAA Fisheries. See the CoastWatch Training for all their events.\n\nOct-Dec 2024 Quarto Workshop\nOctober 25, 2024 Oceanographic Satellite and Animal Telemetry Data Training Course\nMay 17, 2024 Introduction to using earth data in the cloud for scientific workflows",
    "crumbs": [
      "Workshops"
    ]
  },
  {
    "objectID": "content/slides.html#enabling-analysis-in-the-cloud-using-nasa-earth-science-data",
    "href": "content/slides.html#enabling-analysis-in-the-cloud-using-nasa-earth-science-data",
    "title": "NASA AGU 2023 Workshop Slides",
    "section": "Enabling Analysis in the Cloud Using NASA Earth Science Data",
    "text": "Enabling Analysis in the Cloud Using NASA Earth Science Data"
  },
  {
    "objectID": "content/setup.html",
    "href": "content/setup.html",
    "title": "Quick Start",
    "section": "",
    "text": "For those already familiar with JupyterLab and unix.\n\nGitHub Account\nA GitHub account is required to gain access to the JupyterHub and to clone the tutorials used in the Hackhours.\nHow do I get the tutorials into the JupyterHub?\n\nYou can upload files.\nEasiest is probably cloning a repo into the hub. See the JupyterHub Skills section if you do not know how to do this.\n\n\n\nAuthenticating to GitHub\nThis is a little different on the JupyterHub. See git authentication.\nFor content that uses the NASA Earthdata repository, you will need an Earthdata Login account. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create. Please jot down your username and password, as you need to enter it in the tutorials.\n\n\nWhen done, please stop the JupyterHub\nIf you are in JupyterLab in the browser:\n\nFile &gt; Hub Control Panel &gt; Stop my server\n\nIf you are in RStudio and you still have the JupyterLab tab open in your browser:\n\nGo to the JupyterLab tab\nFile &gt; Hub Control Panel &gt; Stop my server\n\nIf you are in RStudio and you do not have the JupyterLab tab open in your browser because you closed that tab:\n\nGo to the url https://&lt;jupyterhub url&gt;/user/&lt;your username in the hub&gt;/lab/ That will open the JupyterLab tab\nFile &gt; Hub Control Panel &gt; Stop my server",
    "crumbs": [
      "Quick Start"
    ]
  },
  {
    "objectID": "content/jhub.html",
    "href": "content/jhub.html",
    "title": "NOAA HackHours",
    "section": "",
    "text": "The NMFS Openscapes JupyterHub is managed by Openscapes and developed in partnership with the International Interactive Computing Collaboration 2i2c. Launched in September 2024, the NMFS Openscapes JupyterHub joins the NASA Openscapes JupyterHub in providing a curated interactive computing platform to support training in earth and life science visualization, computing and analysis. The NMFS Openscapes JupyterHub supports workshops and trainings run by NOAA Fisheries.",
    "crumbs": [
      "About the Hub"
    ]
  },
  {
    "objectID": "coc.html",
    "href": "coc.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We are dedicated to providing a harassment-free learning experience for everyone. We do not tolerate harassment of participants in any form. Sexual language and imagery is not appropriate either in-person or virtual form, including the Discussion boards and Chats. Participants (including event volunteers and organizers) violating these rules may be sanctioned or expelled from the event at the discretion of the organizers.",
    "crumbs": [
      "JupyterHub",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#definition-of-harassment",
    "href": "coc.html#definition-of-harassment",
    "title": "Code of Conduct",
    "section": "Definition of Harassment",
    "text": "Definition of Harassment\nHarassment includes, but is not limited to:\n\nVerbal comments that harass based on sexual orientation, disability, physical appearance, body size, race, age, religion.\nSexual images in public spaces\nDeliberate intimidation, stalking, or following\nHarassing photography or recording\nSustained disruption of talks or other events\nInappropriate physical contact\nUnwelcome sexual attention\nAdvocating for, or encouraging, any of the above behavior",
    "crumbs": [
      "JupyterHub",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#expectations",
    "href": "coc.html#expectations",
    "title": "Code of Conduct",
    "section": "Expectations",
    "text": "Expectations\nParticipants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, the organizers retain the right to take any actions to keep the event a welcoming environment for all participants. This includes warning the offender or expulsion from the event.\nThe organizers may take action to redress anything designed to, or with the clear impact of, disrupting the event or making the environment hostile for any participants. We expect participants to follow these rules at all the event venues and event-related social activities.",
    "crumbs": [
      "JupyterHub",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#reporting-a-violation",
    "href": "coc.html#reporting-a-violation",
    "title": "Code of Conduct",
    "section": "Reporting a violation",
    "text": "Reporting a violation\nHarassment and other code of conduct violations reduce the value of the event for everyone. If someone makes you or anyone else feel unsafe or unwelcome, please report it as soon as possible.\nIf you feel comfortable contacting someone associated with our event, you may speak with one of the event organizers in person or contact an organizer on a private channel.",
    "crumbs": [
      "JupyterHub",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "content/hackhours.html",
    "href": "content/hackhours.html",
    "title": "Hackhours",
    "section": "",
    "text": "HackHour Goals\nThese sessions are for NOAA staff to gain more familiarity with JupyterHubs and working with spatial data, esp big data hosted in the cloud in databases, via code and via geospatial packages in R and Python.\n\nProvide an inclusive place to learn and practice new skills\nGet practice working in a JupyterHub with R and Python\nLearn about and experience working with earth data in the cloud;\nPractice using remote-sensing data in R and Python with code.\nLearn by working together on small projects.\nGive you the skills to be able to join hackweeks focused on big earth data.\n\n\n\nSign ups\nSee the 2025 Hackhour page for info.\nContact or questions: Eli Holmes (NOAA) - Type my name in your NOAA email, and my contact will pop up. Note, it uses “Eli” not “Elizabeth”! There are two Elizabeth Holmes’s in NOAA.\n\n\nOrientation\nSee the Quick Start in left nav bar or go to the “JupyterHub Skills” section.\n\n\nFAQ\n\nCan I bring my own content/code to the event and JupyterHub? Absolutely, please do!! You can clone a GitHub repo or just upload files into the hub.",
    "crumbs": [
      "Hackhours"
    ]
  },
  {
    "objectID": "content/reuse.html",
    "href": "content/reuse.html",
    "title": "Reuse Statement",
    "section": "",
    "text": "This content is released under CC0 Creative Commons.\nPermissive Re-Mix and No Attribution Needed: You may reuse the content in this repository—excluding the NMFS Open Science logo and any NOAA logos—in any way you like. You do not need permission. You do not need to give attribution, but if you use large parts of tutorials or content it is polite to give acknowledgement of the source. Please check each NMFS Open Science repository for its reuse statement. Some of the content is from Carl Boettiger and from NASA Openscapes. This will be noted and you should check the original content for its reuse statement.",
    "crumbs": [
      "Reuse Statement"
    ]
  },
  {
    "objectID": "content/signup.html#noaa-fisheries-friday-hackhours-12-1pm-pt3-4pm-et",
    "href": "content/signup.html#noaa-fisheries-friday-hackhours-12-1pm-pt3-4pm-et",
    "title": "HackHours in R and Python",
    "section": "NOAA Fisheries Friday Hackhours 12-1pm PT/3-4pm ET",
    "text": "NOAA Fisheries Friday Hackhours 12-1pm PT/3-4pm ET\nUse this form to sign-up to be alerted for future hackdays and Intro to JupyterHubs sessions: SIGN-UP FORM\nContact or questions: Eli Holmes (NOAA) - Type my name in your NOAA email, and my contact will pop up. Note, it uses “Eli” not “Elizabeth”.\nDuring these 1 hour hackhours, we will learn to do cloud computing with a JupyterHub set-up with geospatial packages and data. These sessions will get you more familiar with cloud-computing, JupyterHubs, Jupyter notebooks, and Python for geospatial analysis.\nAdd event to your calendar\nClick “HackHour 2024” for list of events and dates"
  },
  {
    "objectID": "content/why-cloud.html#why-would-i-want-to-work-in-the-cloud",
    "href": "content/why-cloud.html#why-would-i-want-to-work-in-the-cloud",
    "title": "NOAA HackHours",
    "section": "Why would I want to work in the cloud?",
    "text": "Why would I want to work in the cloud?\nWatch this video on “Enabling Analysis in the Cloud Using NASA Earth Science Data” by Michele Thorton, a NASA Openscapes mentor from the Oak Ridge National Laboratory Distributed Active Archive Center.\n\n\nMore earth data tutorials to explore!\nThe content and tutorials is a mix of content from workshops by the NASA Openscapes mentors (for example 2023 Cloud AGU Workshop), content developed by Carl Boettiger for NASA TOPS-T Cloud Native Geospatial in R & Python, content by NMFS CoastWatch, and other internal and external tutorials.\nHow do I get these tutorials into the JupyterHub? clone this https://github.com/NASA-Openscapes/earthdata-cloud-cookbook/ and then look in the examples folder.\nHow do I clone? Since these are Jupyter/Python notebooks, easiest is cloning via JupyterLab.\n\nGo to JupyterLab. How? I closed the tab. Open the JupyterHub url again.\nClick on the little file icon on left until you are at the home directory.\nClick on the little Git icon on left. Which is it? Click on all the icons until you find it.\nWhen you see the ‘Clone repository’ button, click that. Paste in the url of the GitHub repo. I don’t see ‘Clone repository’. Go back to step 1. You are not in the home directory yet.\n\n\n\nFAQ\n\nCan I bring my own content/code to the event and JupyterHub? Absolutely, please do!! You can clone a GitHub repo or just upload files into the hub."
  },
  {
    "objectID": "index.html#noaa-fisheries-training-in-ocean-data-and-cloud-computing",
    "href": "index.html#noaa-fisheries-training-in-ocean-data-and-cloud-computing",
    "title": "NOAA HackHours",
    "section": "NOAA Fisheries Training in Ocean Data and Cloud Computing",
    "text": "NOAA Fisheries Training in Ocean Data and Cloud Computing\nThese are the support pages for the NMFS Open Science resources that support training in data science for the earth and life sciences at NOAA Fisheries.\n\nJupyterHub information and orientation pages\nTutorials from our HackDays\nLinks to workshops\n\nWe provide technical and infrastructure support for any groups within NOAA Fisheries who would like computing support for their workshops or trainings; See our training page (NOAA internal). In September 2024, we launched a JupyterHub with a variety of specialized computing environments tailored to needs in fisheries and ocean modeling. We also support the development of a Docker stack tailored to R and Python workflows. We run regular workshops and trainings in reproducible science. See NMFS Openscapes and NMFS Open Science. If at NOAA see our internal site and the tabs for News and Training."
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#summary",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#summary",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Summary",
    "text": "Summary\nIn this examples we will use the xarray and earthaccess to subset data and make figures."
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#learning-objectives",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#learning-objectives",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExtract variables, temporal slices, and spatial slices from an xarray dataset\nPlot data and exclude data points via boolean conditions, using xarray, cartopy, and matplotlib\n\n\nImport Required Packages\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\nfrom pprint import pprint\n\nimport earthaccess\nimport xarray as xr\nxr.set_options(display_expand_attrs=False)\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\n%matplotlib inline"
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#authenticate-to-nasa-earthdata",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#authenticate-to-nasa-earthdata",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Authenticate to NASA Earthdata",
    "text": "Authenticate to NASA Earthdata\nWe will authenticate our Earthaccess session, and then open the results like we did in the Search & Discovery section.\n\n# Bug on dhub settings is setting the home to /home/rstudio\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\nEDL_USERNAME and EDL_PASSWORD are not set in the current environment, try setting them or use a different strategy (netrc, interactive)\nYou're now authenticated with NASA Earthdata Login\nUsing token with expiration date: 01/29/2024\nUsing .netrc file for EDL"
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/Earthdata_Subset_and_Plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3",
    "text": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3\n\nDataset\nWe will use the GPM IMERG Final Precipitation L3 Daily dataset for this tutorial. The IMERG Precipitation Rate provides the rain and snow rates in millimeters per hour (mm/hr). It is estimated by the Integrated Multi-satellitE Retrievals for Global Precipitation Measurement (GPM) (IMERG) algorithm. The IMERG algorithm uses passive-microwave data from the GPM constellation of satellites and infrared data from geosynchronous satellites. IMERG “morphs” observations to earlier or later times using wind from weather-model analyses. The daily IMERG dataset is derived from the half-hourly GPM_3IMERGHH. The derived result represents the final estimate of the daily mean precipitation rate in mm/day.\nLink to data on NASA Earthdata\nThe IMERG data has 0.1 x 0.1 degree latitude-longitude resolution (approximately 11 by 11 km at the Equator). The grid covers the globe, although precipitation cannot always be estimated near the Poles. The dataset and algorithm are described in the data user guide and the Algorithm Theoretical Basis Document (ATBD).\nPlease cite the dataset as: &gt; Huffman, G.J., E.F. Stocker, D.T. Bolvin, E.J. Nelkin, Jackson Tan (2023), GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07, Edited by Andrey Savtchenko, Greenbelt, MD, Goddard Earth Sciences Data and Information Services Center (GES DISC), https://doi.org/10.5067/GPM/IMERGDF/DAY/07\n\ncollection_id = 'C2723754864-GES_DISC'  # GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07 (GPM_3IMERGDF)\n# Seems to be a bug in the collection above so I am using older data\n\n# Bounds within which we search for data granules\ndate_start = \"2015-02-25\"\ndate_end = \"2015-02-26\"\ndate_range = (date_start, date_end)\nbbox = (-127.0761, 31.6444, -113.9039, 42.6310)  # min lon, min lat, max lon, max lat\n\n# For reference (e.g., to visualize in https://geojson.io/), here is a GeoJSON representing the above bounding box:\n# {\"type\": \"FeatureCollection\", \"features\": [{\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"LineString\", \"bbox\": [-127.0761, 31.6444, -113.9039, 42.631], \"coordinates\": [[-113.9039, 42.631], [-127.0761,42.631], [-127.0761, 31.6444], [-113.9039, 31.6444], [-113.9039, 42.631]]}}]}\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 2\n\n\n\nds = xr.open_mfdataset(earthaccess.open(results))\n\n Opening 2 granules, approx size: 0.05 GB\n\n\n\n\n\n\n\n\n\n\n\nNote that xarray works with “lazy” computation whenever possible. In this case, the metadata are loaded into JupyterHub memory, but the data arrays and their values are not — until there is a need for them.\nLet’s print out all the variable names.\n\nfor v in ds.variables:\n    print(v)\n\nprecipitation\nprecipitation_cnt\nprecipitation_cnt_cond\nMWprecipitation\nMWprecipitation_cnt\nMWprecipitation_cnt_cond\nrandomError\nrandomError_cnt\nprobabilityLiquidPrecipitation\nlon\nlat\ntime\ntime_bnds\n\n\nOf the variables listed above, we are interested in three variables: precipitation, precipitation_cnt_cond, and probabilityLiquidPrecipitation. Let’s print their attributes.\n\nds.variables['precipitation'].attrs\n\n{'units': 'mm/day',\n 'long_name': 'Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.'}\n\n\n\nds.variables['precipitation_cnt_cond'].attrs\n\n{'units': 'count',\n 'long_name': 'Count of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr'}\n\n\n\nds.variables['probabilityLiquidPrecipitation'].attrs\n\n{'units': 'percent',\n 'long_name': 'Probability of liquid precipitation',\n 'description': 'Probability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation.  Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.'}\n\n\n\n\nSubsetting\nIn addition to directly accessing the files archived and distributed by each of the NASA DAACs, many datasets also support services that allow us to customize the data via subsetting, reformatting, reprojection/regridding, and file aggregation. What does subsetting mean? To subset means to extract only the portions of a dataset that are needed for a given purpose.\nThere are three primary types of subsetting that we will walk through: 1. Temporal 2. Spatial 3. Variable\nIn each case, we will be excluding parts of the dataset that are not wanted using xarray. Note that “subsetting” is also called a data “transformation”.\n\nds.time.values\n\narray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')\n\n\nWe start with a subset that represents the U.S. state of California. Notice the dimensions of the Dataset and each variable — time, lon, lat, and ‘nv’ (number of vertices) for the bounds variable.\n\n# Display the full dataset's metadata\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                         (time: 2, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                             (lon) float32 -179.9 -179.9 ... 179.9 179.9\n  * lat                             (lat) float64 -89.95 -89.85 ... 89.85 89.95\n  * time                            (time) datetime64[ns] 2015-02-25 2015-02-26\nDimensions without coordinates: nv\nData variables:\n    precipitation                   (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt               (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt_cond          (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation                 (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt             (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt_cond        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                     (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt                 (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    probabilityLiquidPrecipitation  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                       (time, nv) datetime64[ns] dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes: (9)xarray.DatasetDimensions:time: 2lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.9 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95, -179.85, -179.75, ...,  179.75,  179.85,  179.95],\n      dtype=float32)lat(lat)float64-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95, -89.85, -89.75, ...,  89.75,  89.85,  89.95])time(time)datetime64[ns]2015-02-25 2015-02-26standard_name :timelong_name :timebounds :time_bndsarray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (10)precipitation(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nprecipitation_cnt(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of all valid half-hourly precipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nprecipitation_cnt_cond(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nMWprecipitation(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean High Quality precipitation rate from all available microwave sources. Formerly HQprecipitation.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nMWprecipitation_cnt(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of all valid half-hourly MWprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nMWprecipitation_cnt_cond(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of half-hourly MWprecipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nrandomError(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mm/daylong_name :Root-mean-square error estimate for combined microwave-IR daily precipitation rate\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nrandomError_cnt(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :countlong_name :Count of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\nprobabilityLiquidPrecipitation(time, lon, lat)int8dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :percentlong_name :Probability of liquid precipitationdescription :Probability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation.  Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\ntime_bnds(time, nv)datetime64[ns]dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;coordinates :time nv\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n32 B\n16 B\n\n\nShape\n(2, 2)\n(1, 2)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n          2 2\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.85000610351562,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.35000610351562,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.14999389648438,              179.25,\n               179.35000610351562,   179.4499969482422,   179.5500030517578,\n               179.64999389648438,              179.75,  179.85000610351562,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([            -89.95, -89.85000000000001,             -89.75,\n                          -89.65,             -89.55,             -89.45,\n              -89.35000000000001,             -89.25,             -89.15,\n                          -89.05,\n              ...\n                           89.05,  89.15000000000002,  89.25000000000001,\n               89.35000000000001,              89.45,              89.55,\n               89.65000000000002,  89.75000000000001,  89.85000000000001,\n                           89.95],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(DatetimeIndex(['2015-02-25', '2015-02-26'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (9)BeginDate :2015-02-25BeginTime :00:00:00.000ZEndDate :2015-02-25EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2015-02-25T00:00:00.000Z;\nStopGranuleDateTime=2015-02-25T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20150225-S000000-E002959.0000.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S003000-E005959.0030.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S010000-E012959.0060.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S013000-E015959.0090.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S020000-E022959.0120.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S023000-E025959.0150.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S030000-E032959.0180.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S033000-E035959.0210.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S040000-E042959.0240.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S043000-E045959.0270.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S050000-E052959.0300.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S053000-E055959.0330.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S060000-E062959.0360.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S063000-E065959.0390.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S070000-E072959.0420.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S073000-E075959.0450.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S080000-E082959.0480.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S083000-E085959.0510.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S090000-E092959.0540.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S093000-E095959.0570.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S100000-E102959.0600.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S103000-E105959.0630.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S110000-E112959.0660.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S113000-E115959.0690.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S120000-E122959.0720.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S123000-E125959.0750.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S130000-E132959.0780.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S133000-E135959.0810.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S140000-E142959.0840.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S143000-E145959.0870.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S150000-E152959.0900.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S153000-E155959.0930.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S160000-E162959.0960.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S163000-E165959.0990.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S170000-E172959.1020.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S173000-E175959.1050.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S180000-E182959.1080.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S183000-E185959.1110.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S190000-E192959.1140.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S193000-E195959.1170.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S200000-E202959.1200.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S203000-E205959.1230.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S210000-E212959.1260.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S213000-E215959.1290.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S220000-E222959.1320.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S223000-E225959.1350.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S230000-E232959.1380.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S233000-E235959.1410.V07B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/07ProductionTime :2023-12-18T14:54:02.047Z\n\n\nNow we will prepare a subset. We’re using essentially the same spatial bounds as above; however, as opposed to the earthaccess inputs above, here we must provide inputs in the formats expected by xarray. Instead of a single, four-element, bounding box, we use Python slice objects, which are defined by starting and ending numbers.\n\nds_subset = ds.sel(time=date_start, lat=slice(31, 43), lon=slice(-125, -113)) \nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                         (lon: 120, lat: 120, nv: 2)\nCoordinates:\n  * lon                             (lon) float32 -124.9 -124.8 ... -113.1\n  * lat                             (lat) float64 31.05 31.15 ... 42.85 42.95\n    time                            datetime64[ns] 2015-02-25\nDimensions without coordinates: nv\nData variables:\n    precipitation                   (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    precipitation_cnt               (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    precipitation_cnt_cond          (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation                 (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation_cnt             (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation_cnt_cond        (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    randomError                     (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    randomError_cnt                 (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    probabilityLiquidPrecipitation  (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    time_bnds                       (nv) datetime64[ns] dask.array&lt;chunksize=(2,), meta=np.ndarray&gt;\nAttributes: (9)xarray.DatasetDimensions:lon: 120lat: 120nv: 2Coordinates: (3)lon(lon)float32-124.9 -124.8 ... -113.2 -113.1units :degrees_eastlong_name :Longitudearray([-124.95, -124.85, -124.75, -124.65, -124.55, -124.45, -124.35, -124.25,\n       -124.15, -124.05, -123.95, -123.85, -123.75, -123.65, -123.55, -123.45,\n       -123.35, -123.25, -123.15, -123.05, -122.95, -122.85, -122.75, -122.65,\n       -122.55, -122.45, -122.35, -122.25, -122.15, -122.05, -121.95, -121.85,\n       -121.75, -121.65, -121.55, -121.45, -121.35, -121.25, -121.15, -121.05,\n       -120.95, -120.85, -120.75, -120.65, -120.55, -120.45, -120.35, -120.25,\n       -120.15, -120.05, -119.95, -119.85, -119.75, -119.65, -119.55, -119.45,\n       -119.35, -119.25, -119.15, -119.05, -118.95, -118.85, -118.75, -118.65,\n       -118.55, -118.45, -118.35, -118.25, -118.15, -118.05, -117.95, -117.85,\n       -117.75, -117.65, -117.55, -117.45, -117.35, -117.25, -117.15, -117.05,\n       -116.95, -116.85, -116.75, -116.65, -116.55, -116.45, -116.35, -116.25,\n       -116.15, -116.05, -115.95, -115.85, -115.75, -115.65, -115.55, -115.45,\n       -115.35, -115.25, -115.15, -115.05, -114.95, -114.85, -114.75, -114.65,\n       -114.55, -114.45, -114.35, -114.25, -114.15, -114.05, -113.95, -113.85,\n       -113.75, -113.65, -113.55, -113.45, -113.35, -113.25, -113.15, -113.05],\n      dtype=float32)lat(lat)float6431.05 31.15 31.25 ... 42.85 42.95units :degrees_northlong_name :Latitudearray([31.05, 31.15, 31.25, 31.35, 31.45, 31.55, 31.65, 31.75, 31.85, 31.95,\n       32.05, 32.15, 32.25, 32.35, 32.45, 32.55, 32.65, 32.75, 32.85, 32.95,\n       33.05, 33.15, 33.25, 33.35, 33.45, 33.55, 33.65, 33.75, 33.85, 33.95,\n       34.05, 34.15, 34.25, 34.35, 34.45, 34.55, 34.65, 34.75, 34.85, 34.95,\n       35.05, 35.15, 35.25, 35.35, 35.45, 35.55, 35.65, 35.75, 35.85, 35.95,\n       36.05, 36.15, 36.25, 36.35, 36.45, 36.55, 36.65, 36.75, 36.85, 36.95,\n       37.05, 37.15, 37.25, 37.35, 37.45, 37.55, 37.65, 37.75, 37.85, 37.95,\n       38.05, 38.15, 38.25, 38.35, 38.45, 38.55, 38.65, 38.75, 38.85, 38.95,\n       39.05, 39.15, 39.25, 39.35, 39.45, 39.55, 39.65, 39.75, 39.85, 39.95,\n       40.05, 40.15, 40.25, 40.35, 40.45, 40.55, 40.65, 40.75, 40.85, 40.95,\n       41.05, 41.15, 41.25, 41.35, 41.45, 41.55, 41.65, 41.75, 41.85, 41.95,\n       42.05, 42.15, 42.25, 42.35, 42.45, 42.55, 42.65, 42.75, 42.85, 42.95])time()datetime64[ns]2015-02-25standard_name :timelong_name :timebounds :time_bndsarray('2015-02-25T00:00:00.000000000', dtype='datetime64[ns]')Data variables: (10)precipitation(lon, lat)float32dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nprecipitation_cnt(lon, lat)int8dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :countlong_name :Count of all valid half-hourly precipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nprecipitation_cnt_cond(lon, lat)int8dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :countlong_name :Count of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nMWprecipitation(lon, lat)float32dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean High Quality precipitation rate from all available microwave sources. Formerly HQprecipitation.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nMWprecipitation_cnt(lon, lat)int8dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :countlong_name :Count of all valid half-hourly MWprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nMWprecipitation_cnt_cond(lon, lat)int8dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :countlong_name :Count of half-hourly MWprecipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nrandomError(lon, lat)float32dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :mm/daylong_name :Root-mean-square error estimate for combined microwave-IR daily precipitation rate\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nrandomError_cnt(lon, lat)int8dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :countlong_name :Count of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\nprobabilityLiquidPrecipitation(lon, lat)int8dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :percentlong_name :Probability of liquid precipitationdescription :Probability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation.  Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n         120 120\n\n\n\n\ntime_bnds(nv)datetime64[ns]dask.array&lt;chunksize=(2,), meta=np.ndarray&gt;coordinates :time nv\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16 B\n16 B\n\n\nShape\n(2,)\n(2,)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n         2 1\n\n\n\n\nIndexes: (2)lonPandasIndexPandasIndex(Float64Index([-124.94999694824219,  -124.8499984741211,             -124.75,\n               -124.6500015258789, -124.55000305175781, -124.44999694824219,\n               -124.3499984741211,             -124.25,  -124.1500015258789,\n              -124.05000305175781,\n              ...\n              -113.94999694824219,  -113.8499984741211,             -113.75,\n               -113.6500015258789, -113.55000305175781, -113.44999694824219,\n               -113.3499984741211,             -113.25,  -113.1500015258789,\n              -113.05000305175781],\n             dtype='float64', name='lon', length=120))latPandasIndexPandasIndex(Float64Index([             31.05,  31.15000000000001, 31.250000000000004,\n              31.350000000000012, 31.450000000000006,              31.55,\n               31.65000000000001, 31.750000000000004, 31.850000000000012,\n              31.950000000000006,\n              ...\n                           42.05,  42.14999999999999, 42.250000000000014,\n               42.35000000000001,              42.45,              42.55,\n               42.64999999999999, 42.750000000000014,  42.85000000000001,\n                           42.95],\n             dtype='float64', name='lat', length=120))Attributes: (9)BeginDate :2015-02-25BeginTime :00:00:00.000ZEndDate :2015-02-25EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2015-02-25T00:00:00.000Z;\nStopGranuleDateTime=2015-02-25T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20150225-S000000-E002959.0000.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S003000-E005959.0030.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S010000-E012959.0060.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S013000-E015959.0090.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S020000-E022959.0120.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S023000-E025959.0150.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S030000-E032959.0180.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S033000-E035959.0210.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S040000-E042959.0240.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S043000-E045959.0270.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S050000-E052959.0300.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S053000-E055959.0330.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S060000-E062959.0360.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S063000-E065959.0390.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S070000-E072959.0420.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S073000-E075959.0450.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S080000-E082959.0480.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S083000-E085959.0510.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S090000-E092959.0540.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S093000-E095959.0570.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S100000-E102959.0600.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S103000-E105959.0630.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S110000-E112959.0660.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S113000-E115959.0690.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S120000-E122959.0720.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S123000-E125959.0750.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S130000-E132959.0780.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S133000-E135959.0810.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S140000-E142959.0840.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S143000-E145959.0870.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S150000-E152959.0900.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S153000-E155959.0930.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S160000-E162959.0960.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S163000-E165959.0990.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S170000-E172959.1020.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S173000-E175959.1050.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S180000-E182959.1080.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S183000-E185959.1110.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S190000-E192959.1140.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S193000-E195959.1170.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S200000-E202959.1200.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S203000-E205959.1230.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S210000-E212959.1260.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S213000-E215959.1290.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S220000-E222959.1320.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S223000-E225959.1350.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S230000-E232959.1380.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S233000-E235959.1410.V07B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/07ProductionTime :2023-12-18T14:54:02.047Z\n\n\nNotice the differences?\n\n\nPlotting\nWe will first plot using the methods built-in to the xarray package.\nNote that, as opposed to the “lazy” loading of metadata previously, this will now perform “eager” computation, pulling the required data chunks.\n\nds_subset['precipitation'].plot(figsize=(10,6), x='lon', y='lat');\n\n\n\n\n\n\n\n\nNow let’s utilize the “Probability of liquid precipitation phase” (probabilityLiquidPrecipitation) variable to split apart the snow precipitation from everything else. From the variable’s description attribute, we can see that “0=missing values; 1=likely solid; 100=likely liquid or no precipitation”.\nMoreover, we’ll utilize precipitation_cnt_cond to filter out data points that had less than 0.01 mm/hr preciptation amounts.\n\nsnow = ds_subset['precipitation'].where(\n    (ds_subset.precipitation_cnt_cond&gt;0) & (ds_subset.probabilityLiquidPrecipitation == 1)\n)\n\nprcp = ds_subset['precipitation'].where(\n    (ds_subset.precipitation_cnt_cond&gt;0) & (ds_subset.probabilityLiquidPrecipitation != 1)\n)\n\nIn the following plotting commands, we utilize cartopy and matplotlib to generate a more customized figure.\ncartopy is used to set the map projection (to PlateCarree) and to add U.S. state boundary lines to the figure. matplotlib’s pcolormesh is used to generate the color plot, with colors determined by the third argument’s value.\n\n# create the plot\nproj = ccrs.PlateCarree()\nfig, ax = plt.subplots(figsize=(8,5), dpi=130, facecolor=\"w\", subplot_kw=dict(projection=proj))\n\nsnowax = plt.pcolormesh(prcp.lon, prcp.lat, snow.squeeze(), vmax=53, cmap='cool')\nprcpax = plt.pcolormesh(prcp.lon, prcp.lat, prcp.squeeze(), vmax=53, cmap='RdYlGn')\n\nplt.colorbar(snowax, ax=ax, label=\"snow (mm/day)\")\nplt.colorbar(prcpax, ax=ax, label=\"rainfall (mm/day)\")\nax.add_feature(cfeature.STATES)\nax.set_extent([-125, -113.0, 31.0, 43.0], crs=proj)\nax.set_title(f'Precipitation {date_start}')\n\nplt.show()\n\n\n\n\n\n\n\n\nNotice the enhancements?\nAlso, note that you can explore these (and other) data before generating your own customized plots, by using NASA Worldview. Here’s a link to an example map on Worldview for these IMERG data.\nEND of Notebook."
  },
  {
    "objectID": "topics-2023/index.html#select-an-event-to-the-left",
    "href": "topics-2023/index.html#select-an-event-to-the-left",
    "title": "HackHours 2023",
    "section": "Select an event to the left",
    "text": "Select an event to the left",
    "crumbs": [
      "JupyterHub",
      "HackHours 2023"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-19-dask/Parallel_compute_with_dask.html",
    "href": "topics-2024/2024-04-19-dask/Parallel_compute_with_dask.html",
    "title": "Simple dask example",
    "section": "",
    "text": "# import needed modules\nimport time, random\n\n# define our functions\ndef inc(x):\n    time.sleep(random.random())\n    return x + 1\n\ndef dec(x):\n    time.sleep(random.random())\n    return x - 1\n\ndef add(x, y):\n    time.sleep(random.random())\n    return x + y\n\n\n%%time\n\n# a sequential example with no parallelization\nresults = []\nfor x in range(20):\n    result = inc(x)\n    result = dec(result)\n    results.append(result)\n\nprint(results)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\nCPU times: user 3.4 ms, sys: 92 µs, total: 3.49 ms\nWall time: 17.4 s\n\n\n\n# import dask for parallel work\nfrom dask.distributed import Client, LocalCluster\n\n\n# Set up our cluster with default workers and threads\ncluster = LocalCluster(processes=False)\ncluster\n\n\n\n\n\n%%time\n# Set up a client for work\nclient = cluster.get_client()\n\nresults = []\nfor x in range(20):\n    result = client.submit(inc, x)\n    result = client.submit(dec, result)\n    results.append(result)\n\nresults = client.gather(results)\nprint(results)\nclient.close()\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\nCPU times: user 450 ms, sys: 63 ms, total: 513 ms\nWall time: 6.01 s\n\n\n\n# When we are done we can close our dask cluster\ncluster.close()\n\n\n# Set up a new cluster with default 4 workers and 1 thread per worker\ncluster = LocalCluster(n_workers=4, processes=False, threads_per_worker=1)\ncluster\n\n\n\n\n\n%%time\n# Set up a client for work\nclient = cluster.get_client()\n\nresults = []\nfor x in range(20):\n    result = client.submit(inc, x)\n    result = client.submit(dec, result)\n    results.append(result)\n\nresults = client.gather(results)\nprint(results)\nclient.close()\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\nCPU times: user 500 ms, sys: 55 ms, total: 555 ms\nWall time: 4.47 s\n\n\n\n# When we are done we can close our dask cluster\ncluster.close()"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html",
    "href": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html",
    "title": "Watching a solar eclipse using an OOI moored echosounder",
    "section": "",
    "text": "Jupyter notebook accompanying the manuscript:\nEchopype: A Python library for interoperable and scalable processing of ocean sonar data for biological information\nAuthors: Wu-Jung Lee, Emilio Mayorga, Landung Setiawan, Kavin Nguyen, Imran Majeed, Valentina Staneva"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#introduction",
    "href": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#introduction",
    "title": "Watching a solar eclipse using an OOI moored echosounder",
    "section": "Introduction",
    "text": "Introduction\n\nGoals\n\nIllustrate a common workflow for echosounder data conversion, calibration and use. This workflow leverages the standardization applied by echopype. and the power, ease of use and familiarity of libraries in the scientific Python ecosystem.\nDemonstrate the ease to interoperate echosounder data with those from a different instrument in a single computing environment. Without echopype, additional wrangling across more than one software systems is needed to achieve the same visualization and comparison.\n\n\n\nDescription\nThis notebook uses EK60 echosounder data from the U.S. Ocean Observatories Initiative (OOI) to illustrate a common workflow for data conversion, combination, calibration and analysis using echopype, as well as the data interoperability it enables. Without echopype, additional wrangling across more than one software systems is needed to achieve the same visualization and comparison.\nWe will use data from the OOI Oregon Offshore Cabled Shallow Profiler Mooring collected on August 20-21, 2017. This was the day before and of a solar eclipse, during which the reduced sunlight affected the regular diel vertical migration (DVM) patterns of marine life. This change was directly observed using the upward-looking echosounder mounted on this mooring platform that happened to be within the totality zone. The effect of the solar eclipse was clearly seen by aligning and comparing the echosounder observations with solar radiation data collected by the Bulk Meteorology Instrument Package located on the nearby Coastal Endurance Oregon Offshore Surface Mooring, also maintained by the OOI.\nThe data used are 19 .raw files with a total volume of approximately 1 GB. With echopype functionality, the raw data files hosted on the OOI Raw Data Archive (an HTTP server) are directly parsed and organized into a standardized representation following in the SONAR-netCDF4 v1.0 convention, and stored to the cloud-optimized Zarr format. The individual converted files are later combined into a single entity that can be easily explored and manipulated.\n\n\nOutline\n\nEstablish connection with the OOI Raw Data Archive and generate list of target EK60 .raw files\nProcess the archived raw files with echopype: convert and combine into a single quantity (an EchoData object) in a standardized format.\nObtain solar radiation data from an OOI Thredds server.\nPlot the echosounder and solar radiation data together to visualize the zooplankton response to a solar eclipse.\n\n\n\nRunning the notebook\nThis notebook can be run with a conda environment created using the conda environment file https://github.com/OSOceanAcoustics/echopype-examples/blob/main/binder/environment.yml. The notebook creates a directory ./exports/notebook3 and save all generated Zarr and netCDF files there.\n\n\nWarning\nThe compute_MVBS step in this notebook is not efficient for lazy-loaded data with echopype version 0.6.3. We plan to address this issue soon.\n\n\nNote\nWe encourage importing echopype as ep for consistency.\n\nfrom pathlib import Path\nimport itertools as it\nimport datetime as dt\nfrom dateutil import parser as dtparser\n\nimport fsspec\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport hvplot.xarray\nimport panel\n\nimport echopype as ep\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#establish-connection-with-the-ooi-raw-data-archive-and-generate-list-of-target-ek60-.raw-files",
    "href": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#establish-connection-with-the-ooi-raw-data-archive-and-generate-list-of-target-ek60-.raw-files",
    "title": "Watching a solar eclipse using an OOI moored echosounder",
    "section": "Establish connection with the OOI Raw Data Archive and generate list of target EK60 .raw files",
    "text": "Establish connection with the OOI Raw Data Archive and generate list of target EK60 .raw files\nAccess and inspect the publicly accessible OOI Raw Data Archive (an HTTP server) as if it were a local file system. This will be done through the Python fsspec file system and bytes storage interface. We will use fsspec.filesystem.glob (fs.glob) to generate a list of all EK60 .raw data files in the archive then filter on file names for target dates of interest.\n\nfs = fsspec.filesystem('https')\n\n\nooi_raw_url = (\n    \"https://rawdata.oceanobservatories.org/files/\"\n    \"CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/2017/08\"\n)\n\nNow let’s specify the range of dates we will be pulling data from. Note that the data filenames contain the time information but were recorded at UTC time.\n\ndef in_range(raw_file: str, start: dt.datetime, end: dt.datetime) -&gt; bool:\n    \"\"\"Check if file url is in datetime range\"\"\"\n    file_name = Path(raw_file).name\n    file_datetime = dtparser.parse(file_name, fuzzy=True)\n    return file_datetime &gt;= start and file_datetime &lt;= end\n\n\nstart_datetime = dt.datetime(2017, 8, 21, 7, 0)\nend_datetime = dt.datetime(2017, 8, 22, 7, 0)\n\nOn the OOI Raw Data Archive, the monthly folder is further split to daily folders, so we can simply grab data from the desired days.\n\ndesired_day_urls = [f\"{ooi_raw_url}/{day}\" for day in range(start_datetime.day, end_datetime.day + 1)]\n\n\ndesired_day_urls\n\n['https://rawdata.oceanobservatories.org/files/CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/2017/08/21',\n 'https://rawdata.oceanobservatories.org/files/CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/2017/08/22']\n\n\nGrab all raw files within daily folders by using the filesytem glob, just like the Linux glob.\n\nall_raw_file_urls = it.chain.from_iterable([fs.glob(f\"{day_url}/*.raw\") for day_url in desired_day_urls])\n\n\ndesired_raw_file_urls = list(filter(\n    lambda raw_file: in_range(\n        raw_file, \n        start_datetime-dt.timedelta(hours=3),  # 3 hour buffer to select files\n        end_datetime+dt.timedelta(hours=3)\n    ), \n    all_raw_file_urls\n))\n\n\nprint(f\"There are {len(desired_raw_file_urls)} raw files within the specified datetime range.\")\n\nThere are 19 raw files within the specified datetime range."
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#process-the-archived-raw-files-with-echopype",
    "href": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#process-the-archived-raw-files-with-echopype",
    "title": "Watching a solar eclipse using an OOI moored echosounder",
    "section": "Process the archived raw files with echopype",
    "text": "Process the archived raw files with echopype\n\nExamine the workflow by processing just one file\nLet’s first test the echopype workflow by converting and processing 1 file from the above list.\nWe will use ep.open_raw to directly read in a raw data file from the OOI HTTP server.\nThe type of sonar needs to be specified as an input argument. The echosounders on the OOI Regional Cabled Array are Simrad EK60 echosounder. All other uncabled echosounders are the Acoustic Zooplankton and Fisher Profiler (AZFP) manufacturered by ASL Environmental Sciences. Echopype supports both of these and other instruments (see echopype documentation for detail).\n\n\nConverting from raw data files to a standardized data format\nBelow we already know the path to the 1 file on the http server:\n\nechodata = ep.open_raw(raw_file=desired_raw_file_urls[0], sonar_model=\"ek60\")\n\nHere echopype read, parse, and convert content of the raw file into memory, and gives you a nice representation of the converted file below as a Python EchoData object.\n\nechodata\n\n\n    \n        EchoData: standardized raw data from Internal Memory\n    \n    \n        \n            Top-level: contains metadata about the SONAR-netCDF4 file format.\n            \n            \n                \n                    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 0B\nDimensions:  ()\nData variables:\n    *empty*\nAttributes:\n    conventions:                 CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3\n    keywords:                    EK60\n    sonar_convention_authority:  ICES\n    sonar_convention_name:       SONAR-netCDF4\n    sonar_convention_version:    1.0\n    summary:                     \n    title:                       \n    date_created:                2017-08-21T04:57:17Zxarray.DatasetDimensions:Coordinates: (0)Data variables: (0)Indexes: (0)Attributes: (8)conventions :CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3keywords :EK60sonar_convention_authority :ICESsonar_convention_name :SONAR-netCDF4sonar_convention_version :1.0summary :title :date_created :2017-08-21T04:57:17Z\n                \n            \n        \n        \n                    Environment: contains information relevant to acoustic propagation through water.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 332kB\nDimensions:                 (channel: 3, time1: 5923)\nCoordinates:\n  * channel                 (channel) &lt;U39 468B 'GPT  38 kHz 00907208dd13 5-1...\n  * time1                   (time1) datetime64[ns] 47kB 2017-08-21T04:57:17.3...\nData variables:\n    absorption_indicative   (channel, time1) float64 142kB 0.009785 ... 0.05269\n    sound_speed_indicative  (channel, time1) float64 142kB 1.494e+03 ... 1.49...\n    frequency_nominal       (channel) float64 24B 3.8e+04 1.2e+05 2e+05xarray.DatasetDimensions:channel: 3time1: 5923Coordinates: (2)channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')time1(time1)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...axis :Tlong_name :Timestamps for NMEA position datagramsstandard_name :timecomment :Time coordinate corresponding to environmental variables.array(['2017-08-21T04:57:17.329287000', '2017-08-21T04:57:18.332344000',\n       '2017-08-21T04:57:19.335403000', ..., '2017-08-21T06:36:15.549934000',\n       '2017-08-21T06:36:16.552992000', '2017-08-21T06:36:17.556049000'],\n      dtype='datetime64[ns]')Data variables: (3)absorption_indicative(channel, time1)float640.009785 0.009785 ... 0.05269long_name :Indicative acoustic absorptionunits :dB/mvalid_min :0.0array([[0.00978527, 0.00978527, 0.00978527, ..., 0.00978527, 0.00978527,\n        0.00978527],\n       [0.03744031, 0.03744031, 0.03744031, ..., 0.03744031, 0.03744031,\n        0.03744031],\n       [0.05268759, 0.05268759, 0.05268759, ..., 0.05268759, 0.05268759,\n        0.05268759]])sound_speed_indicative(channel, time1)float641.494e+03 1.494e+03 ... 1.494e+03long_name :Indicative sound speedstandard_name :speed_of_sound_in_sea_waterunits :m/svalid_min :0.0array([[1493.88879395, 1493.88879395, 1493.88879395, ..., 1493.88879395,\n        1493.88879395, 1493.88879395],\n       [1493.88879395, 1493.88879395, 1493.88879395, ..., 1493.88879395,\n        1493.88879395, 1493.88879395],\n       [1493.88879395, 1493.88879395, 1493.88879395, ..., 1493.88879395,\n        1493.88879395, 1493.88879395]])frequency_nominal(channel)float643.8e+04 1.2e+05 2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 38000., 120000., 200000.])Indexes: (2)channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287', '2017-08-21 04:57:18.332344',\n               '2017-08-21 04:57:19.335403', '2017-08-21 04:57:20.338461',\n               '2017-08-21 04:57:21.341518', '2017-08-21 04:57:22.344574',\n               '2017-08-21 04:57:23.347631', '2017-08-21 04:57:24.350689',\n               '2017-08-21 04:57:25.353746', '2017-08-21 04:57:26.356804',\n               ...\n               '2017-08-21 06:36:08.528532', '2017-08-21 06:36:09.531590',\n               '2017-08-21 06:36:10.534647', '2017-08-21 06:36:11.537704',\n               '2017-08-21 06:36:12.540762', '2017-08-21 06:36:13.543819',\n               '2017-08-21 06:36:14.546877', '2017-08-21 06:36:15.549934',\n               '2017-08-21 06:36:16.552992', '2017-08-21 06:36:17.556049'],\n              dtype='datetime64[ns]', name='time1', length=5923, freq=None))Attributes: (0)\n                        \n                    \n                \n                    Platform: contains information about the platform on which the sonar is installed.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 190kB\nDimensions:              (time1: 1, time2: 5923, channel: 3)\nCoordinates:\n  * time1                (time1) datetime64[ns] 8B 2017-08-21T04:57:17.329287\n  * time2                (time2) datetime64[ns] 47kB 2017-08-21T04:57:17.3292...\n  * channel              (channel) &lt;U39 468B 'GPT  38 kHz 00907208dd13 5-1 OO...\nData variables: (12/20)\n    latitude             (time1) float64 8B nan\n    longitude            (time1) float64 8B nan\n    sentence_type        (time1) float64 8B nan\n    pitch                (time2) float64 47kB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n    roll                 (time2) float64 47kB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n    vertical_offset      (time2) float64 47kB 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n    ...                   ...\n    position_offset_y    float64 8B nan\n    position_offset_z    float64 8B nan\n    transducer_offset_x  (channel) float64 24B 0.0 0.0 0.0\n    transducer_offset_y  (channel) float64 24B 0.0 0.0 0.0\n    transducer_offset_z  (channel) float64 24B 0.0 0.0 0.0\n    frequency_nominal    (channel) float64 24B 3.8e+04 1.2e+05 2e+05\nAttributes:\n    platform_name:       \n    platform_type:       \n    platform_code_ICES:  xarray.DatasetDimensions:time1: 1time2: 5923channel: 3Coordinates: (3)time1(time1)datetime64[ns]2017-08-21T04:57:17.329287axis :Tlong_name :Timestamps for NMEA datagramsstandard_name :timecomment :Time coordinate corresponding to NMEA position data.array(['2017-08-21T04:57:17.329287000'], dtype='datetime64[ns]')time2(time2)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...axis :Tlong_name :Timestamps for platform motion and orientation datastandard_name :timecomment :Time coordinate corresponding to platform motion and orientation data.array(['2017-08-21T04:57:17.329287000', '2017-08-21T04:57:18.332344000',\n       '2017-08-21T04:57:19.335403000', ..., '2017-08-21T06:36:15.549934000',\n       '2017-08-21T06:36:16.552992000', '2017-08-21T06:36:17.556049000'],\n      dtype='datetime64[ns]')channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')Data variables: (20)latitude(time1)float64nanlong_name :Platform latitudestandard_name :latitudeunits :degrees_northvalid_range :(-90.0, 90.0)array([nan])longitude(time1)float64nanlong_name :Platform longitudestandard_name :longitudeunits :degrees_eastvalid_range :(-180.0, 180.0)array([nan])sentence_type(time1)float64nanlong_name :NMEA sentence typearray([nan])pitch(time2)float640.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0long_name :Platform pitchstandard_name :platform_pitch_angleunits :arc_degreevalid_range :(-90.0, 90.0)array([0., 0., 0., ..., 0., 0., 0.])roll(time2)float640.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0long_name :Platform rollstandard_name :platform_roll_angleunits :arc_degreevalid_range :(-90.0, 90.0)array([0., 0., 0., ..., 0., 0., 0.])vertical_offset(time2)float640.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0long_name :Platform vertical offset from nominal water levelunits :marray([0., 0., 0., ..., 0., 0., 0.])water_level()float640.0long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(0.)MRU_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_rotation_x()float64nanlong_name :Extrinsic rotation about the x-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_y()float64nanlong_name :Extrinsic rotation about the y-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_z()float64nanlong_name :Extrinsic rotation about the z-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)position_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)transducer_offset_x(channel)float640.0 0.0 0.0long_name :x-axis distance from the platform coordinate system origin to the sonar transducerunits :marray([0., 0., 0.])transducer_offset_y(channel)float640.0 0.0 0.0long_name :y-axis distance from the platform coordinate system origin to the sonar transducerunits :marray([0., 0., 0.])transducer_offset_z(channel)float640.0 0.0 0.0long_name :z-axis distance from the platform coordinate system origin to the sonar transducerunits :marray([0., 0., 0.])frequency_nominal(channel)float643.8e+04 1.2e+05 2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 38000., 120000., 200000.])Indexes: (3)time1PandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287'], dtype='datetime64[ns]', name='time1', freq=None))time2PandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287', '2017-08-21 04:57:18.332344',\n               '2017-08-21 04:57:19.335403', '2017-08-21 04:57:20.338461',\n               '2017-08-21 04:57:21.341518', '2017-08-21 04:57:22.344574',\n               '2017-08-21 04:57:23.347631', '2017-08-21 04:57:24.350689',\n               '2017-08-21 04:57:25.353746', '2017-08-21 04:57:26.356804',\n               ...\n               '2017-08-21 06:36:08.528532', '2017-08-21 06:36:09.531590',\n               '2017-08-21 06:36:10.534647', '2017-08-21 06:36:11.537704',\n               '2017-08-21 06:36:12.540762', '2017-08-21 06:36:13.543819',\n               '2017-08-21 06:36:14.546877', '2017-08-21 06:36:15.549934',\n               '2017-08-21 06:36:16.552992', '2017-08-21 06:36:17.556049'],\n              dtype='datetime64[ns]', name='time2', length=5923, freq=None))channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))Attributes: (3)platform_name :platform_type :platform_code_ICES :\n                        \n                    \n                \n                    NMEA: contains information specific to the NMEA protocol.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 96B\nDimensions:        (time1: 1)\nCoordinates:\n  * time1          (time1) datetime64[ns] 8B 2017-08-21T04:57:17.329287\nData variables:\n    NMEA_datagram  (time1) &lt;U22 88B '$SDVLW,0.000,N,0.000,N'\nAttributes:\n    description:  All NMEA sensor datagramsxarray.DatasetDimensions:time1: 1Coordinates: (1)time1(time1)datetime64[ns]2017-08-21T04:57:17.329287axis :Tlong_name :Timestamps for NMEA datagramsstandard_name :timecomment :Time coordinate corresponding to NMEA sensor data.array(['2017-08-21T04:57:17.329287000'], dtype='datetime64[ns]')Data variables: (1)NMEA_datagram(time1)&lt;U22'$SDVLW,0.000,N,0.000,N'long_name :NMEA datagramarray(['$SDVLW,0.000,N,0.000,N'], dtype='&lt;U22')Indexes: (1)time1PandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287'], dtype='datetime64[ns]', name='time1', freq=None))Attributes: (1)description :All NMEA sensor datagrams\n                        \n                    \n                \n                    Provenance: contains metadata about how the SONAR-netCDF4 version of the data were obtained.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 484B\nDimensions:           (filenames: 1)\nCoordinates:\n  * filenames         (filenames) int64 8B 0\nData variables:\n    source_filenames  (filenames) &lt;U119 476B 'https://rawdata.oceanobservator...\nAttributes:\n    conversion_software_name:     echopype\n    conversion_software_version:  0.8.4.dev58+gae911de\n    conversion_time:              2024-04-26T18:38:27Zxarray.DatasetDimensions:filenames: 1Coordinates: (1)filenames(filenames)int640long_name :Index for data and metadata source filenamesarray([0])Data variables: (1)source_filenames(filenames)&lt;U119'https://rawdata.oceanobservator...long_name :Source filenamesarray(['https://rawdata.oceanobservatories.org/files/CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/2017/08/21/OOI-D20170821-T045717.raw'],\n      dtype='&lt;U119')Indexes: (1)filenamesPandasIndexPandasIndex(Index([0], dtype='int64', name='filenames'))Attributes: (3)conversion_software_name :echopypeconversion_software_version :0.8.4.dev58+gae911deconversion_time :2024-04-26T18:38:27Z\n                        \n                    \n                \n                    Sonar: contains sonar system metadata and sonar beam groups.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 568B\nDimensions:           (beam_group: 1)\nCoordinates:\n  * beam_group        (beam_group) &lt;U11 44B 'Beam_group1'\nData variables:\n    beam_group_descr  (beam_group) &lt;U131 524B 'contains backscatter power (un...\nAttributes:\n    sonar_manufacturer:      Simrad\n    sonar_model:             EK60\n    sonar_serial_number:     \n    sonar_software_name:     ER60\n    sonar_software_version:  2.4.3\n    sonar_type:              echosounderxarray.DatasetDimensions:beam_group: 1Coordinates: (1)beam_group(beam_group)&lt;U11'Beam_group1'long_name :Beam group namearray(['Beam_group1'], dtype='&lt;U11')Data variables: (1)beam_group_descr(beam_group)&lt;U131'contains backscatter power (unc...long_name :Beam group descriptionarray(['contains backscatter power (uncalibrated) and other beam or channel-specific data, including split-beam angle data when they exist.'],\n      dtype='&lt;U131')Indexes: (1)beam_groupPandasIndexPandasIndex(Index(['Beam_group1'], dtype='object', name='beam_group'))Attributes: (6)sonar_manufacturer :Simradsonar_model :EK60sonar_serial_number :sonar_software_name :ER60sonar_software_version :2.4.3sonar_type :echosounder\n                        \n                    \n                \n                    Beam_group1: contains backscatter power (uncalibrated) and other beam or channel-specific data, including split-beam angle data when they exist.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 229MB\nDimensions:                        (channel: 3, ping_time: 5923,\n                                    range_sample: 1072)\nCoordinates:\n  * channel                        (channel) &lt;U39 468B 'GPT  38 kHz 00907208d...\n  * ping_time                      (ping_time) datetime64[ns] 47kB 2017-08-21...\n  * range_sample                   (range_sample) int64 9kB 0 1 2 ... 1070 1071\nData variables: (12/29)\n    frequency_nominal              (channel) float64 24B 3.8e+04 1.2e+05 2e+05\n    beam_type                      (channel) int64 24B 0 1 0\n    beamwidth_twoway_alongship     (channel) float64 24B 7.1 7.0 7.0\n    beamwidth_twoway_athwartship   (channel) float64 24B 7.1 7.0 7.0\n    beam_direction_x               (channel) float64 24B nan nan nan\n    beam_direction_y               (channel) float64 24B nan nan nan\n    ...                             ...\n    data_type                      (channel, ping_time) int8 18kB 1 1 1 ... 1 1\n    sample_time_offset             (channel, ping_time) float64 142kB 0.0 ......\n    channel_mode                   (channel, ping_time) int8 18kB 0 0 0 ... 0 0\n    backscatter_r                  (channel, ping_time, range_sample) float32 76MB ...\n    angle_athwartship              (channel, ping_time, range_sample) float32 76MB ...\n    angle_alongship                (channel, ping_time, range_sample) float32 76MB ...\nAttributes:\n    beam_mode:              vertical\n    conversion_equation_t:  type_3xarray.DatasetDimensions:channel: 3ping_time: 5923range_sample: 1072Coordinates: (3)channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')ping_time(ping_time)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...long_name :Timestamp of each pingstandard_name :timeaxis :Tarray(['2017-08-21T04:57:17.329287000', '2017-08-21T04:57:18.332344000',\n       '2017-08-21T04:57:19.335403000', ..., '2017-08-21T06:36:15.549934000',\n       '2017-08-21T06:36:16.552992000', '2017-08-21T06:36:17.556049000'],\n      dtype='datetime64[ns]')range_sample(range_sample)int640 1 2 3 4 ... 1068 1069 1070 1071long_name :Along-range sample number, base 0array([   0,    1,    2, ..., 1069, 1070, 1071])Data variables: (29)frequency_nominal(channel)float643.8e+04 1.2e+05 2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 38000., 120000., 200000.])beam_type(channel)int640 1 0long_name :type of transducer (0-single, 1-split)array([0, 1, 0])beamwidth_twoway_alongship(channel)float647.1 7.0 7.0long_name :Half power two-way beam width along alongship axis of beamunits :arc_degreevalid_range :(0.0, 360.0)comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_minor and beamwidth_transmit_minor), but Simrad echosounders record two-way beamwidth in the data.array([7.0999999, 7.       , 7.       ])beamwidth_twoway_athwartship(channel)float647.1 7.0 7.0long_name :Half power two-way beam width along athwartship axis of beamunits :arc_degreevalid_range :(0.0, 360.0)comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_major and beamwidth_transmit_major), but Simrad echosounders record two-way beamwidth in the data.array([7.0999999, 7.       , 7.       ])beam_direction_x(channel)float64nan nan nanlong_name :x-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :(-1.0, 1.0)array([nan, nan, nan])beam_direction_y(channel)float64nan nan nanlong_name :y-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :(-1.0, 1.0)array([nan, nan, nan])beam_direction_z(channel)float64nan nan nanlong_name :z-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :(-1.0, 1.0)array([nan, nan, nan])angle_offset_alongship(channel)float640.0 0.0 0.0long_name :electrical alongship angle offset of the transducercomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([0., 0., 0.])angle_offset_athwartship(channel)float640.0 0.0 0.0long_name :electrical athwartship angle offset of the transducercomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([0., 0., 0.])angle_sensitivity_alongship(channel)float6421.9 23.0 23.0long_name :alongship angle sensitivity of the transducercomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([21.89999962, 23.        , 23.        ])angle_sensitivity_athwartship(channel)float6421.9 23.0 23.0long_name :athwartship angle sensitivity of the transducercomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([21.89999962, 23.        , 23.        ])equivalent_beam_angle(channel)float64-20.6 -20.7 -20.7long_name :Equivalent beam angleunits :srvalid_range :(0.0, 12.566370614359172)array([-20.60000038, -20.70000076, -20.70000076])gain_correction(channel)float6426.5 25.0 25.0long_name :Gain correctionunits :dBarray([26.5, 25. , 25. ])gpt_software_version(channel)&lt;U6'150120' '070413' '150120'array(['150120', '070413', '150120'], dtype='&lt;U6')transmit_frequency_start(channel)float643.8e+04 1.2e+05 2e+05long_name :Start frequency in transmitted pulseunits :Hzstandard_name :sound_frequencyvalid_min :0.0array([ 38000., 120000., 200000.])transmit_frequency_stop(channel)float643.8e+04 1.2e+05 2e+05long_name :Stop frequency in transmitted pulseunits :Hzstandard_name :sound_frequencyvalid_min :0.0array([ 38000., 120000., 200000.])transmit_type()&lt;U2'CW'long_name :Type of transmitted pulseflag_values :['CW']flag_meanings :['Continuous Wave – a pulse nominally of one frequency']array('CW', dtype='&lt;U2')beam_stabilisation()int80long_name :Beam stabilisation applied (or not)flag_values :[0, 1]flag_meanings :['not stabilised', 'stabilised']array(0, dtype=int8)non_quantitative_processing()int160long_name :Presence or not of non-quantitative processing applied to the backscattering data (sonar specific)flag_values :[0]flag_meanings :['None']array(0, dtype=int16)sample_interval(channel, ping_time)float640.000256 0.000256 ... 0.000256long_name :Interval between recorded raw data samplesunits :svalid_min :0.0array([[0.000256, 0.000256, 0.000256, ..., 0.000256, 0.000256, 0.000256],\n       [0.000256, 0.000256, 0.000256, ..., 0.000256, 0.000256, 0.000256],\n       [0.000256, 0.000256, 0.000256, ..., 0.000256, 0.000256, 0.000256]])transmit_bandwidth(channel, ping_time)float642.425e+03 2.425e+03 ... 3.088e+03long_name :Nominal bandwidth of transmitted pulseunits :Hzvalid_min :0.0array([[2425.1496582 , 2425.1496582 , 2425.1496582 , ..., 2425.1496582 ,\n        2425.1496582 , 2425.1496582 ],\n       [3026.39160156, 3026.39160156, 3026.39160156, ..., 3026.39160156,\n        3026.39160156, 3026.39160156],\n       [3088.40039062, 3088.40039062, 3088.40039062, ..., 3088.40039062,\n        3088.40039062, 3088.40039062]])transmit_duration_nominal(channel, ping_time)float640.001024 0.001024 ... 0.001024long_name :Nominal bandwidth of transmitted pulseunits :svalid_min :0.0array([[0.001024, 0.001024, 0.001024, ..., 0.001024, 0.001024, 0.001024],\n       [0.001024, 0.001024, 0.001024, ..., 0.001024, 0.001024, 0.001024],\n       [0.001024, 0.001024, 0.001024, ..., 0.001024, 0.001024, 0.001024]])transmit_power(channel, ping_time)float64500.0 500.0 500.0 ... 150.0 150.0long_name :Nominal transmit powerunits :Wvalid_min :0.0array([[500., 500., 500., ..., 500., 500., 500.],\n       [250., 250., 250., ..., 250., 250., 250.],\n       [150., 150., 150., ..., 150., 150., 150.]])data_type(channel, ping_time)int81 1 1 1 1 1 1 1 ... 1 1 1 1 1 1 1 1long_name :recorded data type (1=power only, 2=angle only, 3=power and angle)flag_values :[1, 2, 3]flag_meanings :['power only', 'angle only', 'power and angle']array([[1, 1, 1, ..., 1, 1, 1],\n       [3, 3, 3, ..., 3, 3, 3],\n       [1, 1, 1, ..., 1, 1, 1]], dtype=int8)sample_time_offset(channel, ping_time)float640.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0long_name :Time offset that is subtracted from the timestamp of each sampleunits :sarray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])channel_mode(channel, ping_time)int80 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0long_name :Transceiver modeflag_values :[-1, 0, 1, 2]flag_meanings :['Unknown', 'Active', 'Passive', 'Test']comment :From transmit_mode in the EK60 datagramarray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)backscatter_r(channel, ping_time, range_sample)float3211.97 19.57 19.36 ... -134.3 -135.7long_name :Raw backscatter measurements (real part)units :dBarray([[[  11.970646,   19.56695 ,   19.355288, ...,  -98.787224,\n          -98.164   ,  -99.70443 ],\n        [  11.970646,   19.56695 ,   19.355288, ..., -105.54864 ,\n         -103.78479 , -101.65642 ],\n        [  11.958887,   19.56695 ,   19.343529, ..., -102.608894,\n         -101.691696,  -99.63387 ],\n        ...,\n        [  11.982405,   19.578709,   19.355288, ..., -102.72649 ,\n         -115.238045, -119.153786],\n        [  11.982405,   19.578709,   19.355288, ..., -101.75049 ,\n         -101.46828 , -107.31249 ],\n        [  11.958887,   19.555191,   19.343529, ..., -103.667206,\n         -109.51142 , -119.61239 ]],\n\n       [[  12.076477,   17.908934,   17.885414, ..., -123.75155 ,\n         -116.00238 , -110.32279 ],\n        [  12.076477,   17.908934,   17.885414, ..., -112.06312 ,\n         -119.31841 , -120.635414],\n        [  12.088236,   17.908934,   17.885414, ..., -114.03863 ,\n         -117.43697 , -118.530556],\n...\n        [  12.076477,   17.908934,   17.873655, ..., -114.66185 ,\n         -114.47371 , -116.8843  ],\n        [  12.076477,   17.908934,   17.885414, ..., -111.59276 ,\n         -121.2704  , -117.58984 ],\n        [  12.076477,   17.908934,   17.873655, ..., -114.26205 ,\n         -117.07245 , -118.0602  ]],\n\n       [[-124.17487 , -141.24892 , -141.15485 , ..., -149.09216 ,\n         -147.79868 , -135.38118 ],\n        [-133.01762 , -141.20187 , -141.15485 , ..., -130.92453 ,\n         -127.243965, -127.23221 ],\n        [-127.66729 , -141.1078  , -141.17836 , ..., -133.47623 ,\n         -132.74718 , -132.10043 ],\n        ...,\n        [-136.98041 , -141.15485 , -141.17836 , ..., -147.15193 ,\n         -132.57079 , -131.15971 ],\n        [-124.82162 , -141.03726 , -141.17836 , ..., -134.88731 ,\n         -133.89955 , -133.14697 ],\n        [-131.7947  , -141.17836 , -141.17836 , ..., -132.02988 ,\n         -134.25232 , -135.7222  ]]], dtype=float32)angle_athwartship(channel, ping_time, range_sample)float32nan nan nan nan ... nan nan nan nanlong_name :electrical athwartship anglecomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([[[  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        ...,\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]],\n\n       [[  -1.,   -2.,   -2., ..., -118., -128.,  -85.],\n        [  -2.,   -2.,   -2., ...,   18.,  103., -123.],\n        [  -1.,   -2.,   -2., ..., -111., -108.,  -80.],\n        ...,\n        [  -1.,   -2.,   -2., ..., -112.,    4.,  104.],\n        [  -2.,   -2.,   -2., ...,  -37.,  -58.,  -54.],\n        [  -1.,   -2.,   -2., ...,   24.,  -29., -100.]],\n\n       [[  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        ...,\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n        [  nan,   nan,   nan, ...,   nan,   nan,   nan]]], dtype=float32)angle_alongship(channel, ping_time, range_sample)float32nan nan nan nan ... nan nan nan nanlong_name :electrical alongship anglecomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        ...,\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n\n       [[ -1.,  -2.,  -2., ..., 107.,  92.,  58.],\n        [ -1.,  -2.,  -2., ..., -22., -40., -10.],\n        [ -1.,  -2.,  -2., ..., -29., -37.,  40.],\n        ...,\n        [ -1.,  -2.,  -2., ..., -30., -57., -96.],\n        [ -1.,  -2.,  -2., ...,  20., -55., 111.],\n        [ -1.,  -2.,  -2., ..., -80., -93.,  73.]],\n\n       [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        ...,\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n        [ nan,  nan,  nan, ...,  nan,  nan,  nan]]], dtype=float32)Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287', '2017-08-21 04:57:18.332344',\n               '2017-08-21 04:57:19.335403', '2017-08-21 04:57:20.338461',\n               '2017-08-21 04:57:21.341518', '2017-08-21 04:57:22.344574',\n               '2017-08-21 04:57:23.347631', '2017-08-21 04:57:24.350689',\n               '2017-08-21 04:57:25.353746', '2017-08-21 04:57:26.356804',\n               ...\n               '2017-08-21 06:36:08.528532', '2017-08-21 06:36:09.531590',\n               '2017-08-21 06:36:10.534647', '2017-08-21 06:36:11.537704',\n               '2017-08-21 06:36:12.540762', '2017-08-21 06:36:13.543819',\n               '2017-08-21 06:36:14.546877', '2017-08-21 06:36:15.549934',\n               '2017-08-21 06:36:16.552992', '2017-08-21 06:36:17.556049'],\n              dtype='datetime64[ns]', name='ping_time', length=5923, freq=None))range_samplePandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071],\n      dtype='int64', name='range_sample', length=1072))Attributes: (2)beam_mode :verticalconversion_equation_t :type_3\n                        \n                    \n                \n                    Vendor_specific: contains vendor-specific information about the sonar and the data.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 892B\nDimensions:            (channel: 3, pulse_length_bin: 5)\nCoordinates:\n  * channel            (channel) &lt;U39 468B 'GPT  38 kHz 00907208dd13 5-1 OOI....\n  * pulse_length_bin   (pulse_length_bin) int64 40B 0 1 2 3 4\nData variables:\n    frequency_nominal  (channel) float64 24B 3.8e+04 1.2e+05 2e+05\n    sa_correction      (channel, pulse_length_bin) float64 120B 0.0 0.0 ... 0.0\n    gain_correction    (channel, pulse_length_bin) float64 120B 24.0 ... 25.0\n    pulse_length       (channel, pulse_length_bin) float64 120B 0.000256 ... ...xarray.DatasetDimensions:channel: 3pulse_length_bin: 5Coordinates: (2)channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')pulse_length_bin(pulse_length_bin)int640 1 2 3 4array([0, 1, 2, 3, 4])Data variables: (4)frequency_nominal(channel)float643.8e+04 1.2e+05 2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 38000., 120000., 200000.])sa_correction(channel, pulse_length_bin)float640.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0array([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])gain_correction(channel, pulse_length_bin)float6424.0 26.0 26.5 ... 25.0 25.0 25.0array([[24.      , 26.      , 26.5     , 26.5     , 26.5     ],\n       [23.5     , 24.799999, 25.      , 25.      , 25.      ],\n       [23.5     , 24.799999, 25.      , 25.      , 25.      ]])pulse_length(channel, pulse_length_bin)float640.000256 0.000512 ... 0.001024array([[2.560e-04, 5.120e-04, 1.024e-03, 2.048e-03, 4.096e-03],\n       [6.400e-05, 1.280e-04, 2.560e-04, 5.120e-04, 1.024e-03],\n       [6.400e-05, 1.280e-04, 2.560e-04, 5.120e-04, 1.024e-03]])Indexes: (2)channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))pulse_length_binPandasIndexPandasIndex(Index([0, 1, 2, 3, 4], dtype='int64', name='pulse_length_bin'))Attributes: (0)\n                        \n                    \n                \n    \n\n\n\nThe EchoData object can be saved to either the netCDF4 or zarr formats through to_netcdf or to_zarr methods.\n\n# Create directory for files generated in this notebook\nbase_dpath = Path('./exports/notebook3')\nbase_dpath.mkdir(exist_ok=True, parents=True)\n\n\n# Create directory for single-raw-file example\noutput_dpath = Path(base_dpath / 'onefiletest')\noutput_dpath.mkdir(exist_ok=True)\n\n\n# Save to netCDF format\nechodata.to_netcdf(save_path=output_dpath, overwrite=True)\n\n\n# Save to zarr format\nechodata.to_zarr(save_path=output_dpath, overwrite=True)\n\n\n\nBasic echo processing\nAt present echopype supports basic processing funcionalities including calibration (from raw instrument data records to volume backscattering strength, \\(S_V\\)), denoising, and computing mean volume backscattering strength, \\(\\overline{S_V}\\) or \\(\\text{MVBS}\\). The Echodata object can be passed into various calibrate and preprocessing functions without having to write out any intermediate files.\nHere we demonstrate calibration to obtain \\(S_V\\). For EK60 data, by default the function uses environmental (sound speed and absorption) and calibration parameters stored in the data file. Users can optionally specify other parameter choices.\n\n# Compute volume backscattering strength (Sv) from raw data\nds_Sv = ep.calibrate.compute_Sv(echodata)\n\nThe computed Sv is stored with other variables used in the calibration operation.\n\nds_Sv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 305MB\nDimensions:                        (channel: 3, ping_time: 5923,\n                                    range_sample: 1072, filenames: 1)\nCoordinates:\n  * channel                        (channel) &lt;U39 468B 'GPT  38 kHz 00907208d...\n  * ping_time                      (ping_time) datetime64[ns] 47kB 2017-08-21...\n  * range_sample                   (range_sample) int64 9kB 0 1 2 ... 1070 1071\n  * filenames                      (filenames) int64 8B 0\nData variables: (12/16)\n    Sv                             (channel, ping_time, range_sample) float64 152MB ...\n    echo_range                     (channel, ping_time, range_sample) float64 152MB ...\n    frequency_nominal              (channel) float64 24B 3.8e+04 1.2e+05 2e+05\n    sound_speed                    (channel, ping_time) float64 142kB 1.494e+...\n    sound_absorption               (channel, ping_time) float64 142kB 0.00978...\n    sa_correction                  (channel, ping_time) float64 142kB 0.0 ......\n    ...                             ...\n    angle_sensitivity_alongship    (channel) float64 24B 21.9 23.0 23.0\n    angle_sensitivity_athwartship  (channel) float64 24B 21.9 23.0 23.0\n    beamwidth_alongship            (channel) float64 24B 7.1 7.0 7.0\n    beamwidth_athwartship          (channel) float64 24B 7.1 7.0 7.0\n    source_filenames               (filenames) &lt;U119 476B 'https://rawdata.oc...\n    water_level                    float64 8B 0.0\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.4.dev58+gae911de\n    processing_time:              2024-04-26T18:38:31Z\n    processing_function:          calibrate.compute_Svxarray.DatasetDimensions:channel: 3ping_time: 5923range_sample: 1072filenames: 1Coordinates: (4)channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')ping_time(ping_time)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...long_name :Timestamp of each pingstandard_name :timeaxis :Tarray(['2017-08-21T04:57:17.329287000', '2017-08-21T04:57:18.332344000',\n       '2017-08-21T04:57:19.335403000', ..., '2017-08-21T06:36:15.549934000',\n       '2017-08-21T06:36:16.552992000', '2017-08-21T06:36:17.556049000'],\n      dtype='datetime64[ns]')range_sample(range_sample)int640 1 2 3 4 ... 1068 1069 1070 1071long_name :Along-range sample number, base 0array([   0,    1,    2, ..., 1069, 1070, 1071])filenames(filenames)int640long_name :Index for data and metadata source filenamesarray([0])Data variables: (16)Sv(channel, ping_time, range_sample)float64nan nan nan ... -51.91 -53.35long_name :Volume backscattering strength (Sv re 1 m-1)units :dBactual_range :[-159.72, 18.88]array([[[         nan,          nan,          nan, ..., -56.73248439,\n         -56.09738314, -57.62594001],\n        [         nan,          nan,          nan, ..., -63.49389796,\n         -61.71817171, -59.57792823],\n        [         nan,          nan,          nan, ..., -60.55415492,\n         -59.62507784, -57.55538337],\n        ...,\n        [         nan,          nan,          nan, ..., -60.67174678,\n         -73.17142641, -77.07529609],\n        [         nan,          nan,          nan, ..., -59.69574885,\n         -59.40165865, -65.23400276],\n        [         nan,          nan,          nan, ..., -61.61246638,\n         -67.44480288, -77.533899  ]],\n\n       [[         nan,          nan,          nan, ..., -54.31367532,\n         -46.54205175, -40.84001588],\n        [         nan,          nan,          nan, ..., -42.62524453,\n         -49.85808416, -51.15263795],\n        [         nan,          nan,          nan, ..., -44.60075418,\n         -47.97664495, -49.04777955],\n...\n        [         nan,          nan,          nan, ..., -45.22397653,\n         -45.01338049, -47.40152406],\n        [         nan,          nan,          nan, ..., -42.15488473,\n         -51.81007238, -48.10706757],\n        [         nan,          nan,          nan, ..., -44.82417336,\n         -47.61212011, -48.57742738]],\n\n       [[         nan,          nan,          nan, ..., -66.77704258,\n         -65.45526876, -53.00949437],\n        [         nan,          nan,          nan, ..., -48.60940952,\n         -44.90055837, -44.86052282],\n        [         nan,          nan,          nan, ..., -51.1611063 ,\n         -50.40377035, -49.72874791],\n        ...,\n        [         nan,          nan,          nan, ..., -64.83681126,\n         -50.22737874, -48.78802831],\n        [         nan,          nan,          nan, ..., -52.57219334,\n         -51.55614461, -50.77528722],\n        [         nan,          nan,          nan, ..., -49.7147562 ,\n         -51.90891256, -53.35051305]]])echo_range(channel, ping_time, range_sample)float640.0 0.1912 0.3824 ... 204.6 204.8long_name :Range distanceunits :marray([[[0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        ...,\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02]],\n\n       [[0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n...\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02]],\n\n       [[0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        ...,\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02],\n        [0.00000000e+00, 1.91217765e-01, 3.82435530e-01, ...,\n         2.04411791e+02, 2.04603009e+02, 2.04794226e+02]]])frequency_nominal(channel)float643.8e+04 1.2e+05 2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 38000., 120000., 200000.])sound_speed(channel, ping_time)float641.494e+03 1.494e+03 ... 1.494e+03long_name :Indicative sound speedstandard_name :speed_of_sound_in_sea_waterunits :m/svalid_min :0.0array([[1493.88879395, 1493.88879395, 1493.88879395, ..., 1493.88879395,\n        1493.88879395, 1493.88879395],\n       [1493.88879395, 1493.88879395, 1493.88879395, ..., 1493.88879395,\n        1493.88879395, 1493.88879395],\n       [1493.88879395, 1493.88879395, 1493.88879395, ..., 1493.88879395,\n        1493.88879395, 1493.88879395]])sound_absorption(channel, ping_time)float640.009785 0.009785 ... 0.05269long_name :Indicative acoustic absorptionunits :dB/mvalid_min :0.0array([[0.00978527, 0.00978527, 0.00978527, ..., 0.00978527, 0.00978527,\n        0.00978527],\n       [0.03744031, 0.03744031, 0.03744031, ..., 0.03744031, 0.03744031,\n        0.03744031],\n       [0.05268759, 0.05268759, 0.05268759, ..., 0.05268759, 0.05268759,\n        0.05268759]])sa_correction(channel, ping_time)float640.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])gain_correction(channel, ping_time)float6426.5 26.5 26.5 ... 25.0 25.0 25.0array([[26.5, 26.5, 26.5, ..., 26.5, 26.5, 26.5],\n       [25. , 25. , 25. , ..., 25. , 25. , 25. ],\n       [25. , 25. , 25. , ..., 25. , 25. , 25. ]])equivalent_beam_angle(channel)float64-20.6 -20.7 -20.7long_name :Equivalent beam angleunits :srvalid_range :(0.0, 12.566370614359172)array([-20.60000038, -20.70000076, -20.70000076])angle_offset_alongship(channel)float640.0 0.0 0.0long_name :electrical alongship angle offset of the transducercomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([0., 0., 0.])angle_offset_athwartship(channel)float640.0 0.0 0.0long_name :electrical athwartship angle offset of the transducercomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([0., 0., 0.])angle_sensitivity_alongship(channel)float6421.9 23.0 23.0long_name :alongship angle sensitivity of the transducercomment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. array([21.89999962, 23.        , 23.        ])angle_sensitivity_athwartship(channel)float6421.9 23.0 23.0long_name :athwartship angle sensitivity of the transducercomment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. array([21.89999962, 23.        , 23.        ])beamwidth_alongship(channel)float647.1 7.0 7.0long_name :Half power two-way beam width along alongship axis of beamunits :arc_degreevalid_range :(0.0, 360.0)comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_minor and beamwidth_transmit_minor), but Simrad echosounders record two-way beamwidth in the data.array([7.0999999, 7.       , 7.       ])beamwidth_athwartship(channel)float647.1 7.0 7.0long_name :Half power two-way beam width along athwartship axis of beamunits :arc_degreevalid_range :(0.0, 360.0)comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_major and beamwidth_transmit_major), but Simrad echosounders record two-way beamwidth in the data.array([7.0999999, 7.       , 7.       ])source_filenames(filenames)&lt;U119'https://rawdata.oceanobservator...long_name :Source filenamesarray(['https://rawdata.oceanobservatories.org/files/CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/2017/08/21/OOI-D20170821-T045717.raw'],\n      dtype='&lt;U119')water_level()float640.0long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(0.)Indexes: (4)channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287', '2017-08-21 04:57:18.332344',\n               '2017-08-21 04:57:19.335403', '2017-08-21 04:57:20.338461',\n               '2017-08-21 04:57:21.341518', '2017-08-21 04:57:22.344574',\n               '2017-08-21 04:57:23.347631', '2017-08-21 04:57:24.350689',\n               '2017-08-21 04:57:25.353746', '2017-08-21 04:57:26.356804',\n               ...\n               '2017-08-21 06:36:08.528532', '2017-08-21 06:36:09.531590',\n               '2017-08-21 06:36:10.534647', '2017-08-21 06:36:11.537704',\n               '2017-08-21 06:36:12.540762', '2017-08-21 06:36:13.543819',\n               '2017-08-21 06:36:14.546877', '2017-08-21 06:36:15.549934',\n               '2017-08-21 06:36:16.552992', '2017-08-21 06:36:17.556049'],\n              dtype='datetime64[ns]', name='ping_time', length=5923, freq=None))range_samplePandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071],\n      dtype='int64', name='range_sample', length=1072))filenamesPandasIndexPandasIndex(Index([0], dtype='int64', name='filenames'))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.4.dev58+gae911deprocessing_time :2024-04-26T18:38:31Zprocessing_function :calibrate.compute_Sv\n\n\n\n\nQuickly visualize the result\nThe default xarray visualization functions are useful in getting a quick sense of the data.\nFirst replace the channel dimension and coordinate with the frequency_nominal variable containing actual frequency values. Note that this step is possible only because there are no duplicated frequencies present.\n\nds_Sv = ep.consolidate.swap_dims_channel_frequency(ds_Sv)\n\n\nds_Sv.Sv.sel(frequency_nominal=200000).plot.pcolormesh(\n    x='ping_time', cmap = 'jet', vmin=-80, vmax=-30\n);\n\n\n\n\n\n\n\n\nNote that the vertical axis is range_sample. This is the bin (or sample) number as recorded in the data. A separate data variable in ds_Sv contains the physical range (echo_range) from the transducer in meters. echo_range has the same dimension as Sv and may not be uniform across all frequency channels or pings, depending on the echosounder setting during data collection.\n\n\nConvert multiple files and combine into a single EchoData object\nNow that we verified that echopype does work for a single file, let’s proceed to process all sonar data from August 20-21, 2017.\nFirst, convert all desired files from the OOI HTTP server to a local directory.\n\n# Create a directory for all converted files\noutput_dpath = Path(base_dpath / 'convertallfiles')\noutput_dpath.mkdir(exist_ok=True)\n\n\n%%time\nfor raw_file_url in desired_raw_file_urls:\n    # Read and convert, resulting in echodata object\n    ed = ep.open_raw(raw_file=raw_file_url, sonar_model='ek60', use_swap=True)\n    ed.to_zarr(save_path=output_dpath, overwrite=True)\n\nThen, assemble a list of EchoData object from the converted files. Note that by using chunks={}, the files are lazy-loaded and only metadata are read into memory, until more operations are executed.\n\ned_list = []\nfor converted_file in sorted(output_dpath.glob(\"*.zarr\")):\n#     ed_list.append(ep.open_converted(converted_file))\n    ed_list.append(ep.open_converted(converted_file, chunks={}))\n\nCombine all the opened files to a single EchoData object.\n\ned_combined = ep.combine_echodata(ed_list)\n\nBelow we can inspect this combined EchoData object just as before.\nExpand the Provenance group to see how the filenames of all 19 files combined are stored in the coordinate variable echodata_filename, and many more data variables are added to retain information that was previously stored as attributes in the Provenance group of individual EchoData objects.\nExpand the Sonar/Beam_group1 to see how data variables such as backscatter_r and angle_alongship contain chunked dask arrays (that are lazy-loadded), instead of regular numpy arrays (that are fully loaded into memory). This means that the computation needed to combine the EchoData objects are specified but not yet executed, which is why the previous line ran through so fast. This is also the mechanism that allows dask to perform its magic for out-of-core computation.\n\ned_combined\n\n\n    \n        EchoData: standardized raw data from Internal Memory\n    \n    \n        \n            Top-level: contains metadata about the SONAR-netCDF4 file format.\n            \n            \n                \n                    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 0B\nDimensions:  ()\nData variables:\n    *empty*\nAttributes:\n    conventions:                 CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3\n    date_created:                2017-08-21T04:57:17Z\n    keywords:                    EK60\n    sonar_convention_authority:  ICES\n    sonar_convention_name:       SONAR-netCDF4\n    sonar_convention_version:    1.0\n    summary:                     \n    title:                       xarray.DatasetDimensions:Coordinates: (0)Data variables: (0)Indexes: (0)Attributes: (8)conventions :CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3date_created :2017-08-21T04:57:17Zkeywords :EK60sonar_convention_authority :ICESsonar_convention_name :SONAR-netCDF4sonar_convention_version :1.0summary :title :\n                \n            \n        \n        \n                    Environment: contains information relevant to acoustic propagation through water.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 6MB\nDimensions:                 (channel: 3, time1: 109482)\nCoordinates:\n  * channel                 (channel) &lt;U39 468B 'GPT  38 kHz 00907208dd13 5-1...\n  * time1                   (time1) datetime64[ns] 876kB 2017-08-21T04:57:17....\nData variables:\n    absorption_indicative   (channel, time1) float64 3MB dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;\n    frequency_nominal       (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    sound_speed_indicative  (channel, time1) float64 3MB dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;xarray.DatasetDimensions:channel: 3time1: 109482Coordinates: (2)channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')time1(time1)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...axis :Tcomment :Time coordinate corresponding to environmental variables.long_name :Timestamps for NMEA position datagramsstandard_name :timearray(['2017-08-21T04:57:17.329287000', '2017-08-21T04:57:18.332344000',\n       '2017-08-21T04:57:19.335403000', ..., '2017-08-22T11:33:12.631414000',\n       '2017-08-22T11:33:13.634472000', '2017-08-22T11:33:14.637529000'],\n      dtype='datetime64[ns]')Data variables: (3)absorption_indicative(channel, time1)float64dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;long_name :Indicative acoustic absorptionunits :dB/mvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.51 MiB\n138.84 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\nfrequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nsound_speed_indicative(channel, time1)float64dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;long_name :Indicative sound speedstandard_name :speed_of_sound_in_sea_waterunits :m/svalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.51 MiB\n138.84 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\nIndexes: (2)channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287', '2017-08-21 04:57:18.332344',\n               '2017-08-21 04:57:19.335403', '2017-08-21 04:57:20.338461',\n               '2017-08-21 04:57:21.341518', '2017-08-21 04:57:22.344574',\n               '2017-08-21 04:57:23.347631', '2017-08-21 04:57:24.350689',\n               '2017-08-21 04:57:25.353746', '2017-08-21 04:57:26.356804',\n               ...\n               '2017-08-22 11:33:05.611013', '2017-08-22 11:33:06.613070',\n               '2017-08-22 11:33:07.616127', '2017-08-22 11:33:08.619184',\n               '2017-08-22 11:33:09.622242', '2017-08-22 11:33:10.625299',\n               '2017-08-22 11:33:11.628357', '2017-08-22 11:33:12.631414',\n               '2017-08-22 11:33:13.634472', '2017-08-22 11:33:14.637529'],\n              dtype='datetime64[ns]', name='time1', length=109482, freq=None))Attributes: (0)\n                        \n                    \n                \n                    Platform: contains information about the platform on which the sonar is installed.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 4MB\nDimensions:              (channel: 3, time1: 19, time2: 109478)\nCoordinates:\n  * time1                (time1) datetime64[ns] 152B 2017-08-21T04:57:17.3292...\n  * channel              (channel) &lt;U39 468B 'GPT  38 kHz 00907208dd13 5-1 OO...\n  * time2                (time2) datetime64[ns] 876kB 2017-08-21T04:57:17.329...\nData variables: (12/20)\n    MRU_offset_x         float64 8B nan\n    MRU_offset_y         float64 8B nan\n    MRU_offset_z         float64 8B nan\n    MRU_rotation_x       float64 8B nan\n    MRU_rotation_y       float64 8B nan\n    MRU_rotation_z       float64 8B nan\n    ...                   ...\n    transducer_offset_y  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transducer_offset_z  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    water_level          float64 8B 0.0\n    pitch                (time2) float64 876kB dask.array&lt;chunksize=(5923,), meta=np.ndarray&gt;\n    roll                 (time2) float64 876kB dask.array&lt;chunksize=(5923,), meta=np.ndarray&gt;\n    vertical_offset      (time2) float64 876kB dask.array&lt;chunksize=(5923,), meta=np.ndarray&gt;\nAttributes:\n    platform_code_ICES:  \n    platform_name:       \n    platform_type:       xarray.DatasetDimensions:channel: 3time1: 19time2: 109478Coordinates: (3)time1(time1)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...axis :Tcomment :Time coordinate corresponding to NMEA position data.long_name :Timestamps for NMEA datagramsstandard_name :timearray(['2017-08-21T04:57:17.329287000', '2017-08-21T06:36:18.558107000',\n       '2017-08-21T08:15:22.981108000', '2017-08-21T09:54:35.422569000',\n       '2017-08-21T11:33:43.010752000', '2017-08-21T13:12:45.447639000',\n       '2017-08-21T14:51:47.892527000', '2017-08-21T16:30:49.164349000',\n       '2017-08-21T18:09:52.555290000', '2017-08-21T19:48:53.890116000',\n       '2017-08-21T21:28:02.341349000', '2017-08-21T23:07:06.801352000',\n       '2017-08-22T00:00:00.053455000', '2017-08-22T01:39:02.674353000',\n       '2017-08-22T03:18:04.000179000', '2017-08-22T04:57:05.264000000',\n       '2017-08-22T06:36:06.599823000', '2017-08-22T08:15:08.869701000',\n       '2017-08-22T09:54:14.236757000'], dtype='datetime64[ns]')channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')time2(time2)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...axis :Tcomment :Time coordinate corresponding to platform motion and orientation data.long_name :Timestamps for platform motion and orientation datastandard_name :timearray(['2017-08-21T04:57:17.329287000', '2017-08-21T04:57:18.332344000',\n       '2017-08-21T04:57:19.335403000', ..., '2017-08-22T11:33:12.631414000',\n       '2017-08-22T11:33:13.634472000', '2017-08-22T11:33:14.637529000'],\n      dtype='datetime64[ns]')Data variables: (20)MRU_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_rotation_x()float64nanlong_name :Extrinsic rotation about the x-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_y()float64nanlong_name :Extrinsic rotation about the y-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_z()float64nanlong_name :Extrinsic rotation about the z-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)frequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nlatitude(time1)float64dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;long_name :Platform latitudestandard_name :latitudeunits :degrees_northvalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n152 B\n8 B\n\n\nShape\n(19,)\n(1,)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           19 1\n\n\n\n\nlongitude(time1)float64dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;long_name :Platform longitudestandard_name :longitudeunits :degrees_eastvalid_range :(-180.0, 180.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n152 B\n8 B\n\n\nShape\n(19,)\n(1,)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           19 1\n\n\n\n\nposition_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)sentence_type(time1)float64dask.array&lt;chunksize=(1,), meta=np.ndarray&gt;long_name :NMEA sentence type\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n152 B\n8 B\n\n\nShape\n(19,)\n(1,)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           19 1\n\n\n\n\ntransducer_offset_x(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :x-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_y(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :y-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_z(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :z-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nwater_level()float640.0long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(0.)pitch(time2)float64dask.array&lt;chunksize=(5923,), meta=np.ndarray&gt;long_name :Platform pitchstandard_name :platform_pitch_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n855.30 kiB\n46.27 kiB\n\n\nShape\n(109478,)\n(5923,)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109478 1\n\n\n\n\nroll(time2)float64dask.array&lt;chunksize=(5923,), meta=np.ndarray&gt;long_name :Platform rollstandard_name :platform_roll_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n855.30 kiB\n46.27 kiB\n\n\nShape\n(109478,)\n(5923,)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109478 1\n\n\n\n\nvertical_offset(time2)float64dask.array&lt;chunksize=(5923,), meta=np.ndarray&gt;long_name :Platform vertical offset from nominal water levelunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n855.30 kiB\n46.27 kiB\n\n\nShape\n(109478,)\n(5923,)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109478 1\n\n\n\n\nIndexes: (1)beam_groupPandasIndexPandasIndex(Index(['Beam_group1'], dtype='object', name='beam_group'))Attributes: (6)sonar_manufacturer :Simradsonar_model :EK60sonar_serial_number :sonar_software_name :ER60sonar_software_version :2.4.3sonar_type :echosounder\n                        \n                    \n                \n                    Beam_group1: contains backscatter power (uncalibrated) and other beam or channel-specific data, including split-beam angle data when they exist.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 8GB\nDimensions:                        (channel: 3, ping_time: 109482,\n                                    range_sample: 1072)\nCoordinates:\n  * channel                        (channel) &lt;U39 468B 'GPT  38 kHz 00907208d...\n  * ping_time                      (ping_time) datetime64[ns] 876kB 2017-08-2...\n  * range_sample                   (range_sample) int64 9kB 0 1 2 ... 1070 1071\nData variables: (12/29)\n    angle_alongship                (channel, ping_time, range_sample) float64 3GB dask.array&lt;chunksize=(3, 3886, 1072), meta=np.ndarray&gt;\n    angle_athwartship              (channel, ping_time, range_sample) float64 3GB dask.array&lt;chunksize=(3, 3886, 1072), meta=np.ndarray&gt;\n    angle_offset_alongship         (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    angle_offset_athwartship       (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    angle_sensitivity_alongship    (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    angle_sensitivity_athwartship  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    ...                             ...\n    transmit_bandwidth             (channel, ping_time) float64 3MB dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;\n    transmit_duration_nominal      (channel, ping_time) float64 3MB dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;\n    transmit_frequency_start       (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transmit_frequency_stop        (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transmit_power                 (channel, ping_time) float64 3MB dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;\n    transmit_type                  &lt;U2 8B 'CW'\nAttributes:\n    beam_mode:              vertical\n    conversion_equation_t:  type_3xarray.DatasetDimensions:channel: 3ping_time: 109482range_sample: 1072Coordinates: (3)channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')ping_time(ping_time)datetime64[ns]2017-08-21T04:57:17.329287 ... 2...axis :Tlong_name :Timestamp of each pingstandard_name :timearray(['2017-08-21T04:57:17.329287000', '2017-08-21T04:57:18.332344000',\n       '2017-08-21T04:57:19.335403000', ..., '2017-08-22T11:33:12.631414000',\n       '2017-08-22T11:33:13.634472000', '2017-08-22T11:33:14.637529000'],\n      dtype='datetime64[ns]')range_sample(range_sample)int640 1 2 3 4 ... 1068 1069 1070 1071long_name :Along-range sample number, base 0array([   0,    1,    2, ..., 1069, 1070, 1071])Data variables: (29)angle_alongship(channel, ping_time, range_sample)float64dask.array&lt;chunksize=(3, 3886, 1072), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :electrical alongship angle\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.62 GiB\n95.35 MiB\n\n\nShape\n(3, 109482, 1072)\n(3, 3886, 1072)\n\n\nDask graph\n37 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             1072 109482 3\n\n\n\n\nangle_athwartship(channel, ping_time, range_sample)float64dask.array&lt;chunksize=(3, 3886, 1072), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :electrical athwartship angle\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.62 GiB\n95.35 MiB\n\n\nShape\n(3, 109482, 1072)\n(3, 3886, 1072)\n\n\nDask graph\n37 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             1072 109482 3\n\n\n\n\nangle_offset_alongship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :electrical alongship angle offset of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nangle_offset_athwartship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :electrical athwartship angle offset of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nangle_sensitivity_alongship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :alongship angle sensitivity of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nangle_sensitivity_athwartship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :athwartship angle sensitivity of the transducer\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbackscatter_r(channel, ping_time, range_sample)float64dask.array&lt;chunksize=(3, 3886, 1072), meta=np.ndarray&gt;long_name :Raw backscatter measurements (real part)units :dB\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.62 GiB\n95.35 MiB\n\n\nShape\n(3, 109482, 1072)\n(3, 3886, 1072)\n\n\nDask graph\n37 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             1072 109482 3\n\n\n\n\nbeam_direction_x(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :x-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeam_direction_y(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :y-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeam_direction_z(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :z-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeam_stabilisation()int80flag_meanings :['not stabilised', 'stabilised']flag_values :[0, 1]long_name :Beam stabilisation applied (or not)array(0, dtype=int8)beam_type(channel)int64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :type of transducer (0-single, 1-split)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 58 graph layers\n\n\nData type\nint64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeamwidth_twoway_alongship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_minor and beamwidth_transmit_minor), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along alongship axis of beamunits :arc_degreevalid_range :[0.0, 360.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nbeamwidth_twoway_athwartship(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_major and beamwidth_transmit_major), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along athwartship axis of beamunits :arc_degreevalid_range :[0.0, 360.0]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nchannel_mode(channel, ping_time)int8dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;comment :From transmit_mode in the EK60 datagramflag_meanings :['Unknown', 'Active', 'Passive', 'Test']flag_values :[-1, 0, 1, 2]long_name :Transceiver mode\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n320.75 kiB\n17.36 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\ndata_type(channel, ping_time)float32dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;flag_meanings :['power only', 'angle only', 'power and angle']flag_values :[1, 2, 3]long_name :recorded data type (1=power only, 2=angle only, 3=power and angle)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.25 MiB\n69.42 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 55 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\nequivalent_beam_angle(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Equivalent beam angleunits :srvalid_range :[0.0, 12.566370614359172]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nfrequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ngain_correction(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Gain correctionunits :dB\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nnon_quantitative_processing()int160flag_meanings :['None']flag_values :[0]long_name :Presence or not of non-quantitative processing applied to the backscattering data (sonar specific)array(0, dtype=int16)sample_interval(channel, ping_time)float64dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;long_name :Interval between recorded raw data samplesunits :svalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.51 MiB\n138.84 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\nsample_time_offset(channel, ping_time)float64dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;long_name :Time offset that is subtracted from the timestamp of each sampleunits :s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.51 MiB\n138.84 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\ntransmit_bandwidth(channel, ping_time)float64dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;long_name :Nominal bandwidth of transmitted pulseunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.51 MiB\n138.84 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\ntransmit_duration_nominal(channel, ping_time)float64dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;long_name :Nominal bandwidth of transmitted pulseunits :svalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.51 MiB\n138.84 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\ntransmit_frequency_start(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Start frequency in transmitted pulsestandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransmit_frequency_stop(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Stop frequency in transmitted pulsestandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 90 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransmit_power(channel, ping_time)float64dask.array&lt;chunksize=(3, 5923), meta=np.ndarray&gt;long_name :Nominal transmit powerunits :Wvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.51 MiB\n138.84 kiB\n\n\nShape\n(3, 109482)\n(3, 5924)\n\n\nDask graph\n19 chunks in 39 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                           109482 3\n\n\n\n\ntransmit_type()&lt;U2'CW'flag_meanings :['Continuous Wave – a pulse nominally of one frequency']flag_values :['CW']long_name :Type of transmitted pulsearray('CW', dtype='&lt;U2')Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:17.329287', '2017-08-21 04:57:18.332344',\n               '2017-08-21 04:57:19.335403', '2017-08-21 04:57:20.338461',\n               '2017-08-21 04:57:21.341518', '2017-08-21 04:57:22.344574',\n               '2017-08-21 04:57:23.347631', '2017-08-21 04:57:24.350689',\n               '2017-08-21 04:57:25.353746', '2017-08-21 04:57:26.356804',\n               ...\n               '2017-08-22 11:33:05.611013', '2017-08-22 11:33:06.613070',\n               '2017-08-22 11:33:07.616127', '2017-08-22 11:33:08.619184',\n               '2017-08-22 11:33:09.622242', '2017-08-22 11:33:10.625299',\n               '2017-08-22 11:33:11.628357', '2017-08-22 11:33:12.631414',\n               '2017-08-22 11:33:13.634472', '2017-08-22 11:33:14.637529'],\n              dtype='datetime64[ns]', name='ping_time', length=109482, freq=None))range_samplePandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071],\n      dtype='int64', name='range_sample', length=1072))Attributes: (2)beam_mode :verticalconversion_equation_t :type_3\n                        \n                    \n                \n                    Vendor_specific: contains vendor-specific information about the sonar and the data.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 892B\nDimensions:            (channel: 3, pulse_length_bin: 5)\nCoordinates:\n  * channel            (channel) &lt;U39 468B 'GPT  38 kHz 00907208dd13 5-1 OOI....\n  * pulse_length_bin   (pulse_length_bin) int64 40B 0 1 2 3 4\nData variables:\n    frequency_nominal  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    gain_correction    (channel, pulse_length_bin) float64 120B dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n    pulse_length       (channel, pulse_length_bin) float64 120B dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n    sa_correction      (channel, pulse_length_bin) float64 120B dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;xarray.DatasetDimensions:channel: 3pulse_length_bin: 5Coordinates: (2)channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')pulse_length_bin(pulse_length_bin)int640 1 2 3 4array([0, 1, 2, 3, 4])Data variables: (4)frequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ngain_correction(channel, pulse_length_bin)float64dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n120 B\n120 B\n\n\nShape\n(3, 5)\n(3, 5)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         5 3\n\n\n\n\npulse_length(channel, pulse_length_bin)float64dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n120 B\n120 B\n\n\nShape\n(3, 5)\n(3, 5)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         5 3\n\n\n\n\nsa_correction(channel, pulse_length_bin)float64dask.array&lt;chunksize=(3, 5), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n120 B\n120 B\n\n\nShape\n(3, 5)\n(3, 5)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         5 3\n\n\n\n\nIndexes: (2)channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))pulse_length_binPandasIndexPandasIndex(Index([0, 1, 2, 3, 4], dtype='int64', name='pulse_length_bin'))Attributes: (0)\n                        \n                    \n                \n    \n\n\n\n\n\nCalibrate the combined EchoData and visualize the mean Sv\nThe single EchoData object is convenient to use for content inspection and calibration. First, compute Sv.\n\ned_combined.nbytes\n\n8475589941.0\n\n\n\n%%time\nds_Sv = ep.calibrate.compute_Sv(ed_combined).compute()\n\nCPU times: user 31.3 s, sys: 44.9 s, total: 1min 16s\nWall time: 36.3 s\n\n\nNext, compute the mean Sv (MVBS) with coherent dimensions along physically meaningful echo_range (in meters) and ping_time from the calibrated data. This processed dataset is easy to visualize. The average bin size along ping_time can be specified using the time series offset alias.\nNote that we use .compute() to persist the Sv data in memory in the cell above. This is because the current implementation of compute_MVBS is not efficient for lazy-loaded data. This limitation will be changed in a future release.\n\n%%time\nds_MVBS = ep.commongrid.compute_MVBS(\n    ds_Sv, \n    range_bin='0.5m',  # 0.5 meters\n    ping_time_bin='10s'   # 10 seconds\n)\n\nCPU times: user 15.8 s, sys: 15 s, total: 30.8 s\nWall time: 58.4 s\n\n\nThe resulting MVBS Dataset has a coherent echo_range coordinate across all frequencies.\n\nds_MVBS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 108MB\nDimensions:            (channel: 3, ping_time: 11017, echo_range: 410)\nCoordinates:\n  * ping_time          (ping_time) datetime64[ns] 88kB 2017-08-21T04:57:10 .....\n  * channel            (channel) &lt;U39 468B 'GPT  38 kHz 00907208dd13 5-1 OOI....\n  * echo_range         (echo_range) float64 3kB 0.0 0.5 1.0 ... 204.0 204.5\nData variables:\n    Sv                 (channel, ping_time, echo_range) float64 108MB nan ......\n    water_level        float64 8B 0.0\n    frequency_nominal  (channel) float64 24B 3.8e+04 1.2e+05 2e+05\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.4.dev58+gae911de\n    processing_time:              2024-04-26T18:40:36Z\n    processing_function:          commongrid.compute_MVBSxarray.DatasetDimensions:channel: 3ping_time: 11017echo_range: 410Coordinates: (3)ping_time(ping_time)datetime64[ns]2017-08-21T04:57:10 ... 2017-08-...long_name :Ping timestandard_name :timeaxis :Tarray(['2017-08-21T04:57:10.000000000', '2017-08-21T04:57:20.000000000',\n       '2017-08-21T04:57:30.000000000', ..., '2017-08-22T11:32:50.000000000',\n       '2017-08-22T11:33:00.000000000', '2017-08-22T11:33:10.000000000'],\n      dtype='datetime64[ns]')channel(channel)&lt;U39'GPT  38 kHz 00907208dd13 5-1 OO...long_name :Vendor channel IDarray(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'], dtype='&lt;U39')echo_range(echo_range)float640.0 0.5 1.0 ... 203.5 204.0 204.5long_name :Range distanceunits :marray([  0. ,   0.5,   1. , ..., 203.5, 204. , 204.5])Data variables: (3)Sv(channel, ping_time, echo_range)float64nan -5.884 -41.64 ... -55.76 -53.87long_name :Mean volume backscattering strength (MVBS, mean Sv re 1 m-1)units :dBactual_range :[-119.01, 14.12]cell_methods :ping_time: mean (interval: 10 second comment: ping_time is the interval start) echo_range: mean (interval: 0.5 meter comment: echo_range is the interval start)binning_mode :physical unitsrange_meter_interval :0.5mping_time_interval :10sarray([[[         nan,  -5.88425569, -41.63725722, ..., -61.07247099,\n         -61.40462575, -58.33427992],\n        [         nan,  -5.8869054 , -41.66594107, ..., -60.61668924,\n         -60.88883221, -58.66684405],\n        [         nan,  -5.88543566, -41.66623207, ..., -62.56181363,\n         -62.21691439, -60.30231283],\n        ...,\n        [         nan,  -5.88308249, -41.74508058, ..., -59.94833809,\n         -62.39405687, -63.63942714],\n        [         nan,  -5.885433  , -41.74960729, ..., -61.61488555,\n         -61.03294828, -62.00169315],\n        [         nan,  -5.88278614, -41.74180217, ..., -63.98824752,\n         -61.98260965, -62.10536721]],\n\n       [[         nan,   9.82717819, -59.08596601, ..., -44.91381462,\n         -45.94141481, -45.99254766],\n        [         nan,   9.82653878, -59.0812816 , ..., -43.57412527,\n         -46.09596909, -44.72156473],\n        [         nan,   9.82589928, -58.99234292, ..., -42.26453045,\n         -44.08188568, -43.81690877],\n...\n        [         nan,   9.82354788, -59.12304693, ..., -45.63152059,\n         -48.28106551, -52.10231555],\n        [         nan,   9.82539953, -59.21363237, ..., -48.01400699,\n         -49.18533387, -47.96608508],\n        [         nan,   9.82703994, -59.24488219, ..., -47.87535778,\n         -48.78056651, -50.24016753]],\n\n       [[         nan, -49.00110738, -52.87085107, ..., -52.49360565,\n         -51.29642956, -48.23655795],\n        [         nan, -49.05694507, -53.27777004, ..., -48.98742757,\n         -49.08174496, -49.74692975],\n        [         nan, -49.04200486, -53.17903837, ..., -47.43828184,\n         -47.40676229, -49.97991123],\n        ...,\n        [         nan, -49.02214364, -53.05939991, ..., -53.99070834,\n         -53.14276004, -54.03496954],\n        [         nan, -49.02829604, -53.04457027, ..., -53.50089242,\n         -53.42453627, -53.83470529],\n        [         nan, -49.0271787 , -53.18716022, ..., -50.55976847,\n         -55.76192779, -53.86795785]]])water_level()float640.0long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(0.)frequency_nominal(channel)float643.8e+04 1.2e+05 2e+05long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0array([ 38000., 120000., 200000.])Indexes: (3)ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-08-21 04:57:10', '2017-08-21 04:57:20',\n               '2017-08-21 04:57:30', '2017-08-21 04:57:40',\n               '2017-08-21 04:57:50', '2017-08-21 04:58:00',\n               '2017-08-21 04:58:10', '2017-08-21 04:58:20',\n               '2017-08-21 04:58:30', '2017-08-21 04:58:40',\n               ...\n               '2017-08-22 11:31:40', '2017-08-22 11:31:50',\n               '2017-08-22 11:32:00', '2017-08-22 11:32:10',\n               '2017-08-22 11:32:20', '2017-08-22 11:32:30',\n               '2017-08-22 11:32:40', '2017-08-22 11:32:50',\n               '2017-08-22 11:33:00', '2017-08-22 11:33:10'],\n              dtype='datetime64[ns]', name='ping_time', length=11017, freq=None))channelPandasIndexPandasIndex(Index(['GPT  38 kHz 00907208dd13 5-1 OOI.38|200',\n       'GPT 120 kHz 00907208a0b1 3-1 ES120-7CD',\n       'GPT 200 kHz 00907208dd13 5-2 OOI38|200'],\n      dtype='object', name='channel'))echo_rangePandasIndexPandasIndex(Index([  0.0,   0.5,   1.0,   1.5,   2.0,   2.5,   3.0,   3.5,   4.0,   4.5,\n       ...\n       200.0, 200.5, 201.0, 201.5, 202.0, 202.5, 203.0, 203.5, 204.0, 204.5],\n      dtype='float64', name='echo_range', length=410))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.4.dev58+gae911deprocessing_time :2024-04-26T18:40:36Zprocessing_function :commongrid.compute_MVBS\n\n\n\n\nVisualize MVBS interactively using hvPlot\nTo visualize, invert the range axis since the echosounder is upward-looking from a platform at approximately 200 m water depth.\n\nds_MVBS = ds_MVBS.assign_coords(depth=(\"echo_range\", ds_MVBS[\"echo_range\"].values[::-1]))\nds_MVBS = ds_MVBS.swap_dims({'echo_range': 'depth'})  # set depth as data dimension\n\nThen replace the channel dimension and coordinate with the frequency_nominal variable containing actual frequency values. Note that this step is possible only when there are no duplicated frequencies present.\n\nds_MVBS = ep.consolidate.swap_dims_channel_frequency(ds_MVBS)\n\n\nds_MVBS[\"Sv\"].sel(frequency_nominal=200000).hvplot.image(\n    x='ping_time', y='depth', \n    color='Sv', rasterize=True, \n    cmap='jet', clim=(-80, -30),\n    xlabel='Time (UTC)',\n    ylabel='Depth (m)',\n).options(width=800, invert_yaxis=True)\n\n/Users/wujung/miniconda3/envs/echopype_examples_20240424/lib/python3.10/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \nDask dataframe query planning is disabled because dask-expr is not installed.\n\nYou can install it with `pip install dask[dataframe]` or `conda install dask`.\nThis will raise in a future version.\n\n  warnings.warn(msg, FutureWarning)\nOMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n\n\n\n\n\n\n  \n\n\n\n\nNote that the reflection from the sea surface shows up at a location below the depth of 0 m. This is because we have not corrected for the actual depth of the platform on which the echosounder is mounted, and the actual sound speed at the time of data collection (which is related to the calculated range) could also be different from the user-defined sound speed stored in the data file. More accurate platform depth information can be obtained using data from the CTD collocated on the moored platform."
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#obtain-solar-radiation-data-from-an-ooi-thredds-server",
    "href": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#obtain-solar-radiation-data-from-an-ooi-thredds-server",
    "title": "Watching a solar eclipse using an OOI moored echosounder",
    "section": "Obtain solar radiation data from an OOI THREDDS server",
    "text": "Obtain solar radiation data from an OOI THREDDS server\nNow we have the sonar data ready, the next step is to pull solar radiation data collected by a nearby surface mooring also maintained by the OOI. The Bulk Meteorology Instrument Package is located on the Coastal Endurance Oregon Offshore Surface Mooring.\nNote: an earlier version of this notebook used the same dataset but pulled from the National Data Buoy Center (NDBC). We thank the Rutgers OOI Data Lab for pointing out the direct data source in one of the data nuggets.\n\nmetbk_url = (\n    \"http://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/\"\n    \"CE04OSSM-SBD11-06-METBKA000-recovered_host-metbk_a_dcl_instrument_recovered/\"\n    \"deployment0004_CE04OSSM-SBD11-06-METBKA000-recovered_host-metbk_a_dcl_instrument_recovered_20170421T022518.003000-20171013T154805.602000.nc#fillmismatch\"\n)\n\n\nmetbk_ds = (\n    xr.open_dataset(metbk_url)\n    .swap_dims({'obs': 'time'})\n    .drop('obs')\n    .sel(time=slice(start_datetime, end_datetime))[['shortwave_irradiance']]\n)\nmetbk_ds.time.attrs.update({'long_name': 'Time', 'units': 'UTC'})\n\nmetbk_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 17kB\nDimensions:               (time: 1441)\nCoordinates:\n  * time                  (time) datetime64[ns] 12kB 2017-08-21T07:00:08.2329...\nData variables:\n    shortwave_irradiance  (time) float32 6kB ...\nAttributes: (12/73)\n    node:                               SBD11\n    comment:                            \n    publisher_email:                    \n    sourceUrl:                          http://oceanobservatories.org/\n    collection_method:                  recovered_host\n    stream:                             metbk_a_dcl_instrument_recovered\n    ...                                 ...\n    geospatial_vertical_positive:       down\n    lat:                                44.36555\n    lon:                                -124.9407\n    DODS.strlen:                        36\n    DODS.dimName:                       string36\n    DODS_EXTRA.Unlimited_Dimension:     obsxarray.DatasetDimensions:time: 1441Coordinates: (1)time(time)datetime64[ns]2017-08-21T07:00:08.232999936 .....axis :Tstandard_name :timelong_name :Time_ChunkSizes :10000units :UTCarray(['2017-08-21T07:00:08.232999936', '2017-08-21T07:01:12.539999744',\n       '2017-08-21T07:02:16.888000000', ..., '2017-08-22T06:58:15.237000192',\n       '2017-08-22T06:59:19.614000128', '2017-08-22T06:59:53.616999936'],\n      dtype='datetime64[ns]')Data variables: (1)shortwave_irradiance(time)float32...long_name :Downwelling Shortwave Irradianceprecision :1data_product_identifier :SHRTIRR_L1standard_name :downwelling_shortwave_flux_in_airunits :W m-2ancillary_variables :shortwave_irradiance_qartod_results shortwave_irradiance_qartod_executed_ChunkSizes :10000[1441 values with dtype=float32]Indexes: (1)timePandasIndexPandasIndex(DatetimeIndex(['2017-08-21 07:00:08.232999936',\n               '2017-08-21 07:01:12.539999744',\n                  '2017-08-21 07:02:16.888000',\n               '2017-08-21 07:03:21.114000384',\n               '2017-08-21 07:03:54.609000448',\n               '2017-08-21 07:04:59.326000128',\n               '2017-08-21 07:06:03.963000320',\n               '2017-08-21 07:07:08.338000384',\n               '2017-08-21 07:08:12.966000128',\n               '2017-08-21 07:09:17.541999616',\n               ...\n               '2017-08-22 06:51:15.482999808',\n               '2017-08-22 06:52:19.729999872',\n               '2017-08-22 06:52:53.618999808',\n               '2017-08-22 06:53:57.861000192',\n               '2017-08-22 06:55:02.479000064',\n               '2017-08-22 06:56:06.762999808',\n               '2017-08-22 06:57:10.991000064',\n               '2017-08-22 06:58:15.237000192',\n               '2017-08-22 06:59:19.614000128',\n               '2017-08-22 06:59:53.616999936'],\n              dtype='datetime64[ns]', name='time', length=1441, freq=None))Attributes: (73)node :SBD11comment :publisher_email :sourceUrl :http://oceanobservatories.org/collection_method :recovered_hoststream :metbk_a_dcl_instrument_recoveredfeatureType :pointcreator_email :publisher_name :Ocean Observatories Initiativedate_modified :2024-02-14T10:39:21.463206keywords :cdm_data_type :Pointreferences :More information can be found at http://oceanobservatories.org/Metadata_Conventions :Unidata Dataset Discovery v1.0date_created :2024-02-14T10:39:21.463204id :CE04OSSM-SBD11-06-METBKA000-recovered_host-metbk_a_dcl_instrument_recoveredrequestUUID :821b0a93-0f47-4094-a6eb-fe6aa06a3915contributor_role :summary :Dataset Generated by Stream Engine from Ocean Observatories Initiativekeywords_vocabulary :institution :Ocean Observatories Initiativenaming_authority :org.oceanobservatoriesfeature_Type :pointinfoUrl :http://oceanobservatories.org/license :contributor_name :uuid :821b0a93-0f47-4094-a6eb-fe6aa06a3915creator_name :Ocean Observatories Initiativetitle :Data produced by Stream Engine version 1.20.8 for CE04OSSM-SBD11-06-METBKA000-recovered_host-metbk_a_dcl_instrument_recoveredsensor :06-METBKA000standard_name_vocabulary :NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table 29acknowledgement :Conventions :CF-1.6project :Ocean Observatories Initiativesource :CE04OSSM-SBD11-06-METBKA000-recovered_host-metbk_a_dcl_instrument_recoveredpublisher_url :http://oceanobservatories.org/creator_url :http://oceanobservatories.org/nodc_template_version :NODC_NetCDF_TimeSeries_Orthogonal_Template_v1.1subsite :CE04OSSMprocessing_level :L2history :2024-02-14T10:39:21.463167 generated from Stream EngineManufacturer :Star EngineeringModelNumber :ASIMETSerialNumber :LGR032Description :Bulk Meteorology Instrument Package: METBK LGR ModuleFirmwareVersion :Not specified.SoftwareVersion :Not specified.AssetUniqueID :CGINS-METLGR-00032Notes :Not specified.Owner :Oregon State UniversityRemoteResources :[]ShelfLifeExpirationDate :Not specified.Mobile :FalseAssetManagementRecordLastModified :2023-12-22T17:47:37.306000time_coverage_start :2017-04-21T02:25:18.003000time_coverage_end :2017-10-13T15:48:05.602000time_coverage_resolution :P60.00Sgeospatial_lat_min :44.36555geospatial_lat_max :44.36555geospatial_lat_units :degrees_northgeospatial_lat_resolution :0.1geospatial_lon_min :-124.9407geospatial_lon_max :-124.9407geospatial_lon_units :degrees_eastgeospatial_lon_resolution :0.1geospatial_vertical_units :metersgeospatial_vertical_resolution :0.1geospatial_vertical_positive :downlat :44.36555lon :-124.9407DODS.strlen :36DODS.dimName :string36DODS_EXTRA.Unlimited_Dimension :obs"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#combine-sonar-observation-with-solar-radiation-measurements",
    "href": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#combine-sonar-observation-with-solar-radiation-measurements",
    "title": "Watching a solar eclipse using an OOI moored echosounder",
    "section": "Combine sonar observation with solar radiation measurements",
    "text": "Combine sonar observation with solar radiation measurements\nWe can finally put everything together and figure out the impact of the eclipse-driven reduction in sunlight on marine zooplankton!\n\nmetbk_plot = metbk_ds.hvplot.line(\n    x='time', y='shortwave_irradiance', responsive=True,\n).options(width=800, height=120, logy=True, xlim=(start_datetime, end_datetime))\n\nmvbs_plot = ds_MVBS[\"Sv\"].sel(frequency_nominal=200000, ping_time=slice(start_datetime, end_datetime)).hvplot.image(\n    x='ping_time', y='depth', \n    color='Sv', rasterize=True, \n    cmap='jet', clim=(-80, -30),\n    xlabel='Time (UTC)',\n    ylabel='Depth (m)'\n).options(width=800, invert_yaxis=True)\n\n\n(metbk_plot + mvbs_plot).cols(1)\n\n\n\n\n\n  \n\n\n\n\nLook how the dip at solar radiation reading matches exactly with the upwarding moving “blip” at UTC 17:21, August 22, 2017 (local time 10:22 AM). During the solar eclipse, the animals were fooled by the temporary mask of the sun and thought it’s getting dark as at dusk!"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#package-versions",
    "href": "topics-2024/2024-04-26-echopype/ms_OOI_EK60_mooringtimeseries.html#package-versions",
    "title": "Watching a solar eclipse using an OOI moored echosounder",
    "section": "Package versions",
    "text": "Package versions\n\nimport datetime\nprint(f\"echopype: {ep.__version__}, xarray: {xr.__version__}, fsspec: {fsspec.__version__}, \"\n      f\"hvplot: {hvplot.__version__}\")\n\nprint(f\"\\n{datetime.datetime.utcnow()} +00:00\")\n\nechopype: 0.8.4.dev58+gae911de, xarray: 2024.3.0, fsspec: 2024.3.1, hvplot: 0.9.2\n\n2024-04-26 18:40:44.953619 +00:00"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "",
    "text": "Jupyter notebook accompanying the manuscript:\nEchopype: A Python library for interoperable and scalable processing of ocean sonar data for biological information\nAuthors: Wu-Jung Lee, Emilio Mayorga, Landung Setiawan, Kavin Nguyen, Imran Majeed, Valentina Staneva"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#introduction",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#introduction",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Introduction",
    "text": "Introduction\n\nGoals\n\nIllustrate a common workflow for echosounder data conversion, calibration and use. This workflow leverages the standardization applied by echopype and the power, ease of use and familiarity of libraries in the scientific Python ecosystem.\nExtract and visualize data with relative ease using geospatial and temporal filters.\n\n\n\nDescription\nThis notebook uses EK60 echosounder data collected during the 2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey (‘Pacific Hake Survey’) to illustrate a common workflow for data conversion, calibration and analysis using echopype and core scientific Python software packages, particularly xarray, GeoPandas, pandas and NumPy.\nTwo days of cloud-hosted .raw data files are accessed by echopype directly from an Amazon Web Services (AWS) S3 “bucket” maintained by the NOAA NCEI Water-Column Sonar Data Archive. The total data used are 170 .raw files at approximately 25 MB each (1 Hz pinging rate from first light to dusk), corresponding to approximately 4.2 GB. With echopype, each file is converted to a standardized representation based on the SONAR-netCDF4 v1.0 convention and saved to the cloud-optimized Zarr format.\nData stored in the netCDF-based SONAR-netCDF4 convention can be conveniently and intuitively manipulated with xarray in combination with related scientific Python packages. Mean Volume Backscattering Strength (MVBS) is computed with echopype from each raw data file and exported to a netCDF file. Here, we define two geographical bounding boxes encompassing two ship tracks and use these to extract corresponding timestamp intervals from the GPS data, and then the corresponding MVBS data based on those intervals. Finally, these extracted MVBS subsets are plotted as track echograms.\n\n\nOutline\n\nEstablish AWS S3 file system connection and generate list of target EK60 .raw files\nProcess S3-hosted raw files with echopype: convert, calibrate and export to standardized files\nExtract and process GPS locations from the Platform group of converted raw files\nRead MVBS and plot track echograms for time periods corresponding to two ship tracks\n\n\n\nRunning the notebook\nThis notebook can be run with a conda environment created using the conda environment file https://github.com/OSOceanAcoustics/echopype-examples/blob/main/binder/environment.yml. The notebook creates two directories, if not already present: ./exports/hakesurvey_convertedzarr and ./exports/hakesurvey_calibratednc. netCDF and Zarr files will be exported there.\n\n\nNote\nWe encourage importing echopype as ep for consistency.\n\nfrom pathlib import Path\n\nimport fsspec\nimport numpy as np\nimport geopandas as gpd\nimport xarray as xr\n\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import box\nimport cartopy.crs as ccrs\nimport cartopy.io.img_tiles as cimgt\nfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n\nimport echopype as ep\nfrom echopype.qc import exist_reversed_time\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#establish-aws-s3-file-system-connection-and-generate-list-of-target-ek60-.raw-files",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#establish-aws-s3-file-system-connection-and-generate-list-of-target-ek60-.raw-files",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Establish AWS S3 file system connection and generate list of target EK60 .raw files",
    "text": "Establish AWS S3 file system connection and generate list of target EK60 .raw files\nAccess and inspect the publicly accessible NCEI WCSD S3 bucket on the AWS cloud as if it were a local file system. This will be done through the Python fsspec file system and bytes storage interface. We will use fsspec.filesystem.glob (fs.glob) to generate a list of all EK60 .raw data files in the bucket, then filter on file names for target dates of interest.\nThe directory path on the ncei-wcsd-archive S3 bucket is s3://ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/. All .raw files from the 2017 Hake survey cruise are found here.\n\nfs = fsspec.filesystem('s3', anon=True)\n\nbucket = \"ncei-wcsd-archive\"\nrawdirpath = \"data/raw/Bell_M._Shimada/SH1707/EK60\"\n\n\ns3rawfiles = fs.glob(f\"{bucket}/{rawdirpath}/*.raw\")\n\n# print out the last two S3 raw file paths in the list\ns3rawfiles[-2:]\n\n['ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Summer2017-D20170913-T180733.raw',\n 'ncei-wcsd-archive/data/raw/Bell_M._Shimada/SH1707/EK60/Winter2017-D20170615-T002629.raw']\n\n\nGenerate list of target EK60 .raw files from AWS S3 bucket based on dates. The dates are found in the middle string token (e.g., “D20170913”). Select files from 2 days, 2017-07-28 and 2017-07-29.\n\ns3rawfiles = [\n    s3path for s3path in s3rawfiles \n    if any([f\"D2017{datestr}\" in s3path for datestr in ['0728', '0729']])\n]\n\nprint(f\"There are {len(s3rawfiles)} target raw files available\")\n\nThere are 170 target raw files available"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#process-s3-hosted-raw-files-with-echopype-convert-calibrate-and-export-to-standardized-files",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#process-s3-hosted-raw-files-with-echopype-convert-calibrate-and-export-to-standardized-files",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Process S3-hosted raw files with echopype: convert, calibrate and export to standardized files",
    "text": "Process S3-hosted raw files with echopype: convert, calibrate and export to standardized files\nLoop through all the selected raw files on S3 and convert, calibrate and generate Mean Volume Backscattering Strength (MVBS). Save the raw converted and MVBS data to local files, as zarr and netCDF, respectively.\n\ndef populate_metadata(ed, raw_fname):\n    \"\"\"\n    Manually populate into the \"ed\" EchoData object \n    additional metadata about the dataset and the platform\n    \"\"\"\n    \n    # -- SONAR-netCDF4 Top-level Group attributes\n    survey_name = (\n        \"2017 Joint U.S.-Canada Integrated Ecosystem and \"\n        \"Pacific Hake Acoustic Trawl Survey ('Pacific Hake Survey')\"\n    )\n    ed['Top-level'].attrs['title'] = f\"{survey_name}, file {raw_fname}\"\n    ed['Top-level'].attrs['summary'] = (\n        f\"EK60 raw file {raw_fname} from the {survey_name}, converted to a SONAR-netCDF4 file using echopype.\"\n        \"Information about the survey program is available at \"\n        \"https://www.fisheries.noaa.gov/west-coast/science-data/\"\n        \"joint-us-canada-integrated-ecosystem-and-pacific-hake-acoustic-trawl-survey\"\n    )\n\n    # -- SONAR-netCDF4 Platform Group attributes\n    # Per SONAR-netCDF4, for platform_type see https://vocab.ices.dk/?ref=311\n    ed['Platform'].attrs['platform_type'] = \"Research vessel\"\n    ed['Platform'].attrs['platform_name'] = \"Bell M. Shimada\"  # A NOAA ship\n    ed['Platform'].attrs['platform_code_ICES'] = \"315\"\n\nCreate the directories where the exported files will be saved, if these directories don’t already exist.\n\nbase_dpath = Path('./exports/notebook2')\nbase_dpath.mkdir(exist_ok=True, parents=True)\n\nconverted_dpath = Path(base_dpath / 'hakesurvey_convertedzarr')\nconverted_dpath.mkdir(exist_ok=True)\ncalibrated_dpath = (base_dpath / 'hakesurvey_calibratednc')\ncalibrated_dpath.mkdir(exist_ok=True)\n\n\nechopype processing\nEchoData is an echopype object for conveniently handling raw converted data from either raw instrument files or previously converted and standardized raw netCDF4 and Zarr files. It is essentially a container for multiple xarray.Dataset objects, each corresponds to one of the netCDF4 groups specified in the SONAR-netCDF4 convention – the convention followed by echopype. The EchoData object can be used to conveniently accesse and explore the echosounder raw data and for calibration and other processing.\nThe cell below contains the main echopype workflow steps. For each raw file: - Access file directly from S3 via ep.open_raw to create a converted EchoData object in memory - Add global and platform attributes to EchoData object - Export to a local Zarr dataset (a collection of files encapsulated in a directory) - Generate calibrated Sv and then MVBS from the raw data in the EchoData object - Export MVBS to a local netcdf file\nNote: Depending on your internet speed, this cell may take some time to run (potentially 20-30 mins).\n\n%%time\n\nfor s3rawfpath in s3rawfiles:\n    raw_fpath = Path(s3rawfpath)\n    try:\n        # Access file directly from S3 to create a converted EchoData object in memory\n        ed = ep.open_raw(\n            f's3://{s3rawfpath}',\n            sonar_model='EK60',\n            storage_options={'anon': True}\n        )\n        # Manually populate additional metadata about the dataset and the platform\n        populate_metadata(ed, raw_fpath.name)\n\n        # Save to converted Zarr format\n        ed.to_zarr(save_path=converted_dpath, overwrite=True)\n\n        # Use the EchoData object \"ed\" to generate calibrated and\n        # computed MVBS files that will be saved to netcdf\n        ds_Sv = ep.calibrate.compute_Sv(ed)\n        ds_MVBS = ep.commongrid.compute_MVBS(\n            ds_Sv,\n            range_bin='5m',  # in meters\n            ping_time_bin='20s',  # in seconds\n            \n        )\n        ds_MVBS.to_netcdf(calibrated_dpath / f'MVBS_{raw_fpath.stem}.nc')\n    except Exception as e:\n        print(f'Failed to process raw file {raw_fpath.name}: {e}')\n\n/Users/wujung/miniconda3/envs/echopype_examples_v084/lib/python3.10/site-packages/xarray/core/duck_array_ops.py:215: RuntimeWarning: invalid value encountered in cast\n  return data.astype(dtype, **kwargs)\n/Users/wujung/miniconda3/envs/echopype_examples_v084/lib/python3.10/site-packages/xarray/core/duck_array_ops.py:215: RuntimeWarning: invalid value encountered in cast\n  return data.astype(dtype, **kwargs)\n/Users/wujung/miniconda3/envs/echopype_examples_v084/lib/python3.10/site-packages/xarray/core/duck_array_ops.py:215: RuntimeWarning: invalid value encountered in cast\n  return data.astype(dtype, **kwargs)\n\n\nCPU times: user 3min 18s, sys: 53.2 s, total: 4min 11s\nWall time: 9min\n\n\n\n\nTest for time reversals\nSmall time reversals are found in EK60 datasets, including the 2017 Pacific Hake survey, where the ping_time (or GPS time1) value may be lower (older) than the preceding ping_time by a second. Such discontinuities can interfere with concatenating individual raw files to produce an aggregated dataset. The capability to identify and address these reversals is in the echopype.qc subpackage.\n\nfor datapath in converted_dpath.glob('*'):\n    ed = ep.open_converted(datapath)\n    # Test for a negative ping_time increment in sequential timestamps, in the Sonar/Beam_group1 group\n    if exist_reversed_time(ds=ed['Sonar/Beam_group1'], time_name='ping_time'):\n        print(f'Reversed time in {datapath}')\n\nThere are no time reversals in this two-day dataset, fortunately.\n\n\nExamine the EchoData object for one of the data files\nechopype provides a user-friendly, convenient representation of an EchoData object that leverages the user-friendly xarray Dataset HTML representation. Since an EchoData object is effectively a container for multiple xarray.Dataset objects corresponding to netCDF4 groups, the notebook “print out” provides a summary view of all the groups and interactive access to summaries of each group.\nHere, ed is the last object opened in the time reversal test, in the preceding cell.\n\ned\n\n\n    \n        EchoData: standardized raw data from /Users/wujung/code_git/echopype-examples/notebooks/exports/notebook2/hakesurvey_convertedzarr/Summer2017-D20170728-T151434.zarr\n    \n    \n        \n            Top-level: contains metadata about the SONAR-netCDF4 file format.\n            \n            \n                \n                    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 0B\nDimensions:  ()\nData variables:\n    *empty*\nAttributes:\n    conventions:                 CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3\n    date_created:                2017-07-28T15:14:34Z\n    keywords:                    EK60\n    processing_level:            Level 1A\n    processing_level_url:        https://echopype.readthedocs.io/en/stable/pr...\n    sonar_convention_authority:  ICES\n    sonar_convention_name:       SONAR-netCDF4\n    sonar_convention_version:    1.0\n    summary:                     EK60 raw file Summer2017-D20170728-T151434.r...\n    title:                       2017 Joint U.S.-Canada Integrated Ecosystem ...xarray.DatasetDimensions:Coordinates: (0)Data variables: (0)Indexes: (0)Attributes: (10)conventions :CF-1.7, SONAR-netCDF4-1.0, ACDD-1.3date_created :2017-07-28T15:14:34Zkeywords :EK60processing_level :Level 1Aprocessing_level_url :https://echopype.readthedocs.io/en/stable/processing-levels.htmlsonar_convention_authority :ICESsonar_convention_name :SONAR-netCDF4sonar_convention_version :1.0summary :EK60 raw file Summer2017-D20170728-T151434.raw from the 2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey ('Pacific Hake Survey'), converted to a SONAR-netCDF4 file using echopype.Information about the survey program is available at https://www.fisheries.noaa.gov/west-coast/science-data/joint-us-canada-integrated-ecosystem-and-pacific-hake-acoustic-trawl-surveytitle :2017 Joint U.S.-Canada Integrated Ecosystem and Pacific Hake Acoustic Trawl Survey ('Pacific Hake Survey'), file Summer2017-D20170728-T151434.raw\n                \n            \n        \n        \n                    Environment: contains information relevant to acoustic propagation through water.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 30kB\nDimensions:                 (channel: 3, time1: 534)\nCoordinates:\n  * channel                 (channel) &lt;U37 444B 'GPT  18 kHz 009072058c8d 1-1...\n  * time1                   (time1) datetime64[ns] 4kB 2017-07-28T15:14:34.69...\nData variables:\n    absorption_indicative   (channel, time1) float64 13kB ...\n    frequency_nominal       (channel) float64 24B ...\n    sound_speed_indicative  (channel, time1) float64 13kB ...xarray.DatasetDimensions:channel: 3time1: 534Coordinates: (2)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')time1(time1)datetime64[ns]2017-07-28T15:14:34.693743 ... 2...axis :Tcomment :Time coordinate corresponding to environmental variables.long_name :Timestamps for NMEA position datagramsstandard_name :timearray(['2017-07-28T15:14:34.693743000', '2017-07-28T15:14:36.940872000',\n       '2017-07-28T15:14:39.167000000', ..., '2017-07-28T15:34:19.310423000',\n       '2017-07-28T15:34:21.536551000', '2017-07-28T15:34:23.762678000'],\n      dtype='datetime64[ns]')Data variables: (3)absorption_indicative(channel, time1)float64...long_name :Indicative acoustic absorptionunits :dB/mvalid_min :0.0[1602 values with dtype=float64]frequency_nominal(channel)float64...long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0[3 values with dtype=float64]sound_speed_indicative(channel, time1)float64...long_name :Indicative sound speedstandard_name :speed_of_sound_in_sea_waterunits :m/svalid_min :0.0[1602 values with dtype=float64]Indexes: (2)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 15:14:34.693743', '2017-07-28 15:14:36.940872',\n               '2017-07-28 15:14:39.167000', '2017-07-28 15:14:41.392128',\n               '2017-07-28 15:14:43.628256', '2017-07-28 15:14:45.864382',\n               '2017-07-28 15:14:48.090509', '2017-07-28 15:14:50.316637',\n               '2017-07-28 15:14:52.542765', '2017-07-28 15:14:54.778893',\n               ...\n               '2017-07-28 15:34:03.679531', '2017-07-28 15:34:05.915657',\n               '2017-07-28 15:34:08.151785', '2017-07-28 15:34:10.397915',\n               '2017-07-28 15:34:12.633043', '2017-07-28 15:34:14.859169',\n               '2017-07-28 15:34:17.085297', '2017-07-28 15:34:19.310423',\n               '2017-07-28 15:34:21.536551', '2017-07-28 15:34:23.762678'],\n              dtype='datetime64[ns]', name='time1', length=534, freq=None))Attributes: (0)\n                        \n                    \n                \n                    Platform: contains information about the platform on which the sonar is installed.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 77kB\nDimensions:              (channel: 3, time1: 1659, time2: 534)\nCoordinates:\n  * channel              (channel) &lt;U37 444B 'GPT  18 kHz 009072058c8d 1-1 ES...\n  * time1                (time1) datetime64[ns] 13kB 2017-07-28T15:14:36.2129...\n  * time2                (time2) datetime64[ns] 4kB 2017-07-28T15:14:34.69374...\nData variables: (12/20)\n    MRU_offset_x         float64 8B ...\n    MRU_offset_y         float64 8B ...\n    MRU_offset_z         float64 8B ...\n    MRU_rotation_x       float64 8B ...\n    MRU_rotation_y       float64 8B ...\n    MRU_rotation_z       float64 8B ...\n    ...                   ...\n    sentence_type        (time1) &lt;U3 20kB ...\n    transducer_offset_x  (channel) float64 24B ...\n    transducer_offset_y  (channel) float64 24B ...\n    transducer_offset_z  (channel) float64 24B ...\n    vertical_offset      (time2) float64 4kB ...\n    water_level          float64 8B ...\nAttributes:\n    platform_code_ICES:  315\n    platform_name:       Bell M. Shimada\n    platform_type:       Research vesselxarray.DatasetDimensions:channel: 3time1: 1659time2: 534Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')time1(time1)datetime64[ns]2017-07-28T15:14:36.212906 ... 2...axis :Tcomment :Time coordinate corresponding to NMEA position data.long_name :Timestamps for NMEA datagramsstandard_name :timearray(['2017-07-28T15:14:36.212906000', '2017-07-28T15:14:36.371239000',\n       '2017-07-28T15:14:37.059855000', ..., '2017-07-28T15:34:25.129833000',\n       '2017-07-28T15:34:25.288164000', '2017-07-28T15:34:26.336803000'],\n      dtype='datetime64[ns]')time2(time2)datetime64[ns]2017-07-28T15:14:34.693743 ... 2...axis :Tcomment :Time coordinate corresponding to platform motion and orientation data.long_name :Timestamps for platform motion and orientation datastandard_name :timearray(['2017-07-28T15:14:34.693743000', '2017-07-28T15:14:36.940872000',\n       '2017-07-28T15:14:39.167000000', ..., '2017-07-28T15:34:19.310423000',\n       '2017-07-28T15:34:21.536551000', '2017-07-28T15:34:23.762678000'],\n      dtype='datetime64[ns]')Data variables: (20)MRU_offset_x()float64...long_name :Distance along the x-axis from the platform coordinate system origin to the motion reference unit sensor originunits :m[1 values with dtype=float64]MRU_offset_y()float64...long_name :Distance along the y-axis from the platform coordinate system origin to the motion reference unit sensor originunits :m[1 values with dtype=float64]MRU_offset_z()float64...long_name :Distance along the z-axis from the platform coordinate system origin to the motion reference unit sensor originunits :m[1 values with dtype=float64]MRU_rotation_x()float64...long_name :Extrinsic rotation about the x-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)[1 values with dtype=float64]MRU_rotation_y()float64...long_name :Extrinsic rotation about the y-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)[1 values with dtype=float64]MRU_rotation_z()float64...long_name :Extrinsic rotation about the z-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)[1 values with dtype=float64]frequency_nominal(channel)float64...long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0[3 values with dtype=float64]latitude(time1)float64...long_name :Platform latitudestandard_name :latitudeunits :degrees_northvalid_range :(-90.0, 90.0)[1659 values with dtype=float64]longitude(time1)float64...long_name :Platform longitudestandard_name :longitudeunits :degrees_eastvalid_range :(-180.0, 180.0)[1659 values with dtype=float64]pitch(time2)float64...long_name :Platform pitchstandard_name :platform_pitch_angleunits :arc_degreevalid_range :(-90.0, 90.0)[534 values with dtype=float64]position_offset_x()float64...long_name :Distance along the x-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :m[1 values with dtype=float64]position_offset_y()float64...long_name :Distance along the y-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :m[1 values with dtype=float64]position_offset_z()float64...long_name :Distance along the z-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :m[1 values with dtype=float64]roll(time2)float64...long_name :Platform rollstandard_name :platform_roll_angleunits :arc_degreevalid_range :(-90.0, 90.0)[534 values with dtype=float64]sentence_type(time1)&lt;U3...long_name :NMEA sentence type[1659 values with dtype=&lt;U3]transducer_offset_x(channel)float64...long_name :x-axis distance from the platform coordinate system origin to the sonar transducerunits :m[3 values with dtype=float64]transducer_offset_y(channel)float64...long_name :y-axis distance from the platform coordinate system origin to the sonar transducerunits :m[3 values with dtype=float64]transducer_offset_z(channel)float64...long_name :z-axis distance from the platform coordinate system origin to the sonar transducerunits :m[3 values with dtype=float64]vertical_offset(time2)float64...long_name :Platform vertical offset from nominal water levelunits :m[534 values with dtype=float64]water_level()float64...long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :m[1 values with dtype=float64]Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 15:14:36.212906', '2017-07-28 15:14:36.371239',\n               '2017-07-28 15:14:37.059855', '2017-07-28 15:14:38.065092',\n               '2017-07-28 15:14:38.223423', '2017-07-28 15:14:39.209978',\n               '2017-07-28 15:14:40.453150', '2017-07-28 15:14:40.611479',\n               '2017-07-28 15:14:41.160091', '2017-07-28 15:14:42.359337',\n               ...\n               '2017-07-28 15:34:20.332458', '2017-07-28 15:34:20.883591',\n               '2017-07-28 15:34:21.041922', '2017-07-28 15:34:21.982553',\n               '2017-07-28 15:34:23.331808', '2017-07-28 15:34:23.490141',\n               '2017-07-28 15:34:23.982668', '2017-07-28 15:34:25.129833',\n               '2017-07-28 15:34:25.288164', '2017-07-28 15:34:26.336803'],\n              dtype='datetime64[ns]', name='time1', length=1659, freq=None))time2PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 15:14:34.693743', '2017-07-28 15:14:36.940872',\n               '2017-07-28 15:14:39.167000', '2017-07-28 15:14:41.392128',\n               '2017-07-28 15:14:43.628256', '2017-07-28 15:14:45.864382',\n               '2017-07-28 15:14:48.090509', '2017-07-28 15:14:50.316637',\n               '2017-07-28 15:14:52.542765', '2017-07-28 15:14:54.778893',\n               ...\n               '2017-07-28 15:34:03.679531', '2017-07-28 15:34:05.915657',\n               '2017-07-28 15:34:08.151785', '2017-07-28 15:34:10.397915',\n               '2017-07-28 15:34:12.633043', '2017-07-28 15:34:14.859169',\n               '2017-07-28 15:34:17.085297', '2017-07-28 15:34:19.310423',\n               '2017-07-28 15:34:21.536551', '2017-07-28 15:34:23.762678'],\n              dtype='datetime64[ns]', name='time2', length=534, freq=None))Attributes: (3)platform_code_ICES :315platform_name :Bell M. Shimadaplatform_type :Research vessel\n                        \n                    \n                \n                    NMEA: contains information specific to the NMEA protocol.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 5MB\nDimensions:        (time1: 17079)\nCoordinates:\n  * time1          (time1) datetime64[ns] 137kB 2017-07-28T15:14:34.693743 .....\nData variables:\n    NMEA_datagram  (time1) &lt;U73 5MB ...\nAttributes:\n    description:  All NMEA sensor datagramsxarray.DatasetDimensions:time1: 17079Coordinates: (1)time1(time1)datetime64[ns]2017-07-28T15:14:34.693743 ... 2...axis :Tcomment :Time coordinate corresponding to NMEA sensor data.long_name :Timestamps for NMEA datagramsstandard_name :timearray(['2017-07-28T15:14:34.693743000', '2017-07-28T15:14:35.678015000',\n       '2017-07-28T15:14:35.776020000', ..., '2017-07-28T15:34:26.701145000',\n       '2017-07-28T15:34:26.801151000', '2017-07-28T15:34:26.901155000'],\n      dtype='datetime64[ns]')Data variables: (1)NMEA_datagram(time1)&lt;U73...long_name :NMEA datagram[17079 values with dtype=&lt;U73]Indexes: (1)time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 15:14:34.693743', '2017-07-28 15:14:35.678015',\n               '2017-07-28 15:14:35.776020', '2017-07-28 15:14:35.876026',\n               '2017-07-28 15:14:35.976032', '2017-07-28 15:14:36.036615',\n               '2017-07-28 15:14:36.076038', '2017-07-28 15:14:36.176044',\n               '2017-07-28 15:14:36.276049', '2017-07-28 15:14:36.376055',\n               ...\n               '2017-07-28 15:34:26.301123', '2017-07-28 15:34:26.401127',\n               '2017-07-28 15:34:26.245136', '2017-07-28 15:34:26.501133',\n               '2017-07-28 15:34:26.336803', '2017-07-28 15:34:26.495134',\n               '2017-07-28 15:34:26.601139', '2017-07-28 15:34:26.701145',\n               '2017-07-28 15:34:26.801151', '2017-07-28 15:34:26.901155'],\n              dtype='datetime64[ns]', name='time1', length=17079, freq=None))Attributes: (1)description :All NMEA sensor datagrams\n                        \n                    \n                \n                    Provenance: contains metadata about how the SONAR-netCDF4 version of the data were obtained.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 376B\nDimensions:           (filenames: 1)\nCoordinates:\n  * filenames         (filenames) int64 8B 0\nData variables:\n    source_filenames  (filenames) &lt;U92 368B ...\nAttributes:\n    conversion_software_name:     echopype\n    conversion_software_version:  0.8.4\n    conversion_time:              2024-04-25T18:02:09Zxarray.DatasetDimensions:filenames: 1Coordinates: (1)filenames(filenames)int640long_name :Index for data and metadata source filenamesarray([0])Data variables: (1)source_filenames(filenames)&lt;U92...long_name :Source filenames[1 values with dtype=&lt;U92]Indexes: (1)filenamesPandasIndexPandasIndex(Index([0], dtype='int64', name='filenames'))Attributes: (3)conversion_software_name :echopypeconversion_software_version :0.8.4conversion_time :2024-04-25T18:02:09Z\n                        \n                    \n                \n                    Sonar: contains sonar system metadata and sonar beam groups.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 568B\nDimensions:           (beam_group: 1)\nCoordinates:\n  * beam_group        (beam_group) &lt;U11 44B 'Beam_group1'\nData variables:\n    beam_group_descr  (beam_group) &lt;U131 524B ...\nAttributes:\n    sonar_manufacturer:      Simrad\n    sonar_model:             EK60\n    sonar_serial_number:     \n    sonar_software_name:     ER60\n    sonar_software_version:  2.4.3\n    sonar_type:              echosounderxarray.DatasetDimensions:beam_group: 1Coordinates: (1)beam_group(beam_group)&lt;U11'Beam_group1'long_name :Beam group namearray(['Beam_group1'], dtype='&lt;U11')Data variables: (1)beam_group_descr(beam_group)&lt;U131...long_name :Beam group description[1 values with dtype=&lt;U131]Indexes: (1)beam_groupPandasIndexPandasIndex(Index(['Beam_group1'], dtype='object', name='beam_group'))Attributes: (6)sonar_manufacturer :Simradsonar_model :EK60sonar_serial_number :sonar_software_name :ER60sonar_software_version :2.4.3sonar_type :echosounder\n                        \n                    \n                \n                    Beam_group1: contains backscatter power (uncalibrated) and other beam or channel-specific data, including split-beam angle data when they exist.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 38MB\nDimensions:                        (channel: 3, ping_time: 534,\n                                    range_sample: 3957)\nCoordinates:\n  * channel                        (channel) &lt;U37 444B 'GPT  18 kHz 009072058...\n  * ping_time                      (ping_time) datetime64[ns] 4kB 2017-07-28T...\n  * range_sample                   (range_sample) int64 32kB 0 1 2 ... 3955 3956\nData variables: (12/29)\n    angle_alongship                (channel, ping_time, range_sample) int8 6MB ...\n    angle_athwartship              (channel, ping_time, range_sample) int8 6MB ...\n    angle_offset_alongship         (channel) float64 24B ...\n    angle_offset_athwartship       (channel) float64 24B ...\n    angle_sensitivity_alongship    (channel) float64 24B ...\n    angle_sensitivity_athwartship  (channel) float64 24B ...\n    ...                             ...\n    transmit_bandwidth             (channel, ping_time) float64 13kB ...\n    transmit_duration_nominal      (channel, ping_time) float64 13kB ...\n    transmit_frequency_start       (channel) float64 24B ...\n    transmit_frequency_stop        (channel) float64 24B ...\n    transmit_power                 (channel, ping_time) float64 13kB ...\n    transmit_type                  &lt;U2 8B ...\nAttributes:\n    beam_mode:              vertical\n    conversion_equation_t:  type_3xarray.DatasetDimensions:channel: 3ping_time: 534range_sample: 3957Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')ping_time(ping_time)datetime64[ns]2017-07-28T15:14:34.693743 ... 2...axis :Tlong_name :Timestamp of each pingstandard_name :timearray(['2017-07-28T15:14:34.693743000', '2017-07-28T15:14:36.940872000',\n       '2017-07-28T15:14:39.167000000', ..., '2017-07-28T15:34:19.310423000',\n       '2017-07-28T15:34:21.536551000', '2017-07-28T15:34:23.762678000'],\n      dtype='datetime64[ns]')range_sample(range_sample)int640 1 2 3 4 ... 3953 3954 3955 3956long_name :Along-range sample number, base 0array([   0,    1,    2, ..., 3954, 3955, 3956])Data variables: (29)angle_alongship(channel, ping_time, range_sample)int8...comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :electrical alongship angle[6339114 values with dtype=int8]angle_athwartship(channel, ping_time, range_sample)int8...comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :electrical athwartship angle[6339114 values with dtype=int8]angle_offset_alongship(channel)float64...comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :electrical alongship angle offset of the transducer[3 values with dtype=float64]angle_offset_athwartship(channel)float64...comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :electrical athwartship angle offset of the transducer[3 values with dtype=float64]angle_sensitivity_alongship(channel)float64...comment :Introduced in echopype for Simrad echosounders. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. long_name :alongship angle sensitivity of the transducer[3 values with dtype=float64]angle_sensitivity_athwartship(channel)float64...comment :Introduced in echopype for Simrad echosounders. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. long_name :athwartship angle sensitivity of the transducer[3 values with dtype=float64]backscatter_r(channel, ping_time, range_sample)float32...long_name :Raw backscatter measurements (real part)units :dB[6339114 values with dtype=float32]beam_direction_x(channel)float64...long_name :x-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0][3 values with dtype=float64]beam_direction_y(channel)float64...long_name :y-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0][3 values with dtype=float64]beam_direction_z(channel)float64...long_name :z-component of the vector that gives the pointing direction of the beam, in sonar beam coordinate systemunits :1valid_range :[-1.0, 1.0][3 values with dtype=float64]beam_stabilisation()int8...flag_meanings :['not stabilised', 'stabilised']flag_values :[0, 1]long_name :Beam stabilisation applied (or not)[1 values with dtype=int8]beam_type(channel)int64...long_name :type of transducer (0-single, 1-split)[3 values with dtype=int64]beamwidth_twoway_alongship(channel)float64...comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The alongship angle corresponds to the minor angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_minor and beamwidth_transmit_minor), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along alongship axis of beamunits :arc_degreevalid_range :[0.0, 360.0][3 values with dtype=float64]beamwidth_twoway_athwartship(channel)float64...comment :Introduced in echopype for Simrad echosounders to avoid potential confusion with convention definitions. The athwartship angle corresponds to the major angle in SONAR-netCDF4 vers 2. The convention defines one-way transmit or receive beamwidth (beamwidth_receive_major and beamwidth_transmit_major), but Simrad echosounders record two-way beamwidth in the data.long_name :Half power two-way beam width along athwartship axis of beamunits :arc_degreevalid_range :[0.0, 360.0][3 values with dtype=float64]channel_mode(channel, ping_time)int8...comment :From transmit_mode in the EK60 datagramflag_meanings :['Unknown', 'Active', 'Passive', 'Test']flag_values :[-1, 0, 1, 2]long_name :Transceiver mode[1602 values with dtype=int8]data_type(channel, ping_time)int8...flag_meanings :['power only', 'angle only', 'power and angle']flag_values :[1, 2, 3]long_name :recorded data type (1=power only, 2=angle only, 3=power and angle)[1602 values with dtype=int8]equivalent_beam_angle(channel)float64...long_name :Equivalent beam angleunits :srvalid_range :[0.0, 12.566370614359172][3 values with dtype=float64]frequency_nominal(channel)float64...long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0[3 values with dtype=float64]gain_correction(channel)float64...long_name :Gain correctionunits :dB[3 values with dtype=float64]gpt_software_version(channel)&lt;U6...[3 values with dtype=&lt;U6]non_quantitative_processing()int16...flag_meanings :['None']flag_values :[0]long_name :Presence or not of non-quantitative processing applied to the backscattering data (sonar specific)[1 values with dtype=int16]sample_interval(channel, ping_time)float64...long_name :Interval between recorded raw data samplesunits :svalid_min :0.0[1602 values with dtype=float64]sample_time_offset(channel, ping_time)float64...long_name :Time offset that is subtracted from the timestamp of each sampleunits :s[1602 values with dtype=float64]transmit_bandwidth(channel, ping_time)float64...long_name :Nominal bandwidth of transmitted pulseunits :Hzvalid_min :0.0[1602 values with dtype=float64]transmit_duration_nominal(channel, ping_time)float64...long_name :Nominal bandwidth of transmitted pulseunits :svalid_min :0.0[1602 values with dtype=float64]transmit_frequency_start(channel)float64...long_name :Start frequency in transmitted pulsestandard_name :sound_frequencyunits :Hzvalid_min :0.0[3 values with dtype=float64]transmit_frequency_stop(channel)float64...long_name :Stop frequency in transmitted pulsestandard_name :sound_frequencyunits :Hzvalid_min :0.0[3 values with dtype=float64]transmit_power(channel, ping_time)float64...long_name :Nominal transmit powerunits :Wvalid_min :0.0[1602 values with dtype=float64]transmit_type()&lt;U2...flag_meanings :['Continuous Wave – a pulse nominally of one frequency']flag_values :['CW']long_name :Type of transmitted pulse[1 values with dtype=&lt;U2]Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 15:14:34.693743', '2017-07-28 15:14:36.940872',\n               '2017-07-28 15:14:39.167000', '2017-07-28 15:14:41.392128',\n               '2017-07-28 15:14:43.628256', '2017-07-28 15:14:45.864382',\n               '2017-07-28 15:14:48.090509', '2017-07-28 15:14:50.316637',\n               '2017-07-28 15:14:52.542765', '2017-07-28 15:14:54.778893',\n               ...\n               '2017-07-28 15:34:03.679531', '2017-07-28 15:34:05.915657',\n               '2017-07-28 15:34:08.151785', '2017-07-28 15:34:10.397915',\n               '2017-07-28 15:34:12.633043', '2017-07-28 15:34:14.859169',\n               '2017-07-28 15:34:17.085297', '2017-07-28 15:34:19.310423',\n               '2017-07-28 15:34:21.536551', '2017-07-28 15:34:23.762678'],\n              dtype='datetime64[ns]', name='ping_time', length=534, freq=None))range_samplePandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956],\n      dtype='int64', name='range_sample', length=3957))Attributes: (2)beam_mode :verticalconversion_equation_t :type_3\n                        \n                    \n                \n                    Vendor_specific: contains vendor-specific information about the sonar and the data.\n                    \n                    \n                        \n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 868B\nDimensions:            (channel: 3, pulse_length_bin: 5)\nCoordinates:\n  * channel            (channel) &lt;U37 444B 'GPT  18 kHz 009072058c8d 1-1 ES18...\n  * pulse_length_bin   (pulse_length_bin) int64 40B 0 1 2 3 4\nData variables:\n    frequency_nominal  (channel) float64 24B ...\n    gain_correction    (channel, pulse_length_bin) float64 120B ...\n    pulse_length       (channel, pulse_length_bin) float64 120B ...\n    sa_correction      (channel, pulse_length_bin) float64 120B ...xarray.DatasetDimensions:channel: 3pulse_length_bin: 5Coordinates: (2)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')pulse_length_bin(pulse_length_bin)int640 1 2 3 4array([0, 1, 2, 3, 4])Data variables: (4)frequency_nominal(channel)float64...long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0[3 values with dtype=float64]gain_correction(channel, pulse_length_bin)float64...[15 values with dtype=float64]pulse_length(channel, pulse_length_bin)float64...[15 values with dtype=float64]sa_correction(channel, pulse_length_bin)float64...[15 values with dtype=float64]Indexes: (2)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))pulse_length_binPandasIndexPandasIndex(Index([0, 1, 2, 3, 4], dtype='int64', name='pulse_length_bin'))Attributes: (0)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#extract-and-process-gps-locations-from-the-platform-group-of-converted-raw-files",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#extract-and-process-gps-locations-from-the-platform-group-of-converted-raw-files",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Extract and process GPS locations from the Platform group of converted raw files",
    "text": "Extract and process GPS locations from the Platform group of converted raw files\nUse xarray.open_mfdataset to open the Platform group from all the converted raw netcdf files as a single concatenated (combined) xarray dataset. Then extract GPS time1 (time stamp), latitude and longitude from this group and transform that data into a GeoPandas GeoDataFrame containing point-geometry objects that are readily manipulated via geospatial operations. A GeoDataFrame adds geospatial capabilities to a Pandas DataFrame.\nDue to the presence of multiple time coordinates in this group, care must be taken in defining how the concatenation (combine) operation is to be performed. This is captured in the arguments passed to open_mfdataset.\n\n%%time\nplatform_ds = xr.open_mfdataset(\n    str(converted_dpath / '*.zarr'), group='Platform', \n    engine='zarr',\n    data_vars='minimal', coords='minimal',\n    combine='nested'\n)\n\nCPU times: user 32.5 s, sys: 1.2 s, total: 33.7 s\nWall time: 34.6 s\n\n\n\nplatform_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 11MB\nDimensions:              (channel: 3, time1: 244846, time2: 88959)\nCoordinates:\n  * channel              (channel) &lt;U37 444B 'GPT  18 kHz 009072058c8d 1-1 ES...\n  * time1                (time1) datetime64[ns] 2MB 2017-07-28T00:05:36.10331...\n  * time2                (time2) datetime64[ns] 712kB 2017-07-28T00:05:34.897...\nData variables: (12/20)\n    MRU_offset_x         float64 8B nan\n    MRU_offset_y         float64 8B nan\n    MRU_offset_z         float64 8B nan\n    MRU_rotation_x       float64 8B nan\n    MRU_rotation_y       float64 8B nan\n    MRU_rotation_z       float64 8B nan\n    ...                   ...\n    sentence_type        (time1) object 2MB dask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;\n    transducer_offset_x  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transducer_offset_y  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    transducer_offset_z  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\n    vertical_offset      (time2) float64 712kB dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;\n    water_level          float64 8B 9.15\nAttributes:\n    platform_code_ICES:  315\n    platform_name:       Bell M. Shimada\n    platform_type:       Research vesselxarray.DatasetDimensions:channel: 3time1: 244846time2: 88959Coordinates: (3)channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')time1(time1)datetime64[ns]2017-07-28T00:05:36.103315 ... 2...axis :Tcomment :Time coordinate corresponding to NMEA position data.long_name :Timestamps for NMEA datagramsstandard_name :timearray(['2017-07-28T00:05:36.103315000', '2017-07-28T00:05:37.511097000',\n       '2017-07-28T00:05:37.669428000', ..., '2017-07-30T00:17:57.274191000',\n       '2017-07-30T00:17:59.223482000', '2017-07-30T00:17:59.381813000'],\n      dtype='datetime64[ns]')time2(time2)datetime64[ns]2017-07-28T00:05:34.897272 ... 2...axis :Tcomment :Time coordinate corresponding to platform motion and orientation data.long_name :Timestamps for platform motion and orientation datastandard_name :timearray(['2017-07-28T00:05:34.897272000', '2017-07-28T00:05:37.162401000',\n       '2017-07-28T00:05:38.404472000', ..., '2017-07-30T00:17:52.050917000',\n       '2017-07-30T00:17:54.266043000', '2017-07-30T00:17:56.492170000'],\n      dtype='datetime64[ns]')Data variables: (20)MRU_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the motion reference unit sensor originunits :marray(nan)MRU_rotation_x()float64nanlong_name :Extrinsic rotation about the x-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_y()float64nanlong_name :Extrinsic rotation about the y-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)MRU_rotation_z()float64nanlong_name :Extrinsic rotation about the z-axis from the platform to MRU coordinate systemsunits :arc_degreevalid_range :(–180.0, 180.0)array(nan)frequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :Transducer frequencystandard_name :sound_frequencyunits :Hzvalid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nlatitude(time1)float64dask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;long_name :Platform latitudestandard_name :latitudeunits :degrees_northvalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.87 MiB\n1.87 MiB\n\n\nShape\n(244846,)\n(244846,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         244846 1\n\n\n\n\nlongitude(time1)float64dask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;long_name :Platform longitudestandard_name :longitudeunits :degrees_eastvalid_range :(-180.0, 180.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.87 MiB\n1.87 MiB\n\n\nShape\n(244846,)\n(244846,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         244846 1\n\n\n\n\npitch(time2)float64dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;long_name :Platform pitchstandard_name :platform_pitch_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n694.99 kiB\n694.99 kiB\n\n\nShape\n(88959,)\n(88959,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         88959 1\n\n\n\n\nposition_offset_x()float64nanlong_name :Distance along the x-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_y()float64nanlong_name :Distance along the y-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)position_offset_z()float64nanlong_name :Distance along the z-axis from the platform coordinate system origin to the latitude/longitude sensor originunits :marray(nan)roll(time2)float64dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;long_name :Platform rollstandard_name :platform_roll_angleunits :arc_degreevalid_range :(-90.0, 90.0)\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n694.99 kiB\n694.99 kiB\n\n\nShape\n(88959,)\n(88959,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         88959 1\n\n\n\n\nsentence_type(time1)objectdask.array&lt;chunksize=(244846,), meta=np.ndarray&gt;long_name :NMEA sentence type\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n1.87 MiB\n1.87 MiB\n\n\nShape\n(244846,)\n(244846,)\n\n\nDask graph\n1 chunks in 1859 graph layers\n\n\nData type\nobject numpy.ndarray\n\n\n\n\n         244846 1\n\n\n\n\ntransducer_offset_x(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :x-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_y(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :y-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\ntransducer_offset_z(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;long_name :z-axis distance from the platform coordinate system origin to the sonar transducerunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nvertical_offset(time2)float64dask.array&lt;chunksize=(88959,), meta=np.ndarray&gt;long_name :Platform vertical offset from nominal water levelunits :m\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n694.99 kiB\n694.99 kiB\n\n\nShape\n(88959,)\n(88959,)\n\n\nDask graph\n1 chunks in 1690 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         88959 1\n\n\n\n\nwater_level()float649.15long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(9.14999962)Indexes: (3)channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))time1PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:36.103315', '2017-07-28 00:05:37.511097',\n               '2017-07-28 00:05:37.669428', '2017-07-28 00:05:37.948589',\n               '2017-07-28 00:05:39.000582', '2017-07-28 00:05:39.158913',\n               '2017-07-28 00:05:40.353559', '2017-07-28 00:05:41.152784',\n               '2017-07-28 00:05:41.311115', '2017-07-28 00:05:42.003654',\n               ...\n               '2017-07-30 00:17:52.538342', '2017-07-30 00:17:53.276962',\n               '2017-07-30 00:17:53.926178', '2017-07-30 00:17:54.084509',\n               '2017-07-30 00:17:55.277079', '2017-07-30 00:17:55.924213',\n               '2017-07-30 00:17:56.082544', '2017-07-30 00:17:57.274191',\n               '2017-07-30 00:17:59.223482', '2017-07-30 00:17:59.381813'],\n              dtype='datetime64[ns]', name='time1', length=244846, freq=None))time2PandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:34.897272', '2017-07-28 00:05:37.162401',\n               '2017-07-28 00:05:38.404472', '2017-07-28 00:05:40.670601',\n               '2017-07-28 00:05:42.906729', '2017-07-28 00:05:45.152857',\n               '2017-07-28 00:05:47.387985', '2017-07-28 00:05:49.643114',\n               '2017-07-28 00:05:51.899244', '2017-07-28 00:05:54.145372',\n               ...\n               '2017-07-30 00:17:36.490026', '2017-07-30 00:17:38.716152',\n               '2017-07-30 00:17:40.951281', '2017-07-30 00:17:43.178410',\n               '2017-07-30 00:17:45.393536', '2017-07-30 00:17:47.619663',\n               '2017-07-30 00:17:49.835791', '2017-07-30 00:17:52.050917',\n               '2017-07-30 00:17:54.266043', '2017-07-30 00:17:56.492170'],\n              dtype='datetime64[ns]', name='time2', length=88959, freq=None))Attributes: (3)platform_code_ICES :315platform_name :Bell M. Shimadaplatform_type :Research vessel\n\n\nWe can use time1 (the timestamps for NMEA datagrams, or GPS timestamps) to examine the exact timestamp interval spanned by the combined dataset.\n\nprint(f\"{platform_ds.time1.values.min()}, {platform_ds.time1.values.max()}\")\n\n2017-07-28T00:05:36.103315000, 2017-07-30T00:17:59.381813000\n\n\nTo create the GeoPandas GeoDataFrame, first transform the latitude and longitude arrays to a single Pandas DataFrame that retains the time1 coordinate as a common index. This is done by using the DataFrame to_dataframe method together with a Pandas join operation. Then, a point GeoDataFrame is created from this DataFrame.\n\ngps_df = platform_ds.latitude.to_dataframe().join(platform_ds.longitude.to_dataframe())\n\ngps_df.head(3)\n\n\n\n\n\n\n\n\nlatitude\nlongitude\n\n\ntime1\n\n\n\n\n\n\n2017-07-28 00:05:36.103315\n43.533072\n-124.683998\n\n\n2017-07-28 00:05:37.511097\n43.533080\n-124.684005\n\n\n2017-07-28 00:05:37.669428\n43.533167\n-124.684000\n\n\n\n\n\n\n\n\ngps_gdf = gpd.GeoDataFrame(\n    gps_df,\n    geometry=gpd.points_from_xy(gps_df['longitude'], gps_df['latitude']), \n    crs=\"epsg:4326\"\n)\n\nA simple, easily generated map plot of the point GeoDataFrame\n\ngps_gdf.plot(markersize=2)"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#read-mvbs-and-plot-track-echograms-for-time-periods-corresponding-to-two-ship-tracks",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#read-mvbs-and-plot-track-echograms-for-time-periods-corresponding-to-two-ship-tracks",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Read MVBS and plot track echograms for time periods corresponding to two ship tracks",
    "text": "Read MVBS and plot track echograms for time periods corresponding to two ship tracks\n\nRead MVBS as a concatenated dataset\nUse xarray.open_mfdataset again to read and concatenate (combine) data files into a single xarray Dataset. This time, we’re reading the MVBS netCDF files.\n\n%%time\nMVBS_ds = xr.open_mfdataset(\n    str(calibrated_dpath / 'MVBS_*.nc'), \n    data_vars='minimal', coords='minimal',\n    combine='by_coords'\n)\n\nCPU times: user 2.14 s, sys: 180 ms, total: 2.32 s\nWall time: 3.16 s\n\n\n\nMVBS_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 32MB\nDimensions:            (channel: 3, ping_time: 8819, echo_range: 150)\nCoordinates:\n  * ping_time          (ping_time) datetime64[ns] 71kB 2017-07-28T00:05:20 .....\n  * channel            (channel) &lt;U37 444B 'GPT  18 kHz 009072058c8d 1-1 ES18...\n  * echo_range         (echo_range) float64 1kB 0.0 5.0 10.0 ... 740.0 745.0\nData variables:\n    Sv                 (channel, ping_time, echo_range) float64 32MB dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;\n    water_level        float64 8B 9.15\n    frequency_nominal  (channel) float64 24B dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.4\n    processing_time:              2024-04-25T17:58:23Z\n    processing_function:          commongrid.compute_MVBSxarray.DatasetDimensions:channel: 3ping_time: 8819echo_range: 150Coordinates: (3)ping_time(ping_time)datetime64[ns]2017-07-28T00:05:20 ... 2017-07-...long_name :Ping timestandard_name :timeaxis :Tarray(['2017-07-28T00:05:20.000000000', '2017-07-28T00:05:40.000000000',\n       '2017-07-28T00:06:00.000000000', ..., '2017-07-30T00:17:00.000000000',\n       '2017-07-30T00:17:20.000000000', '2017-07-30T00:17:40.000000000'],\n      dtype='datetime64[ns]')channel(channel)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')echo_range(echo_range)float640.0 5.0 10.0 ... 735.0 740.0 745.0long_name :Range distanceunits :marray([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,  55.,\n        60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105., 110., 115.,\n       120., 125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175.,\n       180., 185., 190., 195., 200., 205., 210., 215., 220., 225., 230., 235.,\n       240., 245., 250., 255., 260., 265., 270., 275., 280., 285., 290., 295.,\n       300., 305., 310., 315., 320., 325., 330., 335., 340., 345., 350., 355.,\n       360., 365., 370., 375., 380., 385., 390., 395., 400., 405., 410., 415.,\n       420., 425., 430., 435., 440., 445., 450., 455., 460., 465., 470., 475.,\n       480., 485., 490., 495., 500., 505., 510., 515., 520., 525., 530., 535.,\n       540., 545., 550., 555., 560., 565., 570., 575., 580., 585., 590., 595.,\n       600., 605., 610., 615., 620., 625., 630., 635., 640., 645., 650., 655.,\n       660., 665., 670., 675., 680., 685., 690., 695., 700., 705., 710., 715.,\n       720., 725., 730., 735., 740., 745.])Data variables: (3)Sv(channel, ping_time, echo_range)float64dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;long_name :Mean volume backscattering strength (MVBS, mean Sv re 1 m-1)units :dBactual_range :[-98.92  -1.67]cell_methods :ping_time: mean (interval: 20 second comment: ping_time is the interval start) echo_range: mean (interval: 5.0 meter comment: echo_range is the interval start)binning_mode :physical unitsrange_meter_interval :5.0mping_time_interval :20s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n30.28 MiB\n362.11 kiB\n\n\nShape\n(3, 8819, 150)\n(3, 103, 150)\n\n\nDask graph\n170 chunks in 341 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             150 8819 3\n\n\n\n\nwater_level()float649.15long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(9.14999962)frequency_nominal(channel)float64dask.array&lt;chunksize=(3,), meta=np.ndarray&gt;units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequency\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n24 B\n24 B\n\n\nShape\n(3,)\n(3,)\n\n\nDask graph\n1 chunks in 845 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n         3 1\n\n\n\n\nIndexes: (3)ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:20', '2017-07-28 00:05:40',\n               '2017-07-28 00:06:00', '2017-07-28 00:06:20',\n               '2017-07-28 00:06:40', '2017-07-28 00:07:00',\n               '2017-07-28 00:07:20', '2017-07-28 00:07:40',\n               '2017-07-28 00:08:00', '2017-07-28 00:08:20',\n               ...\n               '2017-07-30 00:14:40', '2017-07-30 00:15:00',\n               '2017-07-30 00:15:20', '2017-07-30 00:15:40',\n               '2017-07-30 00:16:00', '2017-07-30 00:16:20',\n               '2017-07-30 00:16:40', '2017-07-30 00:17:00',\n               '2017-07-30 00:17:20', '2017-07-30 00:17:40'],\n              dtype='datetime64[ns]', name='ping_time', length=8819, freq=None))channelPandasIndexPandasIndex(Index(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'],\n      dtype='object', name='channel'))echo_rangePandasIndexPandasIndex(Index([  0.0,   5.0,  10.0,  15.0,  20.0,  25.0,  30.0,  35.0,  40.0,  45.0,\n       ...\n       700.0, 705.0, 710.0, 715.0, 720.0, 725.0, 730.0, 735.0, 740.0, 745.0],\n      dtype='float64', name='echo_range', length=150))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.4processing_time :2024-04-25T17:58:23Zprocessing_function :commongrid.compute_MVBS\n\n\nReplace the channel dimension and coordinate with the frequency_nominal variable containing actual frequency values. Note that this step is possible only because there are no duplicated frequencies present.\n\nMVBS_ds = ep.consolidate.swap_dims_channel_frequency(MVBS_ds)\n\n\nMVBS_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 32MB\nDimensions:            (frequency_nominal: 3, ping_time: 8819, echo_range: 150)\nCoordinates:\n  * ping_time          (ping_time) datetime64[ns] 71kB 2017-07-28T00:05:20 .....\n  * echo_range         (echo_range) float64 1kB 0.0 5.0 10.0 ... 740.0 745.0\n  * frequency_nominal  (frequency_nominal) float64 24B 1.8e+04 3.8e+04 1.2e+05\nData variables:\n    Sv                 (frequency_nominal, ping_time, echo_range) float64 32MB dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;\n    channel            (frequency_nominal) &lt;U37 444B 'GPT  18 kHz 009072058c8...\n    water_level        float64 8B 9.15\nAttributes:\n    processing_software_name:     echopype\n    processing_software_version:  0.8.4\n    processing_time:              2024-04-25T17:58:23Z\n    processing_function:          commongrid.compute_MVBSxarray.DatasetDimensions:frequency_nominal: 3ping_time: 8819echo_range: 150Coordinates: (3)ping_time(ping_time)datetime64[ns]2017-07-28T00:05:20 ... 2017-07-...long_name :Ping timestandard_name :timeaxis :Tarray(['2017-07-28T00:05:20.000000000', '2017-07-28T00:05:40.000000000',\n       '2017-07-28T00:06:00.000000000', ..., '2017-07-30T00:17:00.000000000',\n       '2017-07-30T00:17:20.000000000', '2017-07-30T00:17:40.000000000'],\n      dtype='datetime64[ns]')echo_range(echo_range)float640.0 5.0 10.0 ... 735.0 740.0 745.0long_name :Range distanceunits :marray([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,  55.,\n        60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105., 110., 115.,\n       120., 125., 130., 135., 140., 145., 150., 155., 160., 165., 170., 175.,\n       180., 185., 190., 195., 200., 205., 210., 215., 220., 225., 230., 235.,\n       240., 245., 250., 255., 260., 265., 270., 275., 280., 285., 290., 295.,\n       300., 305., 310., 315., 320., 325., 330., 335., 340., 345., 350., 355.,\n       360., 365., 370., 375., 380., 385., 390., 395., 400., 405., 410., 415.,\n       420., 425., 430., 435., 440., 445., 450., 455., 460., 465., 470., 475.,\n       480., 485., 490., 495., 500., 505., 510., 515., 520., 525., 530., 535.,\n       540., 545., 550., 555., 560., 565., 570., 575., 580., 585., 590., 595.,\n       600., 605., 610., 615., 620., 625., 630., 635., 640., 645., 650., 655.,\n       660., 665., 670., 675., 680., 685., 690., 695., 700., 705., 710., 715.,\n       720., 725., 730., 735., 740., 745.])frequency_nominal(frequency_nominal)float641.8e+04 3.8e+04 1.2e+05units :Hzlong_name :Transducer frequencyvalid_min :0.0standard_name :sound_frequencyarray([ 18000.,  38000., 120000.])Data variables: (3)Sv(frequency_nominal, ping_time, echo_range)float64dask.array&lt;chunksize=(3, 60, 150), meta=np.ndarray&gt;long_name :Mean volume backscattering strength (MVBS, mean Sv re 1 m-1)units :dBactual_range :[-98.92  -1.67]cell_methods :ping_time: mean (interval: 20 second comment: ping_time is the interval start) echo_range: mean (interval: 5.0 meter comment: echo_range is the interval start)binning_mode :physical unitsrange_meter_interval :5.0mping_time_interval :20s\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n30.28 MiB\n362.11 kiB\n\n\nShape\n(3, 8819, 150)\n(3, 103, 150)\n\n\nDask graph\n170 chunks in 341 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             150 8819 3\n\n\n\n\nchannel(frequency_nominal)&lt;U37'GPT  18 kHz 009072058c8d 1-1 ES...long_name :Vendor channel IDarray(['GPT  18 kHz 009072058c8d 1-1 ES18-11',\n       'GPT  38 kHz 009072058146 2-1 ES38B',\n       'GPT 120 kHz 00907205a6d0 4-1 ES120-7C'], dtype='&lt;U37')water_level()float649.15long_name :Distance from the platform coordinate system origin to the nominal water level along the z-axisunits :marray(9.14999962)Indexes: (3)ping_timePandasIndexPandasIndex(DatetimeIndex(['2017-07-28 00:05:20', '2017-07-28 00:05:40',\n               '2017-07-28 00:06:00', '2017-07-28 00:06:20',\n               '2017-07-28 00:06:40', '2017-07-28 00:07:00',\n               '2017-07-28 00:07:20', '2017-07-28 00:07:40',\n               '2017-07-28 00:08:00', '2017-07-28 00:08:20',\n               ...\n               '2017-07-30 00:14:40', '2017-07-30 00:15:00',\n               '2017-07-30 00:15:20', '2017-07-30 00:15:40',\n               '2017-07-30 00:16:00', '2017-07-30 00:16:20',\n               '2017-07-30 00:16:40', '2017-07-30 00:17:00',\n               '2017-07-30 00:17:20', '2017-07-30 00:17:40'],\n              dtype='datetime64[ns]', name='ping_time', length=8819, freq=None))echo_rangePandasIndexPandasIndex(Index([  0.0,   5.0,  10.0,  15.0,  20.0,  25.0,  30.0,  35.0,  40.0,  45.0,\n       ...\n       700.0, 705.0, 710.0, 715.0, 720.0, 725.0, 730.0, 735.0, 740.0, 745.0],\n      dtype='float64', name='echo_range', length=150))frequency_nominalPandasIndexPandasIndex(Index([18000.0, 38000.0, 120000.0], dtype='float64', name='frequency_nominal'))Attributes: (4)processing_software_name :echopypeprocessing_software_version :0.8.4processing_time :2024-04-25T17:58:23Zprocessing_function :commongrid.compute_MVBS\n\n\n\n\nExtract MVBS along two N-S tracks selected via geographical bounding boxes\nDefine rectangular bounding boxes around two tracks oriented North-South, then plot a reference map showing all the GPS points (in red), the two bounding boxes (black), and the OOI mooring location (CE04 Oregon Offshore, yellow star) examined in the accompanying Jupyter notebook.\n\ntracksouth_bbox = gpd.GeoSeries(box(-125.17, 43.65, -125.14, 43.84), crs=gps_gdf.crs)\ntracknorth_bbox = gpd.GeoSeries(box(-125.17, 43.98, -125.14, 44.17), crs=gps_gdf.crs)\n\n\nbasemap = cimgt.OSM()\n\n_, ax = plt.subplots(\n    figsize=(7, 7), subplot_kw={\"projection\": basemap.crs}\n)\nbnd = gps_gdf.geometry.bounds\nax.set_extent([bnd.minx.min() - 1, bnd.maxx.max() + 2, \n               bnd.miny.min() - 0.8, bnd.maxy.max() + 2.2])\nax.add_image(basemap, 7)\nax.gridlines(draw_labels=True, xformatter=LONGITUDE_FORMATTER, yformatter=LATITUDE_FORMATTER)\n\n# GPS points\ngps_gdf.plot(ax=ax, markersize=0.1, color='red', \n             transform=ccrs.PlateCarree())\n\n# Bounding box for selected tracks\ntracksouth_bbox.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, facecolor='none', \n                     transform=ccrs.PlateCarree())\ntracknorth_bbox.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, facecolor='none', \n                     transform=ccrs.PlateCarree())\n\n# OOI CE04 Oregon Offshore mooring location\nplt.plot(-124.95, 44.37, marker='*', color='yellow', markersize=13, \n         transform=ccrs.PlateCarree());\n\n\n\n\n\n\n\n\nClip the GPS locations GeoPandas GeoDataFrame gps_gdf generated from the Platform group with the two rectangular regions, tracksouth_bbox and tracknorth_bbox. Extract from those clipped GeoDataFrames (tracksouth_gps_gdf and tracknorth_gps_gdf) the minimum and maximum time1 timestamps for each track and use them to select the corresponding time span in the MVBS data.\nFinally, create a MVBS Dataset subset for each track (tracksouth_MVBS_ds and tracknorth_MVBS_ds) by taking advantage of xarray’s “label”-based selection capability via the sel method. We select MVBS_ds data with ping_time values within the timestamp interval “slice” extracted from the geographical track. As we can see above, ping_time is a coordinate variable in the MVBS_ds Dataset.\n\ntracksouth_gps_gdf = gpd.clip(gps_gdf, tracksouth_bbox)\ntracksouth_MVBS_ds = MVBS_ds.sel(\n    ping_time=slice(tracksouth_gps_gdf.index.min(), tracksouth_gps_gdf.index.max())\n)\n\ntracknorth_gps_gdf = gpd.clip(gps_gdf, tracknorth_bbox)\ntracknorth_MVBS_ds = MVBS_ds.sel(\n    ping_time=slice(tracknorth_gps_gdf.index.min(), tracknorth_gps_gdf.index.max())\n)\n\n\n\nPlot MVBS echograms for the two N-S tracks, for all 3 frequencies\nThe final step is to create echogram plots (range vs ping_time) for each echosounder frequency and each of the two selected ship tracks. That’s 6 subplots. We first define two functions to simplify the task. plot_echograms plots the echograms of the 3 frequencies as a column of subplots, extracting the data for each frequency by using xarray’s isel index selector method, which uses index counts rather than values. As we can see above, frequency_nominal is a coordinate of the Sv (MVBS) DataArray.\n\ndef track_interval_str(trackdt):\n    \"\"\" Create the timestamp interval title string for a plot column\n    \"\"\"\n    track_interval_title_str = (\n        f\"{trackdt.index.min().strftime('%b-%d %H:%MZ')}\"\n        f\" to {trackdt.index.max().strftime('%b-%d %H:%MZ')}\"\n    )\n    return track_interval_title_str\n\ndef plot_echograms(ds, freq_len, column_idx):\n    \"\"\"Plot echograms of the 3 frequencies for xarray dataset ds,\n       as a column of subplots\"\"\"\n    for f in range(freq_len):\n        ax = axes[f][column_idx]\n        # Select Sv data by frequency using the frequency_nominal coordinate index \"f\",\n        # then plot the echogram of the selected data\n        ds.Sv.isel(frequency_nominal=f).plot(\n            ax=ax, \n            x='ping_time',\n            y='echo_range',\n            yincrease=False,\n            vmin=-80,\n            vmax=-50,\n        )\n        if f &lt; 2:\n            ax.set_xlabel(None);\n\n\nfreq_len = len(MVBS_ds.frequency_nominal)\n\nfig, axes = plt.subplots(nrows=freq_len, ncols=2, constrained_layout=True, figsize=(16, 16))\n\nfig.suptitle(\n    (f\"    South Track, {track_interval_str(tracksouth_gps_gdf)}\"\n     \"                                         \"\n     f\"North Track, {track_interval_str(tracknorth_gps_gdf)}\"),\n    fontsize=16)\n\nplot_echograms(tracksouth_MVBS_ds, freq_len, column_idx=0) # left column\nplot_echograms(tracknorth_MVBS_ds, freq_len, column_idx=1) # right column"
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#package-versions",
    "href": "topics-2024/2024-04-26-echopype/ms_PacificHake_EK60_cruisetracks.html#package-versions",
    "title": "Exploring ship echosounder data from the Pacific Hake survey",
    "section": "Package versions",
    "text": "Package versions\n\nimport datetime, s3fs\nprint(f\"echopype: {ep.__version__}, xarray: {xr.__version__}, geopandas: {gpd.__version__}, \"\n      f\"fsspec: {fsspec.__version__}, s3fs: {s3fs.__version__}\")\n\nprint(f\"\\n{datetime.datetime.utcnow()} +00:00\")\n\nechopype: 0.8.4, xarray: 2024.3.0, geopandas: 0.14.3, fsspec: 2024.3.1, s3fs: 2024.3.1\n\n2024-04-25 18:08:15.744108 +00:00"
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/oci_file_structure.html",
    "href": "topics-2024/2024-05-17-ocean-color/oci_file_structure.html",
    "title": "File Structure at Three Processing Levels for the Ocean Color Instrument (OCI)",
    "section": "",
    "text": "Authors: Anna Windle (NASA, SSAI), Ian Carroll (NASA, UMBC), Carina Poulin (NASA, SSAI)"
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/oci_file_structure.html#summary",
    "href": "topics-2024/2024-05-17-ocean-color/oci_file_structure.html#summary",
    "title": "File Structure at Three Processing Levels for the Ocean Color Instrument (OCI)",
    "section": "Summary",
    "text": "Summary\n\nIn this example we will use the earthaccess package to access an OCI Level-1B, Level-2, and Level-3 NetCDF file and open them using xarray.\nNetCDF (Network Common Data Format) is a binary file format for storing multidimensional scientific data (variables). It is optimized for array-oriented data access and support a machine-independent format for representing scientific data. Files ending in .nc are NetCDF files.\nXArray is a package that supports the use of multi-dimensional arrays in Python. It is widely used to handle Earth observation data, which often involves multiple dimensions — for instance, longitude, latitude, time, and channels/bands."
  },
  {
    "objectID": "topics-2024/2024-05-17-ocean-color/oci_file_structure.html#learning-objectives",
    "href": "topics-2024/2024-05-17-ocean-color/oci_file_structure.html#learning-objectives",
    "title": "File Structure at Three Processing Levels for the Ocean Color Instrument (OCI)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAt the end of this notebok you will know: * How to find groups in a NetCDF file * How to use xarray to open OCI data * What key variables are present in the groups within OCI L1B, L2, and L3 files\n ## Contents ***\n\nSetup\nInspecting OCI L1B File Structure\nInspecting OCI L2 File Structure\nInspecting OCI L3 File Structure\n\n ## 1. Setup ***\nWe begin by importing all of the packages used in this notebook. If you have created an environment following the guidance provided with this tutorial, then the imports will be successful.\n\nimport cartopy.crs as ccrs\nimport earthaccess\nimport h5netcdf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\n\nSet (and persist to your user profile on the host, if needed) your Earthdata Login credentials.\n\nauth = earthaccess.login(persist=True)\n\nBack to top  ## 2. Inspecting OCI L1B File Structure ***\nLet’s use xarray to open up a OCI L1B NetCDF file using earthaccess. We will use the same search method used in OCI Data Access. Note that L1B files do not include cloud coverage metadata, so we cannot use that filter.\n\ntspan = (\"2024-04-01\", \"2024-04-16\")\nbbox = (-76.75, 36.97, -75.74, 39.01)\n\nresults = earthaccess.search_data(\n    short_name=\"PACE_OCI_L1B_SCI\",\n    temporal=tspan,\n    bounding_box=bbox,\n)\n\n\npaths = earthaccess.open(results)\n\nWe want to confirm we are running code on a remote host with direct access to the NASA Earthdata Cloud. The next cell has no effect if we are, and otherwise raises an error. If there’s an error, consider the substitution explained in the OCI Data Access notebook.\n\ntry:\n    paths[0].f.bucket\nexcept AttributeError:\n    raise \"The result opened without an S3FileSystem.\"\n\nLet’s open the first file of the L1B files list:\n\ndataset = xr.open_dataset(paths[0])\ndataset\n\nNotice that this xarray.Dataset has nothing but “Attributes”. We cannot use xarray to open multi-group hierarchies or list groups within a NetCDF file, but it can open a specific group if you know its path. The xarray-datatree package is going to be merged into xarray in the not too distant future, which will allow xarray to open the entire hieerarchy. In the meantime, we can use a lower level reader to see the top-level groups.\nTODO: Link to a PACE/OCI user’s guide, referencing the section which explains each group.\n\nwith h5netcdf.File(paths[0]) as file:\n    groups = list(file)\ngroups\n\nLet’s open the “observation_data” group, which contains the core science variables.\n\ndataset = xr.open_dataset(paths[0], group=\"observation_data\")\ndataset\n\nNow you can view the Dimensions, Coordinates, and Variables of this group. To show/hide attributes, press the paper icon on the right hand side of each variable. To show/hide data reprensetaton, press the cylinder icon. For instance, you could check the attributes on “rhot_blue” to see that this variable is the “Top of Atmosphere Blue Band Reflectance”.\nThe dimensions of the “rhot_blue” variable are (“blue_bands”, “number_of_scans”, “ccd_pixels”), and it has shape (119, 1709, 1272). The sizes attribute of a variable gives us that information as a dictionary.\n\ndataset[\"rhot_blue\"].sizes\n\nLet’s plot the reflectance at postion 100 in the “blue_bands” dimension.\n\nplot = dataset[\"rhot_blue\"].sel({\"blue_bands\": 100}).plot()\n\nBack to top  ## 3. Inspecting OCI L2 File Structure\nOCI L2 files include retrievals of geophysical variables, such as Apparent Optical Properties (AOP), for each L1 swath. We’ll use the same earthaccess search for L2 AOP data. Although now we can use cloud_cover too.\n\ntspan = (\"2024-04-01\", \"2024-04-23\")\nbbox = (-76.75, 36.97, -75.74, 39.01)\nclouds = (0, 50)\n\nresults = earthaccess.search_data(\n    short_name=\"PACE_OCI_L2_AOP_NRT\",\n    temporal=tspan,\n    bounding_box=bbox,\n    cloud_cover=clouds,\n)\n\n\npaths = earthaccess.open(results)\ntry:\n    paths[0].f.bucket\nexcept AttributeError:\n    raise \"The result opened without an S3FileSystem.\"\n\n\nwith h5netcdf.File(paths[0]) as file:\n    groups = list(file)\ngroups\n\nLet’s look at the “geophysical_data” group, which is a new group generated by the level 2 processing.\n\ndataset = xr.open_dataset(paths[0], group=\"geophysical_data\")\nrrs = dataset[\"Rrs\"]\nrrs\n\n\nrrs.sizes\n\nThe Rrs variable has length 184 in the wavelength dimension, so the blue, red, and SWIR wavelengths have been combined. Let’s map the Rrs at “wavelength_3d” position 100.\n\nplot = rrs.sel({\"wavelength_3d\": 100}).plot(cmap=\"viridis\")\n\nRight now, the scene is being plotted using number_of_lines and pixels_per_line as “x” and “y”, respectively. We need to add latitude and longitude values to create a true map. To do this, we will create a merged xarray.Dataset that pulls in information from the “navigation_data” group.\n\ndataset = xr.open_dataset(paths[0], group=\"navigation_data\")\ndataset = dataset.set_coords((\"longitude\", \"latitude\"))\ndataset = dataset.rename({\"pixel_control_points\": \"pixels_per_line\"})\ndataset = xr.merge((rrs, dataset.coords))\ndataset\n\nAlthough we now have coordinates, they won’t immediately help because the data are not gridded by latitude and longitude. The Level 2 data cover the original instrument swath and have not been resampled to a regular grid. Therefore latitude and longitude are known, but cannot be used immediately to “look-up” values like you can along an array’s dimensions.\nLet’s make a scatter plot of the pixel locations so we can see the irregular spacing. By selecting a slice with a step size larger than one, we get a subset of the locations for better visualization.\n\nplot = dataset.sel(\n    {\n        \"number_of_lines\": slice(None, None, 1720 // 20),\n        \"pixels_per_line\": slice(None, None, 1272 // 20),\n    },\n).plot.scatter(x=\"longitude\", y=\"latitude\")\n\nLet’s plot this new xarray.Dataset the same way as before, but add latitude and longitude.\n\nrrs = dataset[\"Rrs\"].sel({\"wavelength_3d\": 100})\nplot = rrs.plot(x=\"longitude\", y=\"latitude\", cmap=\"viridis\", vmin=0)\n\nNow you can project the data onto a grid. If you wanna get fancy, add a coastline.\n\nfig = plt.figure()\nax = plt.axes(projection=ccrs.PlateCarree())\nax.coastlines()\nax.gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\nplot = rrs.plot(x=\"longitude\", y=\"latitude\", cmap=\"viridis\", vmin=0, ax=ax)\n\nLet’s plot the full “Rrs” spectrum for individual pixels. A visualization with all the pixels wouldn’t be useful, but limiting to a bounding box gives a simple way to subset pixels. Note that, since we still don’t have gridded data (i.e. our latitude and longitude coordinates are two-dimensional), we can’t slice on a built-in index. Without getting into anything complex, we can just box it out.\n\nrrs_box = dataset[\"Rrs\"].where(\n    (\n        (dataset[\"latitude\"] &gt; 37.52)\n        & (dataset[\"latitude\"] &lt; 37.55)\n        & (dataset[\"longitude\"] &gt; -75.46)\n        & (dataset[\"longitude\"] &lt; -75.43)\n    ),\n    drop=True,\n)\nrrs_box.sizes\n\nThe line plotting method will only draw a line plot for 1D data, which we can get by stacking our two spatial dimensions and choosing to show the new “pixel dimension” as different colors.\n\nrrs_stack = rrs_box.stack(\n    {\"pixel\": [\"number_of_lines\", \"pixels_per_line\"]}, create_index=False,\n)\nplot = rrs_stack.plot.line(hue=\"pixel\")\n\nWe will go over how to plot Rrs spectra with accurate wavelength values on the x-axis in an upcoming notebook.\nBack to top  ## 4. Inspecting OCI L3 File Structure\nAt Level-3 there are binned (B) and mapped (M) products available for OCI. The L3M remote sensing reflectance (Rrs) files contain global maps of Rrs. We’ll use the same earthaccess method to find the data.\n\ntspan = (\"2024-04-16\", \"2024-04-20\")\nbbox = (-76.75, 36.97, -75.74, 39.01)\n\nresults = earthaccess.search_data(\n    short_name=\"PACE_OCI_L3M_RRS_NRT\",\n    temporal=tspan,\n    bounding_box=bbox,\n)\n\n\npaths = earthaccess.open(results)\ntry:\n    paths[0].f.bucket\nexcept AttributeError:\n    raise \"The result opened without an S3FileSystem.\"\n\nOCI L3 data do not have any groups, so we can open the dataset without the group argument. Let’s take a look at the first file.\n\ndataset = xr.open_dataset(paths[0])\ndataset\n\nNotice that OCI L3M data has lat and lon coordinates, so it’s easy to slice out a bounding box and map the “Rrs_442” variable.\n\nfig = plt.figure()\nax = plt.axes(projection=ccrs.PlateCarree())\nax.coastlines()\nax.gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n\nrrs_442 = dataset[\"Rrs_442\"].sel({\"lat\": slice(-25, -45), \"lon\": slice(10, 30)})\nplot = rrs_442.plot(cmap=\"viridis\", vmin=0, ax=ax)\n\nAlso becuase the L3M variables have lat and lon coordinates, it’s possible to stack multiple granules along a new dimension that corresponds to time. Instead of xr.open_dataset, we use xr.open_mfdataset to create a single xarray.Dataset (the “mf” in open_mfdataset stands for multiple files) from an array of paths.\nWe also use a new search filter available in earthaccess.search_data: the granule_name argument accepts strings with the “*” wildcard. We need this to distinguish daily (“DAY”) from eight-day (“8D”) composites, as well as to get the 0.1 degree resolution projections.\n\ntspan = (\"2024-04-12\", \"2024-04-24\")\n\nresults = earthaccess.search_data(\n    short_name=\"PACE_OCI_L3M_CHL_NRT\",\n    temporal=tspan,\n    granule_name=\"*.DAY.*.0p1deg.*\",\n)\n\n\npaths = earthaccess.open(results)\ntry:\n    paths[0].f.bucket\nexcept AttributeError:\n    raise \"The result opened without an S3FileSystem.\"\n\nThe paths list is sorted temporally by default, which means the shape of the paths array specifies the way we need to tile the files together into larger arrays. We specify combine=\"nested\" to combine the files according to the shape of the array of files (or file-like objects), even though paths is not a “nested” list in this case. The concat_dim=\"date\" argument generates a new dimension in the combined dataset, because “date” is not an existing dimension in the individual files.\n\ndataset = xr.open_mfdataset(\n    paths,\n    combine=\"nested\",\n    concat_dim=\"date\",\n)\ndataset\n\nA common reason to generate a single dataset from multiple, daily images is to create a composite. Compare the map from a single day …\n\nchla = np.log10(dataset[\"chlor_a\"])\nchla.attrs.update(\n    {\n        \"units\": f'lg({dataset[\"chlor_a\"].attrs[\"units\"]})',\n    }\n)\nplot = chla.sel({\"date\": 0}).plot(aspect=2, size=4, cmap=\"GnBu_r\")\n\n… to a map of average values, skipping “NaN” values that result from clouds.\n\nchla_avg = chla.mean(\"date\")\nchla_avg.attrs.update(\n    {\n        \"long_name\": chla.attrs[\"long_name\"],\n        \"units\": f'lg({chla.attrs[\"units\"]})',\n    }\n)\nplot = chla_avg.plot(aspect=2, size=4, cmap=\"GnBu_r\")\n\n\n\nYou have completed the notebook on OCI file structure. More notebooks are comming soon!"
  },
  {
    "objectID": "topics-skills/02-git-authentication.html#tell-git-who-you-are",
    "href": "topics-skills/02-git-authentication.html#tell-git-who-you-are",
    "title": "GitHub Authentication",
    "section": "Tell Git who you are",
    "text": "Tell Git who you are\nFirst open a terminal and run these lines. Replace &lt;your email&gt; with your email and remove the angle brackets.\ngit config --global user.email \"&lt;your email&gt;\"\ngit config --global user.name \"&lt;your name&gt;\"\ngit config --global pull.rebase false",
    "crumbs": [
      "JupyterHub",
      "Git Authentication"
    ]
  },
  {
    "objectID": "topics-skills/02-git-authentication.html#authentication",
    "href": "topics-skills/02-git-authentication.html#authentication",
    "title": "GitHub Authentication",
    "section": "Authentication",
    "text": "Authentication\nYou need to authenticate to GitHub so you can push your local changes up to GitHub. There are a few ways to do this. For the JupyterHub, we will mainly use gh-scroped-creds which is a secure app that temporarily stores your GitHub credentials on a JupyterHub. But we will also show you a way to store your credentials in a file that works on any computer, including a virtual computer like the JupyterHub.",
    "crumbs": [
      "JupyterHub",
      "Git Authentication"
    ]
  },
  {
    "objectID": "topics-skills/02-git-authentication.html#preferred-gh-scoped-creds",
    "href": "topics-skills/02-git-authentication.html#preferred-gh-scoped-creds",
    "title": "GitHub Authentication",
    "section": "Preferred: gh-scoped-creds",
    "text": "Preferred: gh-scoped-creds\nIf you get the error that it cannot find gh-scoped-creds, then type\npip install gh-scoped-creds\nin a termnal.\n\nOpen a terminal\nType gh-scoped-creds\nFollow the instructions\nFIRST TIME: Make sure to follow the second pop-up instructions and tell it what repos it is allowed to interact with. You have to go through a number of pop up windows.\n\nJump down to the “Test” section to test.",
    "crumbs": [
      "JupyterHub",
      "Git Authentication"
    ]
  },
  {
    "objectID": "topics-skills/02-git-authentication.html#also-works-set-up-authentication-with-a-personal-token",
    "href": "topics-skills/02-git-authentication.html#also-works-set-up-authentication-with-a-personal-token",
    "title": "GitHub Authentication",
    "section": "Also works: Set up authentication with a Personal Token",
    "text": "Also works: Set up authentication with a Personal Token\nThis will store your credentials in a file on the hub. This is not as secure since the file is unencrypted but sometimes gh-scoped-creds will not be an option.\n\nStep 1: Generate a Personal Access Token\nWe are going to generate a classic token.\n\nGo to https://github.com/settings/tokens\nClick Generate new token &gt; Generate new token (classic)\nWhen the pop-up shows up, fill in a description, click the “repo” checkbox, and then scroll to bottom to click “Generate”.\nSAVE the token. You need it for the next step.\n\n\n\nStep 2: Tell Git who your are\n\nOpen a terminal in JupyterLab or RStudio\nPaste these 3 lines of code into the terminal\n\ngit config --global credential.helper store",
    "crumbs": [
      "JupyterHub",
      "Git Authentication"
    ]
  },
  {
    "objectID": "topics-skills/02-git-authentication.html#test",
    "href": "topics-skills/02-git-authentication.html#test",
    "title": "GitHub Authentication",
    "section": "Test",
    "text": "Test\n\nGo to https://github.com/new\nCreate a PRIVATE repo called “test”\nMake sure to check the “Add a README file” box!\nOpen a terminal and type these lines. Make sure to replace &lt;username&gt;\n\ngit clone https://github.com/&lt;username&gt;/test\n\nIf you properly authenticated, git will ask for your username and password. At the password, paste in the TOKEN not your actual password.",
    "crumbs": [
      "JupyterHub",
      "Git Authentication"
    ]
  },
  {
    "objectID": "topics-skills/02-git-jupyter-old.html",
    "href": "topics-skills/02-git-jupyter-old.html",
    "title": "Git in JupyterLab",
    "section": "",
    "text": "In this tutorial, we will provide a brief introduction to version control with Git."
  },
  {
    "objectID": "topics-skills/02-git-jupyter-old.html#step-3",
    "href": "topics-skills/02-git-jupyter-old.html#step-3",
    "title": "Git in JupyterLab",
    "section": "Step 3:",
    "text": "Step 3:\nConfigure git with your name and email address.\n``` bash\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\n```\n\n**Note:** This name and email could be different from your github.com credentials. Remember `git` is a program that keeps track of your changes locally (on 2i2c JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by `git`, the email/name used in git configuration will show up next to your contributions on github.com when you `push` your repository to github.com (`git push` is discussed in a later step).\n\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\n\n\nGenerate Personal Access Token on github.com\n\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git JupyterLab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#prerequisites",
    "href": "topics-skills/02-git-rstudio.html#prerequisites",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nRead Intro to Git\nHave a GitHub account\nGit Authentication",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#create-a-github-account",
    "href": "topics-skills/02-git-rstudio.html#create-a-github-account",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\nFor access to the NMFS Openscapes JupyterHub, you will need at GitHub account. See the main HackHour page on how to request access (NOAA staff). For NMFS staff, you can look at the NMFS OpenSci GitHub Guide information for how to create your user account and you will find lots of information on the NMFS GitHub Governance Team Training Page (visible only to NOAA staff).",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#setting-up-git-authentication",
    "href": "topics-skills/02-git-rstudio.html#setting-up-git-authentication",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "Setting up Git Authentication",
    "text": "Setting up Git Authentication\nBefore we can work with Git in the JupyterHub, your need to do some set up. Do the steps here: Git Authentication",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#git-tab-in-rstudio",
    "href": "topics-skills/02-git-rstudio.html#git-tab-in-rstudio",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "Git tab in RStudio",
    "text": "Git tab in RStudio\nWhen the instructions say to use or open or click the Git tab, look here:",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#the-key-skills",
    "href": "topics-skills/02-git-rstudio.html#the-key-skills",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "The Key Skills",
    "text": "The Key Skills\n\nSkill 1: Create a blank repo on GitHub\nSkill 2: Clone your GitHub repo to RStudio\nSkill 3: Make some changes and commit those local changes\nSkill 4: Push the changes to GitHub\nSkill 1b: Copy someone else’s GitHub repository",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#lets-see-it-done",
    "href": "topics-skills/02-git-rstudio.html#lets-see-it-done",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "Let’s see it done!",
    "text": "Let’s see it done!\n\nSkill 1: Create a blank repo on GitHub\n\nClick the + in the upper left from YOUR GitHub page.\nGive your repo the name Test and make sure it is public.\nClick new and check checkbox to add the Readme file and .gitignore\nCopy the URL of your new repo. It’s in the browser where you normally see a URL.\n\nShow me\n\n\nSkill 2: Clone your repo to the RStudio\nIn RStudio we do this by making a new project.\n\nCopy the URL of your repo. https://www.github.com/yourname/Test\nFile &gt; New Project &gt; Version Control &gt; Git\nPaste in the URL of your repo from Step 1\nCheck that it is being created in your Home directory which will be denoted ~ in the JupyterHub.\nClick Create.\n\nShow me\n\n\nSkill 3: Make some changes and commit your changes\nThis writes a note about what changes you have made. It also marks a ‘point’ in time that you can go back to if you need to.\n\nMake some changes to the README.md file in the Test repo.\nClick the Git tab, and stage the change(s) by checking the checkboxes next to the files listed.\nClick the Commit button.\nAdd a commit comment, click commit.\n\nShow me\n\n\nSkill 4: Push changes to GitHub / Pull changes from GitHub\nTo push changes you committed in Skill #3\n\nFrom Git tab, click on the Green up arrow that says Push.\n\nTo pull changes on GitHub that are not on your local computer:\n\nMake some changes directly on GitHub (not in RStudio)\nFrom Git tab, click on the down arrow that says Pull.\n\nShow me\n\n\nActivity 1\nIn RStudio,\n\nMake a copy of README.md\nRename it to .md\nAdd some text.\nStage and commit the added file.\nPush to GitHub.\n\nShow me in RStudio\n\n\nActivity 2\n\nGo to your Test repo on GitHub. https://www.github.com/yourname/Test\nCreate a file called test.md.\nStage and then commit that new file.\nGo to RStudio and pull in that new file.\n\n\n\nActivity 3\nYou can copy your own or other people’s repos1.\n\nIn a browser, go to the GitHub repository https://github.com/RWorkflow-Workshops/Week5\nCopy its URL.\nNavigate to your GitHub page: click your icon in the upper right and then ‘your repositories’\nClick the + in top right and click import repository. Paste in the URL and give your repo a name.\nUse Skill #1 to clone your new repo to RStudio and create a new project",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#clean-up-after-you-are-done",
    "href": "topics-skills/02-git-rstudio.html#clean-up-after-you-are-done",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "Clean up after you are done",
    "text": "Clean up after you are done\n\nOpen a Terminal\nType\ncd ~\nrm -rf Test\nrm -rf Week5",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git-rstudio.html#footnotes",
    "href": "topics-skills/02-git-rstudio.html#footnotes",
    "title": "Basic Git/GitHub Skills in RStudio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is different from forking. There is no connection to the original repository.↩︎",
    "crumbs": [
      "JupyterHub",
      "Git in RStudio"
    ]
  },
  {
    "objectID": "topics-skills/02-git.html#what-is-git-and-github",
    "href": "topics-skills/02-git.html#what-is-git-and-github",
    "title": "Intro to Version Control, Git and GitHub",
    "section": "What is Git and GitHub?",
    "text": "What is Git and GitHub?\nGit A program to track your file changes and create a history of those changes. Creates a ‘container’ for a set of files called a repository.\nGitHub A website to host these repositories and allow you to sync local copies (on your computer) to the website. Lots of functionality built on top of this.",
    "crumbs": [
      "JupyterHub",
      "Intro to Git"
    ]
  },
  {
    "objectID": "topics-skills/02-git.html#some-basic-git-jargon",
    "href": "topics-skills/02-git.html#some-basic-git-jargon",
    "title": "Intro to Version Control, Git and GitHub",
    "section": "Some basic Git jargon",
    "text": "Some basic Git jargon\n\nRepo Repository. It is your code and the record of your changes. This record and also the status of your repo is a hidden folder called .git . You have a local repo and a remote repo. The remote repo is on GitHub (for in our case) is called origin. The local repo is on the JupyterHub.\nStage Tell Git which changes you want to commit (write to the repo history).\nCommit Write a note about what change the staged files and “commit” that note to the repository record. You are also tagging this state of the repo and you could go back to this state if you wanted.\nPush Push local changes (commits) up to the remote repository on GitHub (origin).\nPull Pull changes on GitHub into the local repository on the JupyterHub.\nGit GUIs A graphical interface for Git (which is command line). Today I will use jupyterlab-git which we have installed on JupyterHub.\nShell A terminal window where we can issue git commands.",
    "crumbs": [
      "JupyterHub",
      "Intro to Git"
    ]
  },
  {
    "objectID": "topics-skills/02-git.html#overview",
    "href": "topics-skills/02-git.html#overview",
    "title": "Intro to Version Control, Git and GitHub",
    "section": "Overview",
    "text": "Overview\nToday I will cover the four basic Git/GitHub skills. The goal for today is to first get you comfortable with the basic skills and terminology. We will use what is called a “trunk-based workflow”.\n\nSimple Trunk-based Workflow:\n\nMake local (on your computer) changes to code.\nRecord what those changes were about and commit to the code change record (history).\nPush those changes to your remote repository (aka origin)\n\nWe’ll do this",
    "crumbs": [
      "JupyterHub",
      "Intro to Git"
    ]
  },
  {
    "objectID": "topics-skills/02-git.html#the-key-skills",
    "href": "topics-skills/02-git.html#the-key-skills",
    "title": "Intro to Version Control, Git and GitHub",
    "section": "The Key Skills",
    "text": "The Key Skills\nThese basic skills are all you need to learn to get started:\n\nSkill 1: Create a blank repo on GitHub (the remote or origin)\nSkill 2: Clone your GitHub repo to your local computer (in our case the JupyterHub)\nSkill 3: Make some changes and commit those local changes\nSkill 4: Push the changes to GitHub (the remote or origin)\nSkill 1b: Create a new repo from some else’s GitHub repository\n\nIn the next tutorials, you will practice these in RStudio or JuptyerHub.",
    "crumbs": [
      "JupyterHub",
      "Intro to Git"
    ]
  },
  {
    "objectID": "topics-skills/03-AWS_S3_bucket.html",
    "href": "topics-skills/03-AWS_S3_bucket.html",
    "title": "Instructions for setting up an AWS S3 bucket for your project",
    "section": "",
    "text": "This set of instructions will walk through how to setup an AWS S3 bucket for a specific project and how to configure that bucket to allow all members of the project team to have access.\nThis notebook is from the CryoCloud documentation. THE CODE WILL NOT WORK SINCE YOU NEED TO AUTHENTICATE TO THE S3 BUCKET.",
    "crumbs": [
      "JupyterHub",
      "AWS S3 Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-AWS_S3_bucket.html#create-an-aws-account-and-s3-bucket",
    "href": "topics-skills/03-AWS_S3_bucket.html#create-an-aws-account-and-s3-bucket",
    "title": "Instructions for setting up an AWS S3 bucket for your project",
    "section": "Create an AWS account and S3 bucket",
    "text": "Create an AWS account and S3 bucket\nThe first step is to create an AWS account that will be billed to your particular project. This can be done using these instructions.",
    "crumbs": [
      "JupyterHub",
      "AWS S3 Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-AWS_S3_bucket.html#create-aws-s3-bucket",
    "href": "topics-skills/03-AWS_S3_bucket.html#create-aws-s3-bucket",
    "title": "Instructions for setting up an AWS S3 bucket for your project",
    "section": "Create AWS S3 bucket",
    "text": "Create AWS S3 bucket\nWithin your new AWS account, create an new S3 bucket:\n\nOpen the AWS S3 console (https://console.aws.amazon.com/s3/)\nFrom the navigation pane, choose Buckets\nChoose Create bucket\nName the bucket and select us-west-2 for the region\nLeave all other default options\nClick Create Bucket",
    "crumbs": [
      "JupyterHub",
      "AWS S3 Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-AWS_S3_bucket.html#create-a-user",
    "href": "topics-skills/03-AWS_S3_bucket.html#create-a-user",
    "title": "Instructions for setting up an AWS S3 bucket for your project",
    "section": "Create a user",
    "text": "Create a user\nWithin the same AWS account, create a new IAM user:\n\nOn the AWS Console Home page, select the IAM service\nIn the navigation pane, select Users and then select Add users\nName the user and click Next\nAttach policies directly\nDo not select any policies\nClick Next\nCreate user\n\nOnce the user has been created, find the user’s ARN and copy it.\nNow, create access keys for this user:\n\nSelect Users and click the user that you created\nOpen the Security Credentials tab\nCreate access key\nSelect Command Line Interface (CLI)\nCheck the box to agree to the recommendation and click Next\nLeave the tag blank and click Create access key\nIMPORTANT: Copy the access key and the secret access key. This will be used later.",
    "crumbs": [
      "JupyterHub",
      "AWS S3 Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-AWS_S3_bucket.html#create-the-bucket-policy",
    "href": "topics-skills/03-AWS_S3_bucket.html#create-the-bucket-policy",
    "title": "Instructions for setting up an AWS S3 bucket for your project",
    "section": "Create the bucket policy",
    "text": "Create the bucket policy\nConfigure a policy for this S3 bucket that will allow the newly created user to access it.\n\nOpen the AWS S3 console (https://console.aws.amazon.com/s3/)\nFrom the navigation pane, choose Buckets\nSelect the new S3 bucket that you created\nOpen the Permissions tab\nAdd the following bucket policy, replacing USER_ARN with the ARN that you copied above and BUCKET_ARN with the bucket ARN, found on the Edit bucket policy page on the AWS console:\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"ListBucket\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"USER_ARN\"\n            },\n            \"Action\": \"s3:ListBucket\",\n            \"Resource\": \"BUCKET_ARN\"\n        },\n        {\n            \"Sid\": \"AllObjectActions\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"USER_ARN\"\n            },\n            \"Action\": \"s3:*Object\",\n            \"Resource\": \"BUCKET_ARN/*\"\n        }\n    ]\n}",
    "crumbs": [
      "JupyterHub",
      "AWS S3 Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-AWS_S3_bucket.html#reading-from-the-s3-bucket",
    "href": "topics-skills/03-AWS_S3_bucket.html#reading-from-the-s3-bucket",
    "title": "Instructions for setting up an AWS S3 bucket for your project",
    "section": "Reading from the S3 bucket",
    "text": "Reading from the S3 bucket\n\nExample: ls bucket using s3fs\n\nimport s3fs\ns3 = s3fs.S3FileSystem(anon=False, profile='icesat2')\n\n\n\nExample: open HDF5 file using xarray\n\nimport s3fs\nimport xarray as xr\n\nfs_s3 = s3fs.core.S3FileSystem(profile='icesat2')\n\ns3_url = 's3://gris-outlet-glacier-seasonality-icesat2/ssh_grids_v2205_1992101012.nc'\ns3_file_obj = fs_s3.open(s3_url, mode='rb')\nssh_ds = xr.open_dataset(s3_file_obj, engine='h5netcdf')\nprint(ssh_ds)\n\n&lt;xarray.Dataset&gt;\nDimensions:      (Longitude: 2160, nv: 2, Latitude: 960, Time: 1)\nCoordinates:\n  * Longitude    (Longitude) float32 0.08333 0.25 0.4167 ... 359.6 359.8 359.9\n  * Latitude     (Latitude) float32 -79.92 -79.75 -79.58 ... 79.58 79.75 79.92\n  * Time         (Time) datetime64[ns] 1992-10-10T12:00:00\nDimensions without coordinates: nv\nData variables:\n    Lon_bounds   (Longitude, nv) float32 ...\n    Lat_bounds   (Latitude, nv) float32 ...\n    Time_bounds  (Time, nv) datetime64[ns] ...\n    SLA          (Time, Latitude, Longitude) float32 ...\n    SLA_ERR      (Time, Latitude, Longitude) float32 ...\nAttributes: (12/21)\n    Conventions:            CF-1.6\n    ncei_template_version:  NCEI_NetCDF_Grid_Template_v2.0\n    Institution:            Jet Propulsion Laboratory\n    geospatial_lat_min:     -79.916664\n    geospatial_lat_max:     79.916664\n    geospatial_lon_min:     0.083333336\n    ...                     ...\n    version_number:         2205\n    Data_Pnts_Each_Sat:     {\"16\": 661578, \"1001\": 636257}\n    source_version:         commit dc95db885c920084614a41849ce5a7d417198ef3\n    SLA_Global_MEAN:        -0.0015108844021796562\n    SLA_Global_STD:         0.09098986023297456\n    latency:                final\n\n\n\nimport s3fs\n\nimport xarray as xr\n\nimport hvplot.xarray\nimport holoviews as hv\n\nfs_s3 = s3fs.core.S3FileSystem(profile='icesat2')\n\ns3_url = 's3://gris-outlet-glacier-seasonality-icesat2/ssh_grids_v2205_1992101012.nc'\ns3_file_obj = fs_s3.open(s3_url, mode='rb')\nssh_ds = xr.open_dataset(s3_file_obj, engine='h5netcdf')\nssh_da = ssh_ds.SLA\n\nssh_da.hvplot.image(x='Longitude', y='Latitude', cmap='Spectral_r', geo=True, tiles='ESRI', global_extent=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nExample: read a geotiff using rasterio\n\nimport rasterio\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nsession = rasterio.env.Env(profile_name='icesat2')\n\nurl = 's3://gris-outlet-glacier-seasonality-icesat2/out.tif'\n\nwith session:\n    with rasterio.open(url) as ds:\n        print(ds.profile)\n        band1 = ds.read(1)\n        \nband1[band1==-9999] = np.nan\nplt.imshow(band1)\nplt.colorbar()\n\n{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -9999.0, 'width': 556, 'height': 2316, 'count': 1, 'crs': CRS.from_epsg(3413), 'transform': Affine(50.0, 0.0, -204376.0,\n       0.0, -50.0, -2065986.0), 'blockysize': 3, 'tiled': False, 'interleave': 'band'}",
    "crumbs": [
      "JupyterHub",
      "AWS S3 Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-AWS_S3_bucket.html#writing-to-the-s3-bucket",
    "href": "topics-skills/03-AWS_S3_bucket.html#writing-to-the-s3-bucket",
    "title": "Instructions for setting up an AWS S3 bucket for your project",
    "section": "Writing to the S3 bucket",
    "text": "Writing to the S3 bucket\n\ns3 = s3fs.core.S3FileSystem(profile='icesat2')\n\nwith s3.open('gris-outlet-glacier-seasonality-icesat2/new-file', 'wb') as f:\n    f.write(2*2**20 * b'a')\n    f.write(2*2**20 * b'a') # data is flushed and file closed\n\ns3.du('gris-outlet-glacier-seasonality-icesat2/new-file')\n\n4194304",
    "crumbs": [
      "JupyterHub",
      "AWS S3 Bucket"
    ]
  },
  {
    "objectID": "topics-skills/03-earthdata.html",
    "href": "topics-skills/03-earthdata.html",
    "title": "Earthdata Login",
    "section": "",
    "text": "NASA data are stored at one of several Distributed Active Archive Centers (DAACs). If you’re interested in available data for a given area and time of interest, the Earthdata Search portal provides a convenient web interface.",
    "crumbs": [
      "JupyterHub",
      "Earthdata login"
    ]
  },
  {
    "objectID": "topics-skills/03-earthdata.html#why-do-i-need-an-earthdata-login",
    "href": "topics-skills/03-earthdata.html#why-do-i-need-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "Why do I need an Earthdata login?",
    "text": "Why do I need an Earthdata login?\nTo programmatically access NASA data from within your Python or R scripts, you will need to enter your Earthdata username and password.",
    "crumbs": [
      "JupyterHub",
      "Earthdata login"
    ]
  },
  {
    "objectID": "topics-skills/03-earthdata.html#getting-an-earthdata-login",
    "href": "topics-skills/03-earthdata.html#getting-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "Getting an Earthdata login",
    "text": "Getting an Earthdata login\nIf you do not already have an Earthdata login, then navigate to the Earthdata Login page, a username and password, and then record this somewhere for use during the tutorials:",
    "crumbs": [
      "JupyterHub",
      "Earthdata login"
    ]
  },
  {
    "objectID": "topics-skills/03-earthdata.html#configure-programmatic-access-to-nasa-servers",
    "href": "topics-skills/03-earthdata.html#configure-programmatic-access-to-nasa-servers",
    "title": "Earthdata Login",
    "section": "Configure programmatic access to NASA servers",
    "text": "Configure programmatic access to NASA servers\nRun the following commands on the JupyterHub:\n\n\n\n\n\n\nImportant\n\n\n\nIn the below command, replace EARTHDATA_LOGIN with your personal username and EARTHDATA_PASSWORD with your password\n\n\necho 'machine urs.earthdata.nasa.gov login \"EARTHDATA_LOGIN\" password \"EARTHDATA_PASSWORD\"' &gt; ~/.netrc\nchmod 0600 ~/.netrc",
    "crumbs": [
      "JupyterHub",
      "Earthdata login"
    ]
  },
  {
    "objectID": "topics-skills/04-other-images.html#other-images-on-the-hub",
    "href": "topics-skills/04-other-images.html#other-images-on-the-hub",
    "title": "Using other images on the JupyterHub",
    "section": "Other images on the hub",
    "text": "Other images on the hub\nUse the dropdown to select a non-default image on the hub. There are a variety. You can learn about them on the NMFS Open Science container images repo.",
    "crumbs": [
      "JupyterHub",
      "Other images"
    ]
  },
  {
    "objectID": "topics-skills/04-other-images.html#using-other-images-not-on-the-hub",
    "href": "topics-skills/04-other-images.html#using-other-images-not-on-the-hub",
    "title": "Using other images on the JupyterHub",
    "section": "Using other images not on the hub",
    "text": "Using other images not on the hub\nThe JupyterHub can run other images that are compatible with a JupyterHub, e.g. Binder images. When you start the hub, use the image dropdown to select “Other”:\n\nYou can add a url to a Docker image to this. For example, if you wanted to use the Pangeo notebook docker images image, you would paste one of these into the “Custom image” box.\nFrom DockerHub: pangeo/pangeo-notebook From Quay.io quay.io/pangeo/pangeo-notebook\nOther common data science images:\n\nJupyter Docker Stacks\nNASA Openscapes python\nRocker Binder image\nPangeo\ngeocompx\nGPU accelerated data science docker images",
    "crumbs": [
      "JupyterHub",
      "Other images"
    ]
  },
  {
    "objectID": "topics-skills/04-other-images.html#using-a-github-repo",
    "href": "topics-skills/04-other-images.html#using-a-github-repo",
    "title": "Using other images on the JupyterHub",
    "section": "Using a GitHub repo",
    "text": "Using a GitHub repo\nYou can also create an environment with a MyBinder.org compatible GitHub repo. By selecting the “Build your own image” option.\n\n\nSimple example for Python\nThere are two ways to do this. Either via a conda environment or a pip install.\nconda example\n\nPut an environment.yml file in your GitHub repo at the base level with your Python packages that you need.\nCopy the url to your repo and paste that into the “Repository” box (above).\n\nenvironment.yml\nname: example-environment\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.11\n  - numpy\n  - psutil\n  - toolz\n  - matplotlib\n  - dill\n  - pandas\n  - partd\n  - bokeh\n  - dask\npip install example\nYou will need requirements.txt for packages and runtime.txt for the Python version.\nrequirements.txt\nnumpy\nmatplotlib==3.*\nseaborn==0.13.*\npandas\nruntime.txt\npython-3.10\n\n\nSimple example for R\nr example\nYou will need install.R for packages and runtime.txt for the R version.\ninstall.R\ninstall.packages(\"tidyverse\")\ninstall.packages(\"rmarkdown\")\ninstall.packages(\"httr\")\ninstall.packages(\"shinydashboard\")\ninstall.packages(\"leaflet\")\nruntime.txt\nr-4.3.2-2024-01-10",
    "crumbs": [
      "JupyterHub",
      "Other images"
    ]
  },
  {
    "objectID": "topics-2023/2023-12-09-earthdataaccess-intro/index.html#acknowledgements",
    "href": "topics-2023/2023-12-09-earthdataaccess-intro/index.html#acknowledgements",
    "title": "NOAA HackHours",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis content is from the NASA Openscapes AGU 2023 workshop\nhttps://github.com/NASA-Openscapes/2023-Cloud-Workshop-AGU",
    "crumbs": [
      "Earth Data Access in Python"
    ]
  },
  {
    "objectID": "topics-2024/2024-06-14-cefi/index.html",
    "href": "topics-2024/2024-06-14-cefi/index.html",
    "title": "CEFI Portal",
    "section": "",
    "text": "Image: Py-R Geospatial\nThis week Chia-Wei Hsu, developer of the CEFI Portal, will share some cookbooks for work with the CEFI data. https://psl.noaa.gov/cefi_portal/#cookbooks\nThis is a growing database to include more CEFI related resources. If you are interested to contribute on any resource. Please try fill this form in the GitHub issue we designed for resource submission. https://github.com/NOAA-CEFI-Portal/CEFI-info-hub-list/issues/new?assignees=chiaweh2&labels=&projects=&template=add_cefi_resource.yml&title=%5BAdd+new+CEFI+resource%5D%3A+ (Thank you Sunny for submitting a new resource!)\nSome useful links below:\n\nCEFI portal : https://psl.noaa.gov/cefi_portal/#overview\nCEFI portal GitHub organization : https://github.com/NOAA-CEFI-Portal\nData OPeNDAP : https://psl.noaa.gov/thredds/catalog/Projects/CEFI/catalog.html",
    "crumbs": [
      "JupyterHub",
      "Python - CEFI Portal"
    ]
  },
  {
    "objectID": "topics-2025/2025-planetarycomputer-r/index.html",
    "href": "topics-2025/2025-planetarycomputer-r/index.html",
    "title": "Microsoft Planetary Computer in R",
    "section": "",
    "text": "https://planetarycomputer.microsoft.com/docs/quickstarts/reading-stac-r/"
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html",
    "href": "topics-skills/01-intro-to-jupyterhub.html",
    "title": "Intro to JupyterHubs",
    "section": "",
    "text": "In this tutorial, you will get an overview of our JupyterHub.",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#log-into-the-jupyterhub",
    "href": "topics-skills/01-intro-to-jupyterhub.html#log-into-the-jupyterhub",
    "title": "Intro to JupyterHubs",
    "section": "Log into the JupyterHub",
    "text": "Log into the JupyterHub\nGo to https://nmfs-openscapes.2i2c.cloud/. Click “Login to continue”. You will be asked to log in with your GitHub Account, if you are not logged in already.\n\n\n\nNMFS Openscapes JupyterHub Login\n\n\n\nImage type: Python or R\nNext you select your image type from the drop-down. The default is a geospatial image with Python and R.\n\n\nVirtual Machine size\nYou’ll see a dropdown that allows you to choose the size of virtual machine. For the tutorials, you will only need the smallest virtual machine. Please only choose the large machines if you run out of RAM as the larger machines cost us more.\n\n\n\nMachine Profiles\n\n\n\n\nStart up\nAfter we select our server type and click on start, JupyterHub will allocate our virtual machine. This may take several minutes.\n\n\n\nJupyterhub Spawning",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#the-launcher",
    "href": "topics-skills/01-intro-to-jupyterhub.html#the-launcher",
    "title": "Intro to JupyterHubs",
    "section": "The Launcher",
    "text": "The Launcher\nWhen you are in the JupyterLab tab (note the Jupyter Logo), you will see a Launcher page. If you don’t see this, go to File &gt; New Launcher or click the blue button on the top left. From the Launcher, you will see a buttons to open a new Jupyter Notebook, RStudio, Desktop and VSCode on the top row and buttons to open a Terminal and other file types below.\n Clicking on the “Python 3”, Terminal, Text File and Markdown File buttons will open a new tab in JupyterLab. You can also use the File dropdown menu for these.\nTo get an overview of JupyterLab, go here: Intro to JupyterLab",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#rstudio",
    "href": "topics-skills/01-intro-to-jupyterhub.html#rstudio",
    "title": "Intro to JupyterHubs",
    "section": "RStudio",
    "text": "RStudio\nIf you click the RStudio button in Launcher, RStudio will open in a new browser tab.\n\n\n\nRStudio\n\n\nTo get an overview of RStudio, go here: Intro to RStudio",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#end-your-session",
    "href": "topics-skills/01-intro-to-jupyterhub.html#end-your-session",
    "title": "Intro to JupyterHubs",
    "section": "End your session",
    "text": "End your session\nWhen you are finished working for the day you should log out of the JupyterHub, although it will log you out automatically after 90 minutes. You will not lose work; your home directory is persistent. When you keep a session active it uses up AWS resources (costs money) because it keeps a series of virtual machines deployed.\n\n\n\n\n\n\nCaution\n\n\n\nYou log out from the JupyterLab tab not the RStudio tab.\n\n\nFrom the JupyterLab browser tab, do one of two things to stop the server:\n\nLog out File -&gt; Log Out and click “Log Out”!\nor File -&gt; Hub Control Panel -&gt; Stop My Server\n\n\n\n\n\n\n\nTip\n\n\n\nCan’t find the JupyterLab tab? Go to https://nmfs-openscapes.2i2c.cloud/hub/home\n\n\nLogging out or stopping your server will NOT cause any of your work to be lost or deleted. It simply shuts down some resources. It would be equivalent to turning off your desktop computer at the end of the day.",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#restart-your-server",
    "href": "topics-skills/01-intro-to-jupyterhub.html#restart-your-server",
    "title": "Intro to JupyterHubs",
    "section": "Restart your server",
    "text": "Restart your server\nSometimes the server will crash/stop. This can happen if too many people use a lot of memory all at once. If that happens, go to the JupyterLab tab and then File -&gt; Hub Control Panel -&gt; Stop My Server and then Start My Server. You shouldn’t lose your work unless you were uploading a file.",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#your-files",
    "href": "topics-skills/01-intro-to-jupyterhub.html#your-files",
    "title": "Intro to JupyterHubs",
    "section": "Your files",
    "text": "Your files\nWhen you start your server, you will have access to your own virtual drive space. No other users will be able to see or access your files. You can upload files to your virtual drive space and save files here. You can create folders to organize your files. You personal directory is home/jovyan. Everyone has the same home directory but your files are separate and cannot be seen by others.",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#shared-files",
    "href": "topics-skills/01-intro-to-jupyterhub.html#shared-files",
    "title": "Intro to JupyterHubs",
    "section": "Shared files",
    "text": "Shared files\n\n\n\nShared folder\n\n\nIn the file panel, you will see a folder called shared. These are read-only shared files that we have prepared for you.\nYou will also see shared-public. This is a read-write folder for you to put files for everyone to see and use. You can create a team folder here for shared data and files. Note, everyone can see and change these so be careful to communicate with your team so multiple people don’t work on the same file at the same time. You can also create folders for each team member and agree not to change other team members files.",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#getting-help",
    "href": "topics-skills/01-intro-to-jupyterhub.html#getting-help",
    "title": "Intro to JupyterHubs",
    "section": "Getting help",
    "text": "Getting help\n\nDiscussions https://github.com/nmfs-opensci/NOAAHackDays/discussions\nAdd an issue if you see something amiss or you would like a package added https://github.com/nmfs-opensci/NOAAHackDays/issues\nVisit the NMFS Open Science Google Space (NOAA only). Search Google Spaces to find.\nNMFS staff: The NMFS Python User Group and NMFS R User Group are great places to get help from fellow users for Python and R questions.",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-skills/01-intro-to-jupyterhub.html#faq",
    "href": "topics-skills/01-intro-to-jupyterhub.html#faq",
    "title": "Intro to JupyterHubs",
    "section": "FAQ",
    "text": "FAQ\nWhy do we have the same home directory as /home/jovyan? /home/jovyan is the default home directory for ‘Jupyter’ based images/dockers. It is the historic home directory for Jupyter deployments.\nCan other users see the files in my /home/jovyan folder? No, other users can not see your files.\n\nAcknowledgements\nSome sections of this document have been taken from hackweeks organized by the University of Washington eScience Institute, CryoCloud and Openscapes.",
    "crumbs": [
      "JupyterHub",
      "Intro to JupyterHubs"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-19-dask/index.html",
    "href": "topics-2024/2024-04-19-dask/index.html",
    "title": "Parallel Computing in Python",
    "section": "",
    "text": "Image: Py - Openscapes",
    "crumbs": [
      "JupyterHub",
      "Python - Parallel Computing"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-19-dask/index.html#how-to-clone",
    "href": "topics-2024/2024-04-19-dask/index.html#how-to-clone",
    "title": "Parallel Computing in Python",
    "section": "How to clone",
    "text": "How to clone\nNever cloned the NOAAHackDays repo?\ncd ~\ngit clone https://github.com/nmfs-opensci/NOAAHackDays\nHave cloned it but need to update? This is going to destroy any changes that you made to the repo to make it match the current state of the repo on GitHub.\ncd ~/NOAAHackDays\ngit fetch origin\ngit reset --hard origin/main",
    "crumbs": [
      "JupyterHub",
      "Python - Parallel Computing"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/index.html",
    "href": "topics-2024/2024-04-26-echopype/index.html",
    "title": "echopype with Wu-Jung Lee",
    "section": "",
    "text": "Image: Py - echopype\nEnvironment file: environment.yml",
    "crumbs": [
      "JupyterHub",
      "Python - echopype 2"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-26-echopype/index.html#how-to-clone",
    "href": "topics-2024/2024-04-26-echopype/index.html#how-to-clone",
    "title": "echopype with Wu-Jung Lee",
    "section": "How to clone",
    "text": "How to clone\nNever cloned the NOAAHackDays repo?\ncd ~\ngit clone https://github.com/nmfs-opensci/NOAAHackDays\nHave cloned it but need to update? This is going to destroy any changes that you made to the repo to make it match the current state of the repo on GitHub.\ncd ~/NOAAHackDays\ngit fetch origin\ngit reset --hard origin/master",
    "crumbs": [
      "JupyterHub",
      "Python - echopype 2"
    ]
  },
  {
    "objectID": "topics-2024/2024-04-25-vast/index_standardization.html",
    "href": "topics-2024/2024-04-25-vast/index_standardization.html",
    "title": "Index Standardization",
    "section": "",
    "text": "# Load package\nlibrary(VAST)\n\nLoading required package: TMB\n\n\nLoading required package: FishStatsUtils\n\n\nLoading required package: units\n\n\nudunits database from /Users/eli.holmes/Library/R/arm64/4.3/library/units/share/udunits/udunits2.xml\n\n\nLoading required package: marginaleffects\n\n\n###########################################################################################\n\n\nLoading package VAST version 3.11.0\n\n\nFor information and examples, please see http://github.com/james-thorson/VAST/\n\n\n###########################################################################################\n\n# load data set\n# see `?load_example` for list of stocks with example data \n# that are installed automatically with `FishStatsUtils`. \nexample = load_example( data_set=\"EBS_pollock\" )\n\n# Make settings (turning off bias.correct to save time for example)\nsettings = make_settings( n_x = 100, \n  Region = example$Region, \n  purpose = \"index2\", \n  bias.correct = FALSE )\n\nRun model\n\nfit = fit_model( settings = settings, \n  Lat_i = example$sampling_data[,'Lat'], \n  Lon_i = example$sampling_data[,'Lon'], \n  t_i = example$sampling_data[,'Year'], \n  b_i = example$sampling_data[,'Catch_KG'], \n  a_i = example$sampling_data[,'AreaSwept_km2'] )\n\n\n### Writing output from `fit_model` in directory: /var/folders/w4/4s0hrwdd2gd8k4kp6s1z8zn40000gn/T//RtmpjUze7r\n\n\n\n### Making extrapolation-grid\n\n\nUsing strata All_areas\n\n\nFor the UTM conversion, automatically detected zone 2.\n\n\n# Reducing extrapolation-grid from 38284 to 2000 cells for Region(s): eastern_bering_sea\n\n\nUsing 100 iterations to find optimal extrapolation grid placement because no saved file found...\n\n\nIter=1: Current=1577934\n\n\nIter=10: Current=1567765 Proposed=1578585\n\n\nIter=20: Current=1567765 Proposed=1567305\n\n\nIter=30: Current=1567305 Proposed=1579689\n\n\nIter=40: Current=1566894 Proposed=1591286\n\n\nIter=50: Current=1566894 Proposed=1574820\n\n\nIter=60: Current=1566894 Proposed=1583135\n\n\nIter=70: Current=1566894 Proposed=1585003\n\n\nIter=80: Current=1566894 Proposed=1578045\n\n\nIter=90: Current=1566894 Proposed=1569064\n\n\nIter=100: Final=1566894 after 35 iterations\n\n\nResults saved to /var/folders/w4/4s0hrwdd2gd8k4kp6s1z8zn40000gn/T//RtmpjUze7r/Kmeans_extrapolation-2000.RData\n for subsequent runs by default (delete it to override)\n\n\n\n### Making spatial information\n\n\nUsing 100 iterations to find optimal spatial knot placement because no saved file found...\n\n\nIter=1: Current=1706304\n\n\nIter=10: Current=1672553 Proposed=1703603\n\n\nIter=20: Current=1672553 Proposed=1735194\n\n\nIter=30: Current=1672553 Proposed=1733218\n\n\nIter=40: Current=1672553 Proposed=1700374\n\n\nIter=50: Current=1672553 Proposed=1694957\n\n\nIter=60: Current=1662637 Proposed=1768348\n\n\nIter=70: Current=1662637 Proposed=1701889\n\n\nIter=80: Current=1662637 Proposed=1727702\n\n\nIter=90: Current=1662637 Proposed=1692254\n\n\nIter=100: Final=1657788 after 91 iterations\n\n\nResults saved to /var/folders/w4/4s0hrwdd2gd8k4kp6s1z8zn40000gn/T//RtmpjUze7r/Kmeans_knots-100.RData\n for subsequent runs by default (delete it to override)\n\n\nLoading required package: INLA\n\n\nLoading required package: Matrix\n\n\nLoading required package: sp\n\n\nThis is INLA_24.02.09 built 2024-02-09 03:43:24 UTC.\n - See www.r-inla.org/contact-us for how to get help.\n - List available models/likelihoods/etc with inla.list.models()\n - Use inla.doc(&lt;NAME&gt;) to access documentation\n\n\n'as(&lt;matrix&gt;, \"dgTMatrix\")' is deprecated.\nUse 'as(as(as(., \"dMatrix\"), \"generalMatrix\"), \"TsparseMatrix\")' instead.\nSee help(\"Deprecated\") and help(\"Matrix-deprecated\").\n\n\n\n### Making data object\n\n\nCoercing `b_i` to have units `kg`; I recommend using explicit units, e.g., `as_units(b_i,'kg')`, `as_units(b_i,'count') or `as_units(b_i,unitless)`\n\n\nCoercing `a_i` to have units `km^2`; I recommend using explicit units, e.g., `as_units(a_i,'km^2')` or `as_units(a_i,unitless)`\n\n\nFieldConfig_input is:\n\n\n             Component_1 Component_2\nOmega                 -2          -2\nEpsilon               -2          -2\nBeta                  -2          -2\nEpsilon_time          -3          -3\n\n\nOverdispersionConfig_input is:\n\n\nEta1 Eta2 \n  -1   -1 \n\n\nCalculating range shift for stratum #1:\n\n\n\n### Making TMB object\n\n\nNote: Using Makevars in /Users/eli.holmes/.R/Makevars \n\n\nusing C++ compiler: 'Apple clang version 15.0.0 (clang-1500.3.9.4)'\n\n\nusing SDK: 'MacOSX14.4.sdk'\n\n\nList of estimated fixed and random effects:\n\n\n    Coefficient_name Number_of_coefficients   Type\n1           beta1_ft                     33  Fixed\n2           beta2_ft                     33  Fixed\n3       L_epsilon1_z                      1  Fixed\n4       L_epsilon2_z                      1  Fixed\n5         L_omega1_z                      1  Fixed\n6         L_omega2_z                      1  Fixed\n7         ln_H_input                      2  Fixed\n8          logkappa1                      1  Fixed\n9          logkappa2                      1  Fixed\n10         logSigmaM                      1  Fixed\n11 Epsiloninput1_sff                   5016 Random\n12 Epsiloninput2_sff                   5016 Random\n13    Omegainput1_sf                    152 Random\n14    Omegainput2_sf                    152 Random\n\n\n\n### Checking model at initial values\n\n\nAll fixed effects have a nonzero gradient\n\n\n\n### Estimating parameters\n\n\nNote that `getReportCovariance=FALSE` causes an error in `TMB::sdreport` when no ADREPORTed variables are present\n\n\n  0:     78100.015:  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  1.00000  1.00000 -2.91430  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  1.00000  1.00000 -2.91430  1.60944\n  1:     61799.395: 0.000375832 -0.000431684 0.000601171 0.00124146 0.00103594 0.00164626 0.00155997 0.000875006 0.00155580 0.00114853 0.00107249 0.00180461 0.00125852 0.00172735 0.00182709 0.00142026 0.00139356 0.00128142 0.00147507 0.00167383 0.00163763 0.00176278 0.00148412 0.00169934 0.00166286 0.00137403 0.00101402 0.000794046 -0.000672750 -0.000133342 -0.000384397 0.00112662 0.00113623 0.00146627 0.00222076  1.23387 0.990289 -3.14012 0.000103255 0.000969399 0.000515467 0.000633440 0.000446415 0.000610480 0.000594773 0.000650219 0.000499346 0.000446418 0.000404639 0.000645238 0.000563239 0.000380388 0.000224515 0.000228096 0.000398671 0.000107047 0.000615790 0.000496497 0.000578962 0.00104009 0.000412516 0.000368444 2.37835e-05 0.000123173 1.02782e-05 -0.000209809 8.51543e-05 0.000109846 0.000219984 0.000280513 0.000962600  1.02970 0.996014 -2.94142 0.664709\n  2:     58908.800: 0.000408048 -0.00133493 0.000443303 0.00209590 0.00136238 0.00261729 0.00226185 0.00128253 0.00236097 0.00174899 0.00136080 0.00264082 0.00170124 0.00268141 0.00270524 0.00181334 0.00184477 0.00162293 0.00205064 0.00211027 0.00252012 0.00266994 0.00221893 0.00283417 0.00244992 0.00194062 0.000998612 0.000542623 -0.00183933 -0.00127277 -0.00127687 0.00122689 0.00130979 0.00184433 0.00369283  1.30215 0.985350 -3.22402 -7.30105e-05 0.00224560 0.000818578 0.00126047 0.000752557 0.00150320 0.00124588 0.00139458 0.000896841 0.000736050 0.000684721 0.00137575 0.00101289 0.000433890 0.000295846 0.000206071 0.000601190 -0.000296422 0.00129198 0.000996873 0.00111857 0.00219674 0.000800656 0.000672120 -0.000497115 -0.000449703 -0.000564881 -0.00151949 -0.000318689 -0.000164354 0.000100600 0.000151556 0.00204637  1.04485 0.996478 -2.95941 0.305067\n  3:     58261.131: 0.000373383 -0.00553900 -0.000265225 0.00433719 0.00195648 0.00507735 0.00381598 0.00235852 0.00425817 0.00327653 0.00193131 0.00452983 0.00256631 0.00494938 0.00459200 0.00227199 0.00269213 0.00214073 0.00319982 0.00259586 0.00464066 0.00485071 0.00385696 0.00570520 0.00422047 0.00321038 0.000425077 -0.000702186 -0.00513917 -0.00493882 -0.00382358 0.00114464 0.00127092 0.00229713 0.00736223  1.42657 0.991236 -3.40301 -0.000600407 0.00585142 0.00132070 0.00294083 0.00151655 0.00447016 0.00317611 0.00363641 0.00216900 0.00147313 0.00143263 0.00351725 0.00210560 0.000124022 0.000376372 -1.21856e-05 0.000724505 -0.00190915 0.00314421 0.00253648 0.00246399 0.00538964 0.00186378 0.00152630 -0.00254981 -0.00279315 -0.00292843 -0.00668332 -0.00191645 -0.00102742 -0.000625539 -0.000585918 0.00499012  1.07413  1.02408 -3.01863 0.00720550\n  4:     57681.721: -6.00608e-05 -0.0266498 -0.00275591 0.0112028 0.00341680 0.0130989 0.00866746 0.00550617 0.0100362 0.00792610 0.00349344 0.0105386 0.00506829 0.0119240 0.0102262 0.00315519 0.00505253 0.00335608 0.00651699 0.00368328 0.0112159 0.0117965 0.00854289 0.0145340 0.00948890 0.00696539 -0.00201327 -0.00529598 -0.0164879 -0.0174208 -0.0126770 0.000684807 0.000549576 0.00330009 0.0188809  1.75683  1.04759 -3.93691 -0.00194246 0.0178167 0.00259365 0.00833146 0.00397480 0.0155599 0.00978349 0.0115463 0.00727657 0.00393861 0.00432750 0.0108530 0.00555132 -0.00149048 0.000164475 -0.000945244 1.30892e-05 -0.00784193 0.00902928 0.00787779 0.00641847 0.0160004 0.00512441 0.00413903 -0.0104762 -0.0113526 -0.0118218 -0.0257950 -0.00781340 -0.00355204 -0.00373106 -0.00327386 0.0142234  1.16049  1.18514 -3.25873 0.281467\n  5:     57442.556: -0.00858394 -0.138773 -0.00873898 0.0184802 0.00252655 0.0252268 0.0147540 0.00663562 0.0163174 0.0119800 0.00240148 0.0188645 0.00618976 0.0199338 0.0162545 0.00131150 0.00630488 0.00273235 0.00942265 0.00358326 0.0190479 0.0213119 0.0120357 0.0244286 0.0152284 0.0100428 -0.00852528 -0.0152191 -0.0378224 -0.0394270 -0.0300419 -0.00206983 -0.00382446 0.00241507 0.0344939  1.76430 0.891029 -4.35831 -0.00188027 0.0426340 0.00430218 0.0159456 0.00621664 0.0452196 0.0223369 0.0295730 0.0229094 0.00571533 0.0113351 0.0242704 0.00850069 -0.00714303 -0.00280990 -0.00462725 -0.00768066 -0.0252168 0.0171974 0.0168221 0.0113069 0.0351041 0.00777389 0.00742861 -0.0313810 -0.0303147 -0.0285057 -0.0687919 -0.0167552 -0.00613948 -0.0122044 -0.0112719 0.0259373  1.23040  1.39918 -3.67439 -0.0636194\n  6:     56973.108: -0.0274646 -0.320843 -0.0142855 0.0216259 0.000480329 0.0353295 0.0207578 0.00350385 0.0209103 0.0123019 -0.00102042 0.0272301 0.00624223 0.0259705 0.0223702 0.00101118 0.00783647 0.00302680 0.0129970 0.00730506 0.0253158 0.0293338 0.0140412 0.0300557 0.0207286 0.0118178 -0.0121691 -0.0221255 -0.0570884 -0.0559169 -0.0462753 -0.00477255 -0.00663801 0.00333719 0.0474406  1.72029 0.324557 -4.58010 -0.00152760 0.0658498 0.00804500 0.0225245 0.00671697 0.0727096 0.0317380 0.0465644 0.0379739 0.00521294 0.0184962 0.0343075 0.00875330 -0.0120206 -0.00639255 -0.00935338 -0.0147060 -0.0426977 0.0229032 0.0227767 0.0147085 0.0520760 0.00703087 0.00973177 -0.0495278 -0.0448401 -0.0388602 -0.0998676 -0.0205109 -0.00687364 -0.0195462 -0.0189190 0.0331770  1.26431  1.13468 -3.87644 0.143095\n  7:     56904.668: -0.0388898 -0.598963 -0.0344529 0.0151156 -0.0129797 0.0552984 0.0402270 -0.0152832 0.0328038 0.00260718 -0.0136582 0.0557849 0.00573622 0.0439564 0.0462318 0.00381065 0.0180116 0.00946970 0.0258860 0.0319218 0.0431160 0.0519071 0.0152932 0.0369110 0.0404669 0.0182554 -0.0203020 -0.0413134 -0.130710 -0.113755 -0.108778 -0.0117316 -0.0139278 0.0103621 0.0846698  1.48907 0.656629 -4.55878 -0.00783399 0.0964307 0.0138391 0.0405420 0.00937054 0.0984218 0.0435115 0.0668321 0.0507292 0.00795622 0.0271775 0.0467713 0.0108520 -0.0205845 -0.0125695 -0.0143390 -0.0194705 -0.0633054 0.0332563 0.0335273 0.0200499 0.0777700 0.00790131 0.0124970 -0.0732366 -0.0665477 -0.0622487 -0.140957 -0.0286935 -0.0120894 -0.0333059 -0.0298240 0.0493875  1.21088  1.20572 -4.41299 0.139238\n  8:     56898.938: -0.0367106 -0.598416 -0.0345483 0.0151049 -0.0130167 0.0554704 0.0403640 -0.0153894 0.0328991 0.00255784 -0.0137219 0.0559942 0.00573114 0.0440806 0.0463979 0.00383620 0.0180746 0.00953188 0.0259923 0.0321035 0.0432571 0.0520726 0.0153337 0.0369511 0.0406155 0.0183031 -0.0203150 -0.0414072 -0.131079 -0.114044 -0.109082 -0.0117752 -0.0139424 0.0104192 0.0849074  1.49164 0.652512 -4.56288 -0.00786082 0.0966080 0.0138715 0.0406296 0.00937596 0.0985800 0.0435782 0.0669521 0.0508105 0.00795838 0.0272407 0.0468336 0.0108552 -0.0206232 -0.0125991 -0.0143601 -0.0194990 -0.0634353 0.0333084 0.0335795 0.0200727 0.0779139 0.00790037 0.0125143 -0.0733709 -0.0666530 -0.0623513 -0.141160 -0.0287148 -0.0121066 -0.0333825 -0.0298872 0.0494656  1.21071  1.20462 -4.41238 0.118934\n  9:     56892.384: -0.0104825 -0.587854 -0.0356245 0.0149778 -0.0134402 0.0574010 0.0419034 -0.0165886 0.0339661 0.00200071 -0.0144394 0.0583449 0.00567233 0.0454705 0.0482574 0.00412098 0.0187826 0.0102287 0.0271849 0.0341432 0.0448422 0.0539247 0.0157808 0.0373969 0.0422780 0.0188381 -0.0204634 -0.0424626 -0.135234 -0.117282 -0.112505 -0.0122657 -0.0141104 0.0110491 0.0875758  1.52008 0.610506 -4.60650 -0.00816132 0.0986023 0.0142337 0.0416206 0.00944159 0.100362 0.0443308 0.0683035 0.0517292 0.00798899 0.0279571 0.0475391 0.0108945 -0.0210622 -0.0129355 -0.0146042 -0.0198196 -0.0648939 0.0338995 0.0341737 0.0203214 0.0795356 0.00788823 0.0127076 -0.0748905 -0.0678444 -0.0635181 -0.143448 -0.0289705 -0.0122977 -0.0342487 -0.0305953 0.0503475  1.20905  1.20277 -4.39891 0.139325\n 10:     56879.728: 0.0884081 -0.593874 -0.0452762 0.0107127 -0.0195706 0.0689898 0.0526945 -0.0277922 0.0405734 -0.00433523 -0.0213877 0.0752007 0.00459474 0.0549017 0.0618609 0.00591170 0.0242162 0.0148602 0.0352820 0.0498941 0.0551917 0.0664673 0.0169012 0.0389625 0.0538670 0.0221115 -0.0228783 -0.0512233 -0.170828 -0.144431 -0.142389 -0.0162679 -0.0166513 0.0154468 0.106849  1.50522 0.585147 -4.64966 -0.0110707 0.112182 0.0170354 0.0498049 0.0100504 0.111386 0.0491270 0.0772314 0.0573071 0.00849558 0.0325491 0.0520692 0.0109977 -0.0247140 -0.0158543 -0.0164060 -0.0219167 -0.0747470 0.0379189 0.0384900 0.0220043 0.0907799 0.00763150 0.0136745 -0.0854350 -0.0765550 -0.0729130 -0.159384 -0.0309729 -0.0141295 -0.0408416 -0.0356907 0.0566183  1.17122  1.25232 -4.39888 0.113510\n 11:     56872.208: 0.0579300 -0.664921 -0.0572921 0.00497184 -0.0282668 0.0829214 0.0662029 -0.0421026 0.0491418 -0.0123963 -0.0302084 0.0972390 0.00307318 0.0671845 0.0798107 0.00801230 0.0312104 0.0208070 0.0459919 0.0708108 0.0685449 0.0824235 0.0182145 0.0409130 0.0690794 0.0265256 -0.0261736 -0.0621904 -0.215752 -0.178822 -0.180215 -0.0214729 -0.0197563 0.0211866 0.131879  1.50049 0.551808 -4.71270 -0.0146710 0.129569 0.0210215 0.0608602 0.0112491 0.125567 0.0555060 0.0886234 0.0643736 0.00937920 0.0385338 0.0580959 0.0112091 -0.0292362 -0.0193961 -0.0185172 -0.0244598 -0.0870184 0.0431571 0.0443250 0.0243869 0.105444 0.00757351 0.0150374 -0.0984829 -0.0875341 -0.0848545 -0.179723 -0.0337006 -0.0163738 -0.0490111 -0.0418577 0.0649619  1.14577  1.22354 -4.39321 0.125070\n 12:     56863.243: 0.0301881 -0.615417 -0.0845529 -0.00794925 -0.0484710 0.112846 0.0959804 -0.0731671 0.0689994 -0.0297533 -0.0496602 0.147525 -0.000712072 0.0955448 0.121325 0.0119984 0.0468379 0.0335417 0.0706316 0.117644 0.0995459 0.117974 0.0212041 0.0466797 0.104225 0.0367332 -0.0357153 -0.0875423 -0.314595 -0.256480 -0.263422 -0.0334159 -0.0269833 0.0330523 0.189985  1.54402 0.499627 -4.77106 -0.0230329 0.177409 0.0323135 0.0898772 0.0150354 0.165399 0.0737750 0.120044 0.0844412 0.0116600 0.0549901 0.0753490 0.0123045 -0.0402582 -0.0277296 -0.0233096 -0.0312081 -0.119722 0.0576793 0.0604931 0.0320885 0.144806 0.00829890 0.0196187 -0.132231 -0.116745 -0.115880 -0.235427 -0.0410478 -0.0222271 -0.0696701 -0.0576645 0.0874203  1.18246  1.33472 -4.30098 0.107711\n 13:     56857.079: 0.197270 -0.401223 -0.139639 -0.0347360 -0.0903618 0.170763 0.155597 -0.134291 0.109294 -0.0641796 -0.0884152 0.249174 -0.00872594 0.153194 0.206069 0.0198455 0.0788251 0.0580360 0.120431 0.211931 0.162562 0.188664 0.0263194 0.0586025 0.175676 0.0572258 -0.0577094 -0.139749 -0.511583 -0.413536 -0.429204 -0.0570453 -0.0417439 0.0559977 0.308649  1.64666 0.455748 -4.80113 -0.0402679 0.282082 0.0571881 0.152725 0.0242480 0.252298 0.114396 0.189029 0.128575 0.0170155 0.0912236 0.113983 0.0155948 -0.0634209 -0.0449763 -0.0332666 -0.0451250 -0.190170 0.0904362 0.0964781 0.0500686 0.230601 0.0107030 0.0306516 -0.203999 -0.180298 -0.183571 -0.357368 -0.0586333 -0.0350145 -0.113590 -0.0912157 0.136748  1.29626  1.22080 -4.37586 0.138693\n 14:     56851.717: 0.194386 -0.404516 -0.139702 -0.0347717 -0.0904251 0.170845 0.155683 -0.134382 0.109348 -0.0642285 -0.0884711 0.249331 -0.00874099 0.153271 0.206195 0.0198606 0.0788723 0.0580722 0.120508 0.212092 0.162648 0.188768 0.0263289 0.0586092 0.175779 0.0572587 -0.0577161 -0.139802 -0.511805 -0.413702 -0.429399 -0.0570761 -0.0417597 0.0560444 0.308819  1.64751 0.453151 -4.80253 -0.0402897 0.282258 0.0572344 0.152823 0.0242536 0.252457 0.114457 0.189147 0.128655 0.0170061 0.0912810 0.114041 0.0155871 -0.0634590 -0.0450092 -0.0332873 -0.0451575 -0.190305 0.0904789 0.0965247 0.0501012 0.230751 0.0106990 0.0306659 -0.204116 -0.180393 -0.183661 -0.357555 -0.0586433 -0.0350295 -0.113652 -0.0912721 0.136815  1.29589  1.22011 -4.37492 0.114169\n 15:     56849.633: 0.187419 -0.419592 -0.140359 -0.0352788 -0.0911934 0.171297 0.156443 -0.135146 0.109836 -0.0646824 -0.0889904 0.250845 -0.00895510 0.154004 0.207486 0.0199739 0.0793752 0.0582729 0.121244 0.213638 0.163481 0.189612 0.0262804 0.0586702 0.176795 0.0575526 -0.0580651 -0.140405 -0.513562 -0.415242 -0.430982 -0.0573238 -0.0419746 0.0563562 0.310599  1.65379 0.444663 -4.79637 -0.0405831 0.285085 0.0579680 0.154347 0.0244492 0.254889 0.115521 0.191032 0.129910 0.0169455 0.0922166 0.115057 0.0155962 -0.0639810 -0.0454285 -0.0335342 -0.0455568 -0.192298 0.0912934 0.0973724 0.0507300 0.233065 0.0107456 0.0309982 -0.205799 -0.181926 -0.185198 -0.360619 -0.0589980 -0.0353242 -0.114578 -0.0920828 0.137942  1.29638  1.22680 -4.37233 0.122685\n 16:     56846.822: 0.176590 -0.449256 -0.142545 -0.0370920 -0.0936288 0.172821 0.158984 -0.137739 0.111359 -0.0662448 -0.0906786 0.255736 -0.00956138 0.156367 0.211602 0.0204078 0.0810059 0.0590141 0.123569 0.218704 0.166096 0.192390 0.0261256 0.0587534 0.180040 0.0584814 -0.0590830 -0.142361 -0.519716 -0.420453 -0.436535 -0.0580942 -0.0426385 0.0574174 0.316199  1.66797 0.432179 -4.78216 -0.0414634 0.293228 0.0600646 0.158811 0.0250352 0.261810 0.118619 0.196427 0.133480 0.0168619 0.0949181 0.117996 0.0156716 -0.0655305 -0.0466389 -0.0342224 -0.0466598 -0.197971 0.0936954 0.0998689 0.0524892 0.239705 0.0109146 0.0319559 -0.210699 -0.186390 -0.189740 -0.369506 -0.0600632 -0.0362118 -0.117321 -0.0944279 0.141258  1.29797  1.23533 -4.36652 0.112206\n 17:     56843.075: 0.165845 -0.476909 -0.150401 -0.0440575 -0.101667 0.178756 0.168277 -0.147380 0.116359 -0.0720959 -0.0965852 0.272688 -0.0111800 0.164525 0.225499 0.0222681 0.0866485 0.0621604 0.131379 0.236595 0.174764 0.202396 0.0257398 0.0585434 0.191078 0.0616306 -0.0618025 -0.149059 -0.543438 -0.439520 -0.457984 -0.0606542 -0.0447386 0.0614364 0.334810  1.68964 0.443101 -4.77513 -0.0441253 0.316260 0.0659413 0.171799 0.0267324 0.281063 0.127498 0.211516 0.143390 0.0169982 0.102593 0.126313 0.0160283 -0.0701900 -0.0501501 -0.0361306 -0.0496314 -0.213792 0.100673 0.107128 0.0571267 0.258387 0.0114693 0.0345948 -0.224937 -0.199219 -0.203065 -0.394860 -0.0631618 -0.0388627 -0.125496 -0.101155 0.150902  1.29933  1.21767 -4.33906 0.122937\n 18:     56839.088: 0.150841 -0.485653 -0.167368 -0.0593671 -0.117562 0.192223 0.188058 -0.168319 0.126263 -0.0846242 -0.109380 0.308721 -0.0145545 0.181270 0.254464 0.0259881 0.0983099 0.0693048 0.148353 0.274585 0.193062 0.223419 0.0252428 0.0579600 0.214612 0.0680389 -0.0667737 -0.162700 -0.592046 -0.478265 -0.502291 -0.0664292 -0.0489351 0.0695939 0.374155  1.70319 0.395936 -4.75485 -0.0496355 0.369923 0.0803956 0.201499 0.0300030 0.325897 0.147639 0.246576 0.166583 0.0160420 0.120685 0.144828 0.0157527 -0.0808966 -0.0586136 -0.0406963 -0.0570224 -0.251357 0.115953 0.123202 0.0676263 0.301313 0.0117392 0.0403778 -0.257674 -0.228010 -0.232384 -0.451325 -0.0688222 -0.0444536 -0.144216 -0.116713 0.171547  1.27330  1.20824 -4.36796 0.116863\n 19:     56836.148: 0.183591 -0.600778 -0.186476 -0.0972125 -0.140624 0.197315 0.215616 -0.198663 0.129755 -0.105457 -0.125363 0.360853 -0.0192327 0.196598 0.292491 0.0361505 0.116575 0.0781804 0.168901 0.342220 0.208124 0.245648 0.0195564 0.0427549 0.243075 0.0745278 -0.0637149 -0.170116 -0.619797 -0.496851 -0.538425 -0.0674837 -0.0510007 0.0833181 0.421600  1.61604 0.468402 -4.82819 -0.0545074 0.472173 0.110744 0.254903 0.0340580 0.411066 0.185246 0.312770 0.211867 0.00935614 0.155109 0.177735 0.0127499 -0.0994779 -0.0740492 -0.0477624 -0.0703469 -0.324571 0.143640 0.150447 0.0889263 0.380946 0.0110158 0.0519650 -0.313794 -0.276143 -0.279620 -0.547972 -0.0729804 -0.0528848 -0.174534 -0.143603 0.203276  1.14903  1.20852 -4.20620 0.105848\n 20:     56834.095: 0.182472 -0.601376 -0.186505 -0.0972149 -0.140640 0.197369 0.215658 -0.198701 0.129788 -0.105471 -0.125388 0.360931 -0.0192387 0.196638 0.292554 0.0361531 0.116597 0.0782027 0.168951 0.342289 0.208179 0.245702 0.0195721 0.0427755 0.243134 0.0745485 -0.0637183 -0.170141 -0.619905 -0.496936 -0.538511 -0.0675016 -0.0510044 0.0833370 0.421691  1.61698 0.465870 -4.82881 -0.0545131 0.472342 0.110795 0.254986 0.0340653 0.411220 0.185307 0.312884 0.211948 0.00934196 0.155171 0.177791 0.0127402 -0.0995028 -0.0740729 -0.0477783 -0.0703782 -0.324694 0.143677 0.150491 0.0889592 0.381077 0.0110080 0.0519826 -0.313891 -0.276219 -0.279686 -0.548124 -0.0729841 -0.0528881 -0.174583 -0.143647 0.203325  1.14928  1.20922 -4.20661 0.118491\n 21:     56832.924: 0.173715 -0.607660 -0.186741 -0.0972368 -0.140767 0.197805 0.216005 -0.199013 0.130055 -0.105582 -0.125591 0.361562 -0.0192884 0.196968 0.293065 0.0361745 0.116772 0.0783832 0.169351 0.342853 0.208617 0.246143 0.0197005 0.0429407 0.243617 0.0747149 -0.0637468 -0.170352 -0.620781 -0.497629 -0.539216 -0.0676473 -0.0510343 0.0834950 0.422429  1.62448 0.444812 -4.83421 -0.0545615 0.473710 0.111206 0.255655 0.0341224 0.412463 0.185800 0.313808 0.212607 0.00922490 0.155666 0.178243 0.0126625 -0.0997025 -0.0742631 -0.0479002 -0.0706295 -0.325696 0.143980 0.150846 0.0892329 0.382140 0.0109492 0.0521271 -0.314670 -0.276833 -0.280215 -0.549353 -0.0730053 -0.0529179 -0.174979 -0.144007 0.203728  1.15120  1.20975 -4.21245 0.109933\n 22:     56830.990: 0.174918 -0.619042 -0.188414 -0.103601 -0.143217 0.197240 0.219517 -0.203136 0.129602 -0.108535 -0.127411 0.368469 -0.0198676 0.197996 0.297759 0.0379509 0.119351 0.0798768 0.172177 0.353188 0.209768 0.248304 0.0188140 0.0397599 0.247183 0.0754956 -0.0618105 -0.169687 -0.620755 -0.496449 -0.541151 -0.0670331 -0.0504948 0.0857344 0.427517  1.61775 0.433686 -4.83312 -0.0545261 0.492659 0.117555 0.265295 0.0347754 0.428180 0.192651 0.326104 0.221232 0.00728668 0.162390 0.184003 0.0116271 -0.102427 -0.0767739 -0.0487596 -0.0730121 -0.339276 0.148689 0.155540 0.0934299 0.396426 0.0104613 0.0544435 -0.323810 -0.284269 -0.287118 -0.564557 -0.0723993 -0.0535970 -0.179734 -0.148369 0.208380  1.15832  1.22558 -4.21003 0.118370\n 23:     56828.999: 0.169114 -0.624772 -0.193334 -0.114887 -0.148968 0.199168 0.228254 -0.212585 0.131235 -0.114769 -0.131995 0.385107 -0.0211036 0.202686 0.309986 0.0411737 0.125223 0.0838115 0.179764 0.375192 0.215222 0.255534 0.0178540 0.0356524 0.257060 0.0781319 -0.0595210 -0.171008 -0.631397 -0.502996 -0.552714 -0.0670276 -0.0500250 0.0908827 0.441713  1.63391 0.420711 -4.83683 -0.0552304 0.530714 0.129979 0.285547 0.0366256 0.459357 0.206815 0.350803 0.238224 0.00439620 0.175918 0.196144 0.0102768 -0.108136 -0.0816883 -0.0503868 -0.0773627 -0.366123 0.158865 0.165720 0.101847 0.425573 0.0100759 0.0592672 -0.342855 -0.300078 -0.302478 -0.596689 -0.0722648 -0.0553506 -0.189954 -0.157358 0.219212  1.19000  1.22267 -4.20396 0.111260\n 24:     56826.618: 0.160520 -0.601963 -0.202243 -0.134074 -0.159038 0.204161 0.245542 -0.229787 0.136129 -0.125772 -0.140238 0.418065 -0.0230076 0.213154 0.334884 0.0472844 0.137132 0.0922193 0.196032 0.418072 0.227793 0.270719 0.0173035 0.0302730 0.277838 0.0843358 -0.0556994 -0.174395 -0.658168 -0.521195 -0.578486 -0.0671099 -0.0485907 0.101535 0.470304  1.69174 0.434751 -4.84248 -0.0565073 0.607466 0.155028 0.326979 0.0407811 0.521394 0.235925 0.400460 0.272081 -0.00138998 0.203149 0.221298 0.00806126 -0.119201 -0.0910247 -0.0532190 -0.0855147 -0.420427 0.180058 0.186749 0.119351 0.484474 0.00978906 0.0694036 -0.380663 -0.331743 -0.333689 -0.661132 -0.0726652 -0.0589315 -0.210032 -0.175051 0.241709  1.19619  1.18969 -4.18881 0.120300\n 25:     56823.726: 0.172620 -0.619956 -0.205726 -0.153605 -0.165858 0.202345 0.258302 -0.242586 0.136366 -0.134485 -0.145555 0.444149 -0.0246491 0.217960 0.353697 0.0538657 0.147665 0.0988756 0.209588 0.457681 0.234654 0.279051 0.0159938 0.0217115 0.293381 0.0888901 -0.0483845 -0.171440 -0.662177 -0.521108 -0.585997 -0.0643558 -0.0447913 0.111092 0.489289  1.69799 0.409598 -4.84450 -0.0552339 0.686362 0.181973 0.367954 0.0441922 0.585072 0.265509 0.451194 0.307372 -0.00998755 0.231066 0.246427 0.00459665 -0.129031 -0.100018 -0.0554196 -0.0939817 -0.477518 0.200869 0.206957 0.138467 0.544058 0.00875674 0.0801201 -0.416196 -0.360905 -0.360991 -0.721363 -0.0702832 -0.0613294 -0.227563 -0.191688 0.261561  1.11021  1.22476 -4.19028 0.115849\n 26:     56823.353: 0.169166 -0.622483 -0.205786 -0.153572 -0.165883 0.202503 0.258420 -0.242670 0.136469 -0.134497 -0.145613 0.444360 -0.0246569 0.218078 0.353871 0.0538768 0.147729 0.0989449 0.209735 0.457879 0.234813 0.279200 0.0160552 0.0217912 0.293551 0.0889581 -0.0483859 -0.171504 -0.662496 -0.521364 -0.586235 -0.0644012 -0.0447875 0.111155 0.489533  1.70052 0.402603 -4.84688 -0.0552257 0.686862 0.182139 0.368209 0.0442309 0.585520 0.265705 0.451533 0.307618 -0.0100219 0.231256 0.246607 0.00458482 -0.129079 -0.100063 -0.0554424 -0.0940498 -0.477871 0.200997 0.207101 0.138588 0.544452 0.00875397 0.0801931 -0.416439 -0.361092 -0.361146 -0.721756 -0.0702738 -0.0613170 -0.227674 -0.191791 0.261717  1.11203  1.22348 -4.19299 0.121216\n 27:     56822.879: 0.168429 -0.624571 -0.205635 -0.153753 -0.165834 0.202508 0.258733 -0.242830 0.136539 -0.134517 -0.145653 0.444995 -0.0246303 0.218193 0.354334 0.0541147 0.148062 0.0992180 0.210208 0.459058 0.235047 0.279368 0.0161955 0.0217017 0.293994 0.0891665 -0.0480140 -0.171254 -0.662550 -0.521312 -0.586217 -0.0642703 -0.0445089 0.111513 0.489880  1.69890 0.399402 -4.84925 -0.0549148 0.689525 0.183199 0.369637 0.0444563 0.587659 0.266813 0.453259 0.308889 -0.0103246 0.232290 0.247547 0.00455159 -0.129143 -0.100147 -0.0553156 -0.0941734 -0.479754 0.201780 0.207851 0.139409 0.546484 0.00882852 0.0807166 -0.417243 -0.361659 -0.361574 -0.723115 -0.0699067 -0.0611315 -0.227921 -0.192092 0.262358  1.11756  1.22346 -4.19357 0.115915\n 28:     56822.364: 0.166626 -0.628772 -0.205275 -0.154143 -0.165729 0.202509 0.259450 -0.243170 0.136720 -0.134552 -0.145725 0.446460 -0.0245636 0.218468 0.355405 0.0546524 0.148821 0.0998367 0.211281 0.461756 0.235600 0.279758 0.0165044 0.0215146 0.295016 0.0896526 -0.0471891 -0.170697 -0.662699 -0.521230 -0.586190 -0.0639664 -0.0438827 0.112330 0.490679  1.69575 0.392420 -4.85440 -0.0542234 0.695660 0.185633 0.372948 0.0449805 0.592578 0.269368 0.457235 0.311810 -0.0110048 0.234673 0.249717 0.00448915 -0.129306 -0.100345 -0.0550195 -0.0944434 -0.484087 0.203598 0.209590 0.141298 0.551176 0.00901267 0.0819217 -0.419121 -0.362990 -0.362606 -0.726301 -0.0690792 -0.0607224 -0.228514 -0.192800 0.263865  1.12976  1.22428 -4.19449 0.120478\n 29:     56821.592: 0.165685 -0.633900 -0.204040 -0.154785 -0.165226 0.202219 0.260938 -0.243528 0.137109 -0.134396 -0.145564 0.449587 -0.0242672 0.218961 0.357669 0.0559610 0.150567 0.101254 0.213647 0.467924 0.236742 0.280432 0.0172516 0.0211448 0.297219 0.0908235 -0.0451549 -0.169149 -0.662456 -0.520590 -0.585562 -0.0630355 -0.0422795 0.114271 0.492041  1.68768 0.386148 -4.86253 -0.0524543 0.710099 0.191472 0.380882 0.0463296 0.604051 0.275499 0.466597 0.318694 -0.0125722 0.240357 0.254932 0.00446474 -0.129511 -0.100636 -0.0541158 -0.0948754 -0.494247 0.208012 0.213783 0.145897 0.562248 0.00958397 0.0848932 -0.423255 -0.365874 -0.364833 -0.733431 -0.0669840 -0.0596385 -0.229682 -0.194280 0.267483  1.15348  1.22628 -4.19328 0.115576\n 30:     56817.401: 0.115001 -0.622778 -0.177252 -0.145771 -0.148443 0.197252 0.274931 -0.231824 0.146279 -0.121857 -0.132000 0.479627 -0.0144715 0.224970 0.380104 0.0730540 0.171423 0.119276 0.240631 0.535245 0.251441 0.286293 0.0312989 0.0266290 0.321602 0.108894 -0.0187972 -0.145557 -0.652959 -0.509040 -0.568430 -0.0457098 -0.0185970 0.139658 0.497683  1.73407 0.372572 -4.92547 -0.0254097 0.887290 0.266645 0.483967 0.0692508 0.743403 0.356055 0.582620 0.404908 -0.0282743 0.313852 0.325272 0.0103059 -0.123858 -0.0963614 -0.0355400 -0.0932216 -0.616087 0.267629 0.270944 0.208476 0.700112 0.0225965 0.127108 -0.463963 -0.392337 -0.384106 -0.808473 -0.0372945 -0.0402474 -0.235163 -0.204767 0.317880  1.27695  1.21084 -4.18154 0.120880\n 31:     56816.411: 0.187979 -0.686792 -0.175254 -0.146185 -0.147928 0.204659 0.288403 -0.233596 0.156019 -0.120609 -0.130383 0.501520 -0.00998669 0.236188 0.398461 0.0821032 0.183964 0.128720 0.255211 0.566918 0.264882 0.298493 0.0369231 0.0306938 0.338112 0.118315 -0.0125509 -0.143117 -0.667658 -0.518820 -0.580217 -0.0402911 -0.0120795 0.151388 0.515549  1.78747 0.365705 -4.91899 -0.0159995 0.940413 0.290250 0.520710 0.0836915 0.786084 0.384751 0.619302 0.433144 -0.0235176 0.339267 0.353085 0.0206749 -0.116934 -0.0891453 -0.0249236 -0.0868369 -0.645335 0.291739 0.295702 0.231596 0.744702 0.0336573 0.144615 -0.471661 -0.397796 -0.388522 -0.829526 -0.0287983 -0.0310015 -0.232872 -0.202878 0.344502  1.29301  1.20005 -4.17742 0.118879\n 32:     56814.006: 0.136920 -0.661323 -0.176895 -0.152554 -0.148749 0.217176 0.307682 -0.238131 0.167712 -0.120539 -0.128669 0.529915 -0.00210299 0.252120 0.421990 0.0942023 0.199690 0.141351 0.273518 0.603439 0.281242 0.316886 0.0437993 0.0358600 0.359079 0.130265 -0.00484173 -0.140628 -0.679438 -0.524587 -0.595014 -0.0328355 -0.00607530 0.164404 0.541478  1.82924 0.322240 -4.93061 -0.00321214 0.978723 0.312542 0.556153 0.105969 0.818100 0.413127 0.648631 0.457884 -0.00624946 0.364180 0.383082 0.0408226 -0.101576 -0.0730289 -0.00723205 -0.0720434 -0.653092 0.317952 0.325021 0.255623 0.780051 0.0528188 0.165351 -0.465966 -0.392315 -0.382834 -0.833348 -0.0172005 -0.0164668 -0.221704 -0.190737 0.378791  1.24343  1.24251 -4.19368 0.122753\n 33:     56813.601: 0.136825 -0.661551 -0.176901 -0.152554 -0.148750 0.217193 0.307700 -0.238135 0.167723 -0.120539 -0.128669 0.529942 -0.00209854 0.252135 0.422009 0.0942072 0.199699 0.141358 0.273527 0.603463 0.281257 0.316906 0.0438044 0.0358684 0.359096 0.130273 -0.00484108 -0.140633 -0.679456 -0.524602 -0.595031 -0.0328356 -0.00607585 0.164411 0.541508  1.82946 0.321866 -4.93095 -0.00320869 0.978781 0.312563 0.556186 0.105978 0.818153 0.413153 0.648673 0.457915 -0.00624526 0.364205 0.383107 0.0408285 -0.101579 -0.0730300 -0.00723007 -0.0720439 -0.653124 0.317973 0.325042 0.255640 0.780098 0.0528248 0.165363 -0.465991 -0.392335 -0.382852 -0.833393 -0.0171965 -0.0164634 -0.221714 -0.190745 0.378816  1.24332  1.24174 -4.19406 0.117290\n 34:     56813.403: 0.134921 -0.664620 -0.177038 -0.152559 -0.148783 0.217591 0.308112 -0.238240 0.167970 -0.120557 -0.128685 0.530578 -0.00199341 0.252485 0.422454 0.0943230 0.199897 0.141534 0.273736 0.604017 0.281611 0.317364 0.0439198 0.0360625 0.359482 0.130450 -0.00482566 -0.140746 -0.679876 -0.524938 -0.595440 -0.0328349 -0.00609001 0.164584 0.542204  1.83457 0.313998 -4.93878 -0.00312732 0.980134 0.313057 0.556961 0.106198 0.819383 0.413757 0.649654 0.458641 -0.00614314 0.364794 0.383680 0.0409678 -0.101647 -0.0730565 -0.00718959 -0.0720544 -0.653869 0.318452 0.325537 0.256014 0.781203 0.0529639 0.165649 -0.466579 -0.392787 -0.383277 -0.834463 -0.0171127 -0.0163810 -0.221952 -0.190935 0.379404  1.24099  1.23051 -4.19992 0.120575\n 35:     56813.149: 0.127844 -0.655530 -0.176044 -0.152312 -0.147553 0.219172 0.310806 -0.236906 0.169329 -0.119436 -0.126891 0.534205 8.05591e-05 0.254412 0.424598 0.0962077 0.201694 0.143117 0.274419 0.608225 0.283121 0.319737 0.0450480 0.0375024 0.361316 0.132075 -0.00320210 -0.139192 -0.675864 -0.521465 -0.593145 -0.0310739 -0.00516902 0.166181 0.545199  1.83604 0.313461 -4.94531 -0.000160989 0.990642 0.318634 0.564565 0.110071 0.828948 0.419971 0.657839 0.465371 -0.00352003 0.370849 0.389767 0.0442677 -0.0993274 -0.0706046 -0.00413742 -0.0695606 -0.657367 0.323822 0.331214 0.260953 0.790195 0.0562545 0.169870 -0.467235 -0.392639 -0.382780 -0.837574 -0.0136766 -0.0133086 -0.220601 -0.189492 0.385646  1.22653  1.22902 -4.20157 0.116934\n 36:     56812.295: 0.104983 -0.618614 -0.167210 -0.151844 -0.139665 0.228345 0.330827 -0.227395 0.179203 -0.111774 -0.113394 0.562127 0.0146390 0.268054 0.440750 0.110592 0.215461 0.154632 0.278265 0.641583 0.293641 0.336669 0.0523397 0.0463425 0.374516 0.144125 0.00996453 -0.126125 -0.644779 -0.494246 -0.574222 -0.0173879 0.00250293 0.179070 0.567205  1.84506 0.311732 -4.97860 0.0219143  1.07670 0.363016 0.624697 0.138536 0.907080 0.468473 0.724335 0.519219 0.0154729 0.418514 0.436314 0.0684626 -0.0839919 -0.0538154 0.0182435 -0.0507237 -0.687441 0.365846 0.374372 0.299026 0.863217 0.0809472 0.202177 -0.476437 -0.394715 -0.382932 -0.868354 0.0131161 0.00923850 -0.212984 -0.180935 0.432986  1.16867  1.22656 -4.20386 0.119177\n 37:     56810.980: 0.162813 -0.668145 -0.128870 -0.145859 -0.114754 0.249948 0.381306 -0.208276 0.210460 -0.0883086 -0.0827763 0.632761 0.0474173 0.303393 0.491845 0.155422 0.262453 0.195789 0.315882 0.742789 0.328748 0.377536 0.0817661 0.0629835 0.419741 0.183179 0.0624111 -0.0773067 -0.600867 -0.442538 -0.534117 0.0249932 0.0448019 0.228122 0.617433  1.85815 0.306299 -5.00605 0.0926231  1.29473 0.485678 0.780958 0.221532  1.10637 0.597820 0.897319 0.661539 0.0807220 0.545458 0.558577 0.146081 -0.0322278 0.00352037 0.0902282 0.0209051 -0.728387 0.483299 0.489400 0.405230  1.04987 0.161557 0.296098 -0.478323 -0.380499 -0.371006 -0.927094 0.0944328 0.0794682 -0.175852 -0.140770 0.557799  1.21693  1.24686 -4.18155 0.118388\n 38:     56810.361: 0.145463 -0.694595 -0.0631501 -0.0793574 -0.0544247 0.282725 0.412428 -0.161289 0.259598 -0.0369740 -0.0394372 0.660524 0.0868844 0.340434 0.536925 0.205505 0.316430 0.249909 0.392198 0.817368 0.378150 0.407731 0.143373 0.110198 0.472783 0.236841 0.124024 -0.0250717 -0.616850 -0.441126 -0.521386 0.0747069 0.112932 0.290125 0.625726  2.07719 0.337862 -4.94274 0.187451  1.42173 0.591251 0.898186 0.316354  1.21815 0.707142  1.00755 0.763638 0.161835 0.647533 0.665536 0.242499 0.0600514 0.0976671 0.188864 0.125358 -0.678242 0.591593 0.591586 0.511750  1.16860 0.262086 0.397368 -0.392567 -0.294241 -0.290398 -0.852084 0.183444 0.172596 -0.0815484 -0.0492929 0.660307  1.19544  1.24974 -4.17420 0.117531\n 39:     56809.148: 0.137518 -0.697007 -0.0292688 -0.0214893 -0.00843261 0.351794 0.466463 -0.128129 0.319829 0.0101848 -0.00791394 0.715255 0.131205 0.402260 0.607254 0.255590 0.377145 0.309198 0.481064 0.895351 0.450555 0.464184 0.203795 0.169318 0.547679 0.293424 0.163306 0.00250812 -0.640844 -0.457566 -0.528682 0.111378 0.162800 0.343610 0.687243  2.05752 0.315457 -4.97884 0.290805  1.52316 0.692185  1.00438 0.422054  1.30951 0.814091  1.10164 0.859582 0.261063 0.747404 0.774052 0.347792 0.168257 0.204577 0.294008 0.228904 -0.592252 0.698605 0.698900 0.619396  1.27010 0.368299 0.502841 -0.280281 -0.186564 -0.178798 -0.729943 0.276996 0.274832 0.0278960 0.0583142 0.768168  1.17564  1.25122 -4.18158 0.115223\n 40:     56808.193: 0.136130 -0.724174 0.00111353 -0.000494926 0.0178650 0.406890 0.527780 -0.0735818 0.363172 0.0500111 0.0533357 0.788627 0.184848 0.454856 0.653511 0.290743 0.405863 0.339061 0.479602 0.925068 0.491069 0.529359 0.223085 0.213821 0.582971 0.327760 0.190254 0.0472837 -0.485907 -0.327052 -0.416537 0.157276 0.176058 0.369662 0.775486  2.07601 0.303928 -5.00495 0.395128  1.61249 0.789801  1.09547 0.528694  1.40951 0.911223  1.19841 0.964245 0.372726 0.850455 0.874270 0.444746 0.274926 0.306139 0.392267 0.308786 -0.491007 0.790158 0.803054 0.716507  1.36341 0.460372 0.602827 -0.171583 -0.0768066 -0.0571106 -0.606447 0.386393 0.382338 0.129970 0.161300 0.874026  1.15974  1.25351 -4.19932 0.116415\n 41:     56807.184: 0.133993 -0.706536 0.0654446 0.0584789 0.0779689 0.449877 0.581442 0.00199158 0.414866 0.114585 0.124662 0.848360 0.247661 0.505748 0.691553 0.344062 0.449167 0.381785 0.489313 0.936901 0.531028 0.584457 0.271541 0.273391 0.614155 0.378734 0.245211 0.110486 -0.430839 -0.269912 -0.352339 0.221975 0.228925 0.415513 0.840109  2.06605 0.288165 -5.00451 0.498740  1.73713 0.899380  1.19919 0.635453  1.54357  1.02016  1.32413  1.08546 0.484044 0.964824 0.983602 0.544956 0.375976 0.407466 0.492296 0.398667 -0.385409 0.891686 0.911917 0.824179  1.48343 0.557321 0.709304 -0.0850151 0.0106095 0.0241858 -0.551101 0.487888 0.486473 0.223436 0.258147 0.981855  1.15110  1.24383 -4.19602 0.121037\n 42:     56806.457: 0.136474 -0.694632 0.126543 0.105922 0.144764 0.490320 0.611488 0.0115298 0.450072 0.145870 0.142048 0.847102 0.283000 0.535126 0.735591 0.411085 0.525745 0.462217 0.615599  1.01685 0.576258 0.600203 0.346899 0.298600 0.678089 0.434785 0.333129 0.178752 -0.324887 -0.167594 -0.283931 0.265722 0.314777 0.495690 0.812752  2.04928 0.278455 -5.02457 0.597013  1.85600  1.00619  1.30717 0.725673  1.65569  1.12156  1.43561  1.18720 0.562936  1.06576  1.08027 0.643916 0.467655 0.505240 0.594163 0.524483 -0.269298 0.997936  1.00216 0.926637  1.59210 0.663939 0.809095 0.000399138 0.0992851 0.111633 -0.474222 0.592544 0.580935 0.317279 0.352619  1.05764  1.13425  1.23777 -4.20214 0.120084\n 43:     56805.432: 0.139384 -0.673866 0.239724 0.225002 0.244966 0.607403 0.738164 0.197464 0.577641 0.294437 0.320292 0.954298 0.425958 0.666214 0.850375 0.516134 0.623803 0.552286 0.682972  1.14117 0.690886 0.735002 0.438667 0.444685 0.786616 0.549654 0.415143 0.285507 -0.230100 -0.0804762 -0.142987 0.403375 0.389428 0.590705 0.935160  2.03589 0.269032 -5.04365 0.796442  2.06505  1.20833  1.52985 0.923993  1.85857  1.32991  1.63927  1.38660 0.764170  1.26536  1.28424 0.854968 0.654387 0.694592 0.791036 0.740279 -0.0627340  1.21768  1.20508  1.11742  1.80181 0.878585  1.00686 0.186989 0.301668 0.313713 -0.257517 0.806122 0.780104 0.510194 0.540828  1.27244  1.10864  1.22713 -4.19544 0.114472\n 44:     56804.761: 0.136756 -0.667115 0.376921 0.357411 0.408092 0.721849 0.884490 0.227839 0.699439 0.383706 0.356180  1.17939 0.530951 0.794021 0.970402 0.663338 0.758347 0.693490 0.744223  1.19336 0.803667 0.882538 0.599570 0.546025 0.878967 0.678175 0.591464 0.428594 -0.119689 0.0576797 -0.119482 0.505684 0.583559 0.726710  1.16708  2.01914 0.269423 -5.06261 0.992737  2.23369  1.39828  1.71925  1.12497  2.00935  1.51820  1.80520  1.55143  1.00013  1.44397  1.47515  1.05417 0.857261 0.894568 0.992483 0.926598 0.0943718  1.41034  1.40243  1.31398  1.97316  1.07102  1.20030 0.409661 0.513129 0.521392 -0.0299857 0.987118 0.970050 0.725824 0.746087  1.50945  1.08241  1.22488 -4.18611 0.114852\n 45:     56803.962: 0.135072 -0.675896 0.485144 0.481473 0.510878 0.874047  1.00594 0.383083 0.833780 0.521418 0.512252  1.29737 0.657320 0.925206  1.12013 0.786095 0.905893 0.838602 0.970227  1.35822 0.956633 0.998009 0.725194 0.681370  1.04720 0.813179 0.693008 0.527299 -0.0201477 0.134224 0.0617594 0.631593 0.679659 0.869285  1.26468  1.97752 0.270591 -5.09057  1.17886  2.38970  1.57161  1.89254  1.31701  2.17584  1.69827  1.97403  1.73430  1.18471  1.62431  1.65995  1.24771  1.05877  1.09733  1.18816  1.12753 0.292888  1.59247  1.58641  1.50404  2.14171  1.26688  1.39152 0.620308 0.709361 0.718971 0.168969  1.16584  1.16047 0.921249 0.952057  1.68494  1.05379  1.23009 -4.17549 0.120951\n 46:     56803.671: 0.130305 -0.674313 0.522621 0.523857 0.554950 0.917788  1.04503 0.425554 0.879619 0.564370 0.552547  1.28611 0.710042 0.973154  1.16231 0.817547 0.924554 0.855461 0.980673  1.43783  1.00118  1.04688 0.750922 0.735922  1.09138 0.847048 0.722054 0.574919 0.0346928 0.211091 0.0327127 0.677121 0.713257 0.885348  1.27676  1.95955 0.267922 -5.08103  1.20857  2.41902  1.60063  1.91010  1.35111  2.21349  1.72733  2.00867  1.76983  1.19652  1.65964  1.69259  1.27392  1.09176  1.12745  1.21329  1.13650 0.354839  1.61400  1.62041  1.53517  2.17404  1.29075  1.42267 0.647650 0.734703 0.743229 0.184071  1.18515  1.19161 0.947760 0.979272  1.69830  1.05959  1.23246 -4.17357 0.119870\n 47:     56803.179: 0.116619 -0.664034 0.625363 0.616954 0.654210  1.00120  1.13140 0.516167 0.961645 0.652378 0.642730  1.36129 0.792653  1.05397  1.23958 0.911864  1.01165 0.950536  1.04387  1.50938  1.07998  1.13415 0.849273 0.815105  1.16417 0.934111 0.831366 0.674488 0.123725 0.278188 0.222122 0.767364 0.819256 0.979452  1.37236  1.91397 0.261843 -5.04836  1.25720  2.46974  1.64668  1.92987  1.39903  2.27707  1.76731  2.06557  1.82458  1.23906  1.70937  1.73443  1.30454  1.13973  1.17640  1.25586  1.15408 0.430435  1.63926  1.66351  1.58427  2.21858  1.31601  1.46948 0.684607 0.769031 0.775904 0.198689  1.23666  1.23615 0.986297  1.02321  1.72595  1.08124  1.23733 -4.17473 0.115480\n 48:     56803.019: 0.116025 -0.652010 0.710427 0.708792 0.723585  1.08655  1.20099 0.672527  1.04305 0.772071 0.792779  1.51019 0.889644  1.12535  1.31347 0.996178  1.12245  1.05376  1.21948  1.48814  1.15640  1.18655 0.931720 0.911691  1.25228  1.02921 0.891772 0.751555 0.250636 0.421652 0.238427 0.874125 0.869411  1.09238  1.45270  1.88289 0.263180 -5.01720  1.27988  2.49575  1.66707  1.96614  1.40038  2.29578  1.78800  2.08466  1.83966  1.28212  1.72249  1.74233  1.32478  1.14268  1.18774  1.27388  1.22427 0.414910  1.67343  1.66215  1.58802  2.23729  1.34653  1.48232 0.689207 0.796890 0.812054 0.263168  1.27265  1.25619 0.998655  1.03617  1.74278  1.10733  1.23765 -4.18058 0.114438\n 49:     56802.319: 0.123324 -0.644075 0.812327 0.816453 0.837328  1.18694  1.30616 0.766207  1.15262 0.874820 0.885511  1.58273  1.00823  1.23984  1.41402  1.09585  1.20540  1.13185  1.28456  1.59858  1.25669  1.30047  1.02600  1.03040  1.35444  1.12824 0.992442 0.865813 0.345571 0.514964 0.355905 0.979696 0.975915  1.17070  1.52098  1.85576 0.271011 -4.99104  1.29489  2.50791  1.68212  2.00736  1.39447  2.28521  1.80402  2.08271  1.83076  1.28283  1.72382  1.74665  1.34741  1.13540  1.17863  1.27718  1.27119 0.424715  1.71269  1.66242  1.57846  2.24580  1.37902  1.48193 0.695726 0.827948 0.845596 0.333737  1.30872  1.26702  1.01386  1.03222  1.75272  1.12581  1.23488 -4.19037 0.118095\n 50:     56801.765: 0.126687 -0.655884 0.913472 0.909917 0.913842  1.27877  1.41235 0.888777  1.23812 0.973407  1.00518  1.65505  1.07369  1.32619  1.50921  1.19729  1.32226  1.26061  1.36137  1.76107  1.34586  1.40417  1.14067  1.09762  1.43426  1.22684  1.09419 0.931160 0.451846 0.611042 0.443199  1.06596  1.06596  1.29542  1.65402  1.82403 0.291208 -4.96005  1.31233  2.51471  1.69279  2.01285  1.42004  2.30984  1.81674  2.10128  1.86006  1.29501  1.74063  1.76427  1.36618  1.16522  1.20812  1.30300  1.27272 0.473670  1.72225  1.68571  1.60531  2.25712  1.39124  1.50401 0.724406 0.838678 0.854609 0.320992  1.31135  1.28739  1.03376  1.06469  1.78322  1.12518  1.22441 -4.18760 0.119688\n 51:     56801.293: 0.128816 -0.668440 0.998096  1.00477  1.02096  1.39431  1.50540 0.957264  1.34736  1.06505  1.07867  1.77021  1.19375  1.43307  1.61923  1.28351  1.40288  1.33383  1.49456  1.84984  1.45899  1.49999  1.21461  1.21724  1.55363  1.32013  1.17699  1.05539 0.539187 0.714086 0.560317  1.17003  1.16000  1.37052  1.74528  1.79361 0.307276 -4.93021  1.33184  2.52787  1.71317  2.01782  1.45342  2.33807  1.83808  2.12774  1.89251  1.32593  1.77506  1.79397  1.38801  1.20209  1.24020  1.32427  1.27588 0.498248  1.73294  1.71629  1.63696  2.28518  1.41064  1.53402 0.756355 0.857168 0.862804 0.302640  1.31730  1.31468  1.05765  1.09435  1.79968  1.12095  1.21684 -4.18111 0.119092\n 52:     56800.197: 0.135011 -0.677338  1.35619  1.35812  1.37030  1.76458  1.85204  1.32247  1.70430  1.40429  1.43841  2.10427  1.51787  1.80526  1.99269  1.64160  1.72041  1.66923  1.79925  2.15416  1.83038  1.87271  1.58555  1.55212  1.94185  1.66005  1.56380  1.35812 0.894951  1.00710 0.903281  1.50018  1.54081  1.68458  2.01159  1.69881 0.329088 -4.86770  1.42811  2.61111  1.80288  2.07174  1.55131  2.42355  1.91866  2.21130  1.97807  1.38767  1.86083  1.88155  1.45583  1.29690  1.32981  1.41009  1.29979 0.563588  1.79900  1.81186  1.73742  2.36704  1.47942  1.62702 0.856901 0.940069 0.960443 0.411293  1.41122  1.39534  1.14680  1.17786  1.83187  1.11810  1.21510 -4.18721 0.117753\n 53:     56796.100: 0.143353 -0.665278  2.69504  2.74910  2.75895  3.19436  3.25311  2.63685  3.09252  2.78383  2.76224  3.41277  2.92093  3.19316  3.40193  3.00282  3.11436  3.06543  3.17917  3.68944  3.22557  3.28898  2.94868  2.95771  3.32398  3.03671  2.88528  2.80404  2.13070  2.39002  2.34715  2.88999  2.88741  3.09143  3.47866  1.37088 0.402181 -4.59808  1.77933  2.91762  2.13350  2.31034  1.90592  2.71823  2.22680  2.52253  2.27741  1.63920  2.19139  2.18778  1.72523  1.63093  1.68355  1.74440  1.52726 0.968694  2.07142  2.13819  2.06787  2.68043  1.73620  1.97080  1.19176  1.30322  1.32818 0.853737  1.77983  1.72155  1.46573  1.52124  2.11948  1.13122  1.21084 -4.21623 0.114559\n 54:     56791.015: 0.145099 -0.656120  4.02943  4.10891  4.17884  4.65257  4.64763  3.97849  4.49559  4.13326  4.11694  4.80538  4.35276  4.60126  4.77952  4.38414  4.43572  4.37696  4.62065  5.23075  4.60578  4.68636  4.30664  4.38569  4.70199  4.39534  4.31745  4.15580  3.61849  3.59609  3.74249  4.26297  4.30864  4.40918  4.96478  1.09213 0.461022 -4.33878  2.09579  3.14717  2.40783  2.56127  2.22085  3.01280  2.52436  2.80774  2.59681  1.98826  2.50011  2.49258  2.05658  1.97230  2.01437  2.04314  1.88562  1.42942  2.37427  2.42557  2.35679  2.95748  2.06518  2.28677  1.53616  1.62041  1.63872  1.07359  2.05249  2.05226  1.79924  1.85066  2.44986  1.15409  1.20619 -4.23641 0.116942\n 55:     56788.820: 0.145273 -0.655658  4.55182  4.64057  4.72671  5.21538  5.18908  4.50203  5.03803  4.66043  4.64431  5.34096  4.90039  5.14673  5.31381  4.91993  4.95277  4.89393  5.16342  5.80987  5.14134  5.23178  4.83879  4.93275  5.23756  4.92428  4.86757  4.68420  4.16386  4.09527  4.28832  4.79556  4.85499  4.92618  5.52276 0.989051 0.474171 -4.24448  2.21810  3.23560  2.51219  2.65761  2.34207  3.12718  2.63913  2.91847  2.72110  2.12353  2.61780  2.61084  2.18791  2.10456  2.14361  2.16061  2.02329  1.60085  2.49323  2.53728  2.46946  3.06333  2.19571  2.40929  1.66829  1.74250  1.75413  1.15569  2.15616  2.17982  1.92746  1.97967  2.57339  1.16202  1.20120 -4.24529 0.125368\n 56:     56786.257: 0.146473 -0.654275  5.07416  5.17247  5.27490  5.77795  5.73064  5.02540  5.58065  5.18753  5.17149  5.87588  5.44853  5.69228  5.84790  5.45564  5.46989  5.41054  5.70594  6.39037  5.67668  5.77726  5.37064  5.48035  5.77280  5.45338  5.41734  5.21270  4.71048  4.59284  4.83444  5.32824  5.40129  5.44321  6.08107 0.882508 0.495544 -4.14812  2.33994  3.32354  2.61609  2.75440  2.46250  3.24060  2.75370  3.02846  2.84459  2.25831  2.73492  2.72864  2.31933  2.23612  2.27212  2.27755  2.16197  1.77222  2.61258  2.64833  2.58124  3.16879  2.32645  2.53116  1.80003  1.86455  1.86955  1.23795  2.25960  2.30701  2.05546  2.10812  2.69728  1.17002  1.19899 -4.25409 0.119175\n 57:     56785.587: 0.144703 -0.657311  5.23810  5.33983  5.44572  5.95351  5.89998  5.18875  5.74971  5.35147  5.33580  6.04401  5.61706  5.86202  6.01460  5.62200  5.63303  5.57346  5.87246  6.56757  5.84348  5.94859  5.53723  5.64924  5.94030  5.61939  5.58630  5.37715  4.88175  4.75187  5.00290  5.49357  5.57015  5.60744  6.25292 0.857498 0.484441 -4.11839  2.37455  3.34905  2.64527  2.78269  2.49652  3.27322  2.78721  3.06020  2.88016  2.29755  2.76853  2.76299  2.35858  2.27373  2.30916  2.31127  2.20388  1.81951  2.64848  2.67992  2.61306  3.19970  2.36553  2.56621  1.83721  1.89920  1.90225  1.25972  2.28852  2.34341  2.09203  2.14482  2.73390  1.17437  1.18966 -4.26066 0.110554\n 58:     56784.514: 0.144744 -0.657308  5.40117  5.50623  5.61643  6.12855  6.06852  5.35170  5.91854  5.51535  5.49965  6.21078  5.78672  6.03162  6.18078  5.78835  5.79462  5.73480  6.04027  6.74680  6.01005  6.11869  5.70301  5.81909  6.10707  5.78445  5.75625  5.54155  5.05227  4.90785  5.17241  5.65896  5.73973  5.76926  6.42587 0.825562 0.489003 -4.08790  2.41075  3.37533  2.67597  2.81162  2.53220  3.30725  2.82166  3.09315  2.91722  2.33796  2.80364  2.79842  2.39841  2.31311  2.34758  2.34611  2.24612  1.87024  2.68468  2.71289  2.64629  3.23150  2.40513  2.60260  1.87638  1.93547  1.93658  1.28312  2.31896  2.38147  2.13026  2.18305  2.77134  1.17732  1.18852 -4.26364 0.120157\n 59:     56784.082: 0.143854 -0.659064  5.24641  5.35032  5.45114  5.95559  5.90180  5.19492  5.75294  5.35495  5.33797  6.04905  5.61524  5.86433  6.01536  5.62398  5.63827  5.57836  5.87040  6.56287  5.84572  5.95193  5.54348  5.65041  5.94322  5.62451  5.58526  5.37968  4.88460  4.76317  5.00492  5.49387  5.57442  5.61215  6.25348 0.861019 0.480824 -4.11586  2.36070  3.33612  2.63057  2.77160  2.48080  3.26329  2.77617  3.04880  2.87056  2.28759  2.75754  2.75209  2.35053  2.26290  2.29599  2.29718  2.19936  1.80511  2.63978  2.66512  2.59892  3.18868  2.35731  2.55270  1.82479  1.88582  1.88908  1.23720  2.27221  2.33318  2.08086  2.13113  2.72470  1.17594  1.18902 -4.26149 0.118527\n 60:     56782.201: 0.140419 -0.665510  5.42322  5.53228  5.62839  6.12924  6.07088  5.36863  5.92394  5.52485  5.50641  6.22292  5.77929  6.03416  6.17908  5.79306  5.80806  5.74895  6.03051  6.72418  6.01261  6.12459  5.71989  5.81892  6.11087  5.79651  5.75422  5.54850  5.05491  4.94435  5.17294  5.65983  5.74951  5.78202  6.42267 0.843592 0.465048 -4.08362  2.36783  3.33626  2.63102  2.77703  2.48358  3.27709  2.78703  3.05855  2.88757  2.30607  2.76975  2.76414  2.37180  2.27896  2.30624  2.30251  2.22973  1.82279  2.65657  2.66705  2.60285  3.19765  2.37779  2.56054  1.83741  1.89371  1.89532  1.21518  2.26906  2.34949  2.09475  2.14026  2.74133  1.18292  1.18184 -4.26957 0.118446\n 61:     56782.188: 0.140222 -0.665638  5.42349  5.53244  5.62831  6.12906  6.07087  5.36899  5.92383  5.52506  5.50673  6.22314  5.77904  6.03401  6.17900  5.79315  5.80836  5.74938  6.03027  6.72329  6.01251  6.12457  5.72016  5.81866  6.11077  5.79662  5.75420  5.54860  5.05470  4.94568  5.17247  5.65992  5.74941  5.78244  6.42239 0.845567 0.463792 -4.08435  2.36783  3.33637  2.63101  2.77705  2.48350  3.27714  2.78701  3.05859  2.88756  2.30608  2.76968  2.76409  2.37176  2.27887  2.30621  2.30255  2.22970  1.82228  2.65659  2.66700  2.60285  3.19766  2.37776  2.56051  1.83728  1.89366  1.89526  1.21530  2.26906  2.34943  2.09466  2.14024  2.74124  1.18328  1.18228 -4.26989 0.122403\n 62:     56782.066: 0.140164 -0.665726  5.42356  5.53248  5.62829  6.12900  6.07086  5.36909  5.92380  5.52512  5.50682  6.22320  5.77897  6.03397  6.17898  5.79317  5.80845  5.74950  6.03020  6.72305  6.01248  6.12456  5.72024  5.81858  6.11075  5.79666  5.75420  5.54863  5.05464  4.94604  5.17234  5.65994  5.74938  5.78256  6.42232 0.846100 0.463419 -4.08456  2.36783  3.33641  2.63101  2.77706  2.48348  3.27716  2.78700  3.05860  2.88756  2.30608  2.76966  2.76408  2.37174  2.27884  2.30620  2.30256  2.22969  1.82214  2.65659  2.66698  2.60285  3.19766  2.37775  2.56051  1.83724  1.89365  1.89525  1.21533  2.26906  2.34942  2.09464  2.14023  2.74122  1.18337  1.18225 -4.27005 0.119992\n 63:     56781.891: 0.139460 -0.666417  5.42454  5.53305  5.62798  6.12833  6.07082  5.37044  5.92339  5.52591  5.50800  6.22401  5.77803  6.03345  6.17867  5.79349  5.80958  5.75109  6.02932  6.71979  6.01211  6.12448  5.72124  5.81762  6.11041  5.79708  5.75413  5.54899  5.05386  4.95093  5.17060  5.66027  5.74901  5.78412  6.42129 0.853158 0.459023 -4.08731  2.36781  3.33684  2.63098  2.77713  2.48318  3.27734  2.78694  3.05877  2.88754  2.30609  2.76940  2.76389  2.37159  2.27850  2.30610  2.30269  2.22958  1.82024  2.65666  2.66678  2.60285  3.19766  2.37765  2.56041  1.83676  1.89348  1.89503  1.21578  2.26907  2.34921  2.09431  2.14014  2.74090  1.18462  1.18313 -4.27148 0.116568\n 64:     56781.603: 0.139135 -0.667072  5.42647  5.53261  5.62902  6.12816  6.07351  5.37259  5.92471  5.52919  5.51222  6.22581  5.78162  6.03483  6.18022  5.79718  5.81262  5.75514  6.03010  6.71770  6.01338  6.12637  5.72382  5.81946  6.11110  5.79932  5.75937  5.55339  5.05488  4.95518  5.17142  5.66506  5.75092  5.78801  6.42135 0.852809 0.458307 -4.08681  2.36415  3.33419  2.62779  2.77437  2.47959  3.27506  2.78391  3.05632  2.88498  2.30262  2.76690  2.76091  2.36843  2.27525  2.30229  2.29905  2.22649  1.81547  2.65362  2.66336  2.59943  3.19521  2.37418  2.55683  1.83324  1.88983  1.89132  1.21129  2.26559  2.34637  2.09071  2.13640  2.73751  1.18465  1.18327 -4.27146 0.120096\n 65:     56781.267: 0.138327 -0.668544  5.43321  5.53616  5.63319  6.12956  6.07966  5.37956  5.92896  5.53690  5.52116  6.23156  5.78807  6.03893  6.18458  5.80499  5.82058  5.76462  6.03274  6.71419  6.01747  6.13150  5.73102  5.82390  6.11443  5.80570  5.76839  5.56224  5.05856  4.96769  5.17406  5.67406  5.75621  5.79722  6.42296 0.855403 0.455576 -4.08711  2.35797  3.33031  2.62239  2.77004  2.47309  3.27144  2.77888  3.05228  2.88053  2.29682  2.76238  2.75583  2.36313  2.26936  2.29564  2.29276  2.22155  1.80625  2.64876  2.65734  2.59352  3.19118  2.36851  2.55066  1.82660  1.88337  1.88488  1.20363  2.25965  2.34128  2.08444  2.12978  2.73183  1.18539  1.18399 -4.27193 0.117273\n 66:     56776.269: 0.114754 -0.720934  5.93148  6.02996  6.04966  6.42807  6.49297  5.85042  6.31744  5.96785  5.93581  6.66106  6.12666  6.41644  6.56289  6.22669  6.31207  6.26605  6.33492  6.79788  6.40106  6.54046  6.20937  6.17969  6.49275  6.26137  6.12932  5.98019  5.44387  5.60167  5.53306  6.06046  6.17441  6.29416  6.69890 0.718603 0.450834 -3.94831  2.03365  3.14194  2.34325  2.55879  2.12700  3.06749  2.51965  2.81871  2.61762  1.99158  2.49969  2.49556  2.08880  1.94266  1.94001  1.94223  1.96046  1.39139  2.39873  2.34680  2.27928  2.97270  2.08756  2.22624  1.44495  1.52125  1.54412 0.784520  1.94612  2.04009  1.75498  1.76440  2.45498  1.18733  1.17970 -4.24684 0.118223\n 67:     56774.131: 0.110858 -0.713620  5.86482  5.90693  5.99790  6.48558  6.50496  5.81405  6.28468  5.97287  6.00517  6.69260  6.11635  6.40463  6.57524  6.25244  6.31143  6.30229  6.32626  6.73923  6.38973  6.55664  6.21026  6.11938  6.51382  6.22575  6.22600  6.01315  5.41084  5.65137  5.49414  6.12585  6.13583  6.32377  6.67190 0.778373 0.441494 -3.92651  1.89903  3.02132  2.21959  2.43027  2.00147  2.93566  2.38218  2.69873  2.48811  1.84946  2.36673  2.36251  1.94694  1.80554  1.81143  1.82643  1.77939  1.21428  2.25629  2.22678  2.16730  2.84282  1.94244  2.09567  1.31503  1.38556  1.40588 0.693244  1.83211  1.89745  1.60317  1.63311  2.29859  1.19888  1.17060 -4.25142 0.121795\n 68:     56771.846: 0.121763 -0.708702  5.89606  5.96589  5.99379  6.42737  6.44630  5.84143  6.24659  5.94054  5.92426  6.69016  6.06928  6.34483  6.52235  6.19553  6.28676  6.25630  6.31174  6.69822  6.33979  6.49263  6.16853  6.10578  6.45801  6.21500  6.10744  5.95647  5.40864  5.62505  5.43815  6.04164  6.12194  6.29927  6.65344 0.860392 0.438635 -3.94180  1.79758  2.92650  2.11154  2.26106  1.88137  2.80235  2.24615  2.57599  2.33890  1.70707  2.22581  2.22024  1.79229  1.66482  1.70747  1.72995  1.59025  1.03318  2.10817  2.10165  2.07065  2.71598  1.78411  1.98929  1.17127  1.26034  1.27902 0.643607  1.73525  1.73720  1.46461  1.51932  2.14232  1.20463  1.16808 -4.26164 0.121092\n 69:     56771.695: 0.148131 -0.703882  5.96498  6.05053  6.07384  6.33175  6.44067  5.86317  6.37476  6.02757  6.12707  6.70384  6.15775  6.42657  6.49769  6.27711  6.32957  6.25855  6.37864  6.80357  6.39751  6.45920  6.26153  6.20489  6.43453  6.28490  6.25038  6.04320  5.44373  5.66857  5.49110  6.18763  6.20931  6.30779  6.77247 0.886682 0.469189 -3.98548  1.70075  2.81340  1.99302  2.11939  1.74300  2.64897  2.14663  2.45234  2.21802  1.58149  2.08744  2.09359  1.67769  1.53337  1.60725  1.64674  1.56824 0.844516  2.03621  1.94767  1.95305  2.59467  1.68767  1.88259  1.06698  1.18409  1.17806 0.588888  1.64374  1.63358  1.36904  1.40778  2.05811  1.19450  1.19649 -4.27428 0.114878\n 70:     56770.461: 0.153816 -0.694858  5.97447  6.03126  6.08252  6.42115  6.51245  5.93527  6.37188  6.05851  6.07201  6.72470  6.20731  6.45851  6.55366  6.31026  6.36005  6.31932  6.37731  6.85398  6.41988  6.53942  6.26912  6.22400  6.47867  6.30228  6.26457  6.06390  5.48721  5.67226  5.52309  6.18058  6.21202  6.36932  6.77998 0.902723 0.484541 -3.98768  1.64265  2.75286  1.92859  2.11681  1.68004  2.57685  2.09205  2.38464  2.13215  1.53315  2.01459  2.02923  1.65128  1.45344  1.54191  1.60443  1.59946 0.749419  2.02213  1.88735  1.86885  2.53343  1.67428  1.81643 0.994332  1.14438  1.13185 0.556388  1.59978  1.57502  1.31822  1.34929  2.02366  1.19448  1.20540 -4.27070 0.118072\n 71:     56770.177: 0.152717 -0.696461  5.97420  6.03110  6.08231  6.42220  6.51284  5.93502  6.37162  6.05818  6.07171  6.72531  6.20696  6.45849  6.55422  6.31009  6.36011  6.31945  6.37752  6.85424  6.41996  6.53998  6.26897  6.22371  6.47927  6.30220  6.26412  6.06350  5.48694  5.67213  5.52319  6.18018  6.21177  6.36945  6.77995 0.903977 0.475017 -3.98979  1.64255  2.75283  1.92854  2.11703  1.68004  2.57684  2.09196  2.38457  2.13210  1.53324  2.01452  2.02918  1.65132  1.45334  1.54180  1.60431  1.59934 0.749398  2.02207  1.88743  1.86874  2.53338  1.67433  1.81635 0.994164  1.14424  1.13181 0.556359  1.59976  1.57492  1.31809  1.34921  2.02359  1.19269  1.19575 -4.26793 0.122337\n 72:     56769.966: 0.152605 -0.696497  5.97311  6.03121  6.08137  6.42360  6.51268  5.93190  6.36978  6.05562  6.07254  6.72598  6.20357  6.45694  6.55449  6.30814  6.35912  6.31763  6.37619  6.85468  6.41839  6.54035  6.26796  6.22151  6.47967  6.30110  6.26148  6.06083  5.48541  5.67187  5.52271  6.17841  6.21069  6.36803  6.77810 0.904328 0.474254 -3.99034  1.64049  2.75171  1.92689  2.11760  1.67780  2.57447  2.09028  2.38233  2.12995  1.53196  2.01195  2.02712  1.65020  1.45041  1.53909  1.60195  1.59910 0.747155  2.02118  1.88568  1.86618  2.53160  1.67363  1.81406 0.991322  1.14224  1.13018 0.555540  1.59851  1.57275  1.31609  1.34658  2.02240  1.19231  1.19502 -4.26738 0.118513\n 73:     56769.845: 0.152279 -0.696489  5.97109  6.03181  6.07962  6.42687  6.51239  5.92533  6.36592  6.05035  6.07470  6.72796  6.19641  6.45361  6.55532  6.30412  6.35724  6.31391  6.37375  6.85577  6.41519  6.54121  6.26599  6.21707  6.48084  6.29898  6.25599  6.05556  5.48220  5.67148  5.52186  6.17501  6.20870  6.36505  6.77436 0.905173 0.472197 -3.99177  1.63624  2.74928  1.92352  2.11859  1.67320  2.56974  2.08669  2.37773  2.12573  1.52946  2.00675  2.02284  1.64779  1.44458  1.53351  1.59689  1.59792 0.743028  2.01895  1.88214  1.86102  2.52787  1.67199  1.80935 0.985603  1.13799  1.12679 0.553666  1.59581  1.56833  1.31192  1.34118  2.01973  1.19132  1.19342 -4.26572 0.120415\n 74:     56769.692: 0.152188 -0.696405  5.96600  6.02978  6.07420  6.42824  6.50934  5.91464  6.35784  6.04112  6.07435  6.72918  6.18398  6.44612  6.55413  6.29627  6.35251  6.30654  6.36743  6.85508  6.40800  6.53977  6.26089  6.20819  6.48015  6.29364  6.24602  6.04665  5.47496  5.66821  5.51821  6.16799  6.20328  6.35851  6.76563 0.905936 0.471376 -3.99391  1.62735  2.74374  1.91649  2.11886  1.66354  2.56068  2.07918  2.36867  2.11685  1.52336  1.99683  2.01415  1.64186  1.43320  1.52207  1.58640  1.59346 0.734485  2.01352  1.87452  1.85078  2.52031  1.66733  1.79969 0.974449  1.12917  1.11967 0.549266  1.58987  1.55921  1.30303  1.33025  2.01359  1.19016  1.19316 -4.26446 0.118494\n 75:     56768.818: 0.153357 -0.708925  5.83325  5.86499  5.91300  6.27480  6.38217  5.83368  6.21945  5.93572  5.87890  6.63575  6.06486  6.31127  6.43580  6.17841  6.24095  6.20552  6.22251  6.73010  6.27667  6.41298  6.13162  6.06821  6.36189  6.16537  6.11950  5.94509  5.33004  5.52294  5.39213  6.03174  6.05380  6.24583  6.58979 0.908692 0.450557 -4.05148  1.47071  2.63111  1.79356  2.05927  1.49515  2.43207  1.94813  2.22918  1.95615  1.37812  1.85784  1.87329  1.50452  1.26113  1.33030  1.40888  1.44364 0.575931  1.89228  1.73555  1.69022  2.39724  1.53991  1.63707 0.804398 0.974521 0.992204 0.455455  1.47616  1.40081  1.13802  1.15196  1.88705  1.16273  1.19235 -4.25033 0.118789\n 76:     56768.647: 0.154942 -0.704302  5.74040  5.81006  5.85554  6.30743  6.37785  5.65812  6.11685  5.78402  5.86899  6.53784  5.96101  6.26184  6.42277  6.07854  6.17618  6.16174  6.18509  6.62186  6.22929  6.41266  6.03295  5.98906  6.33974  6.08863  5.96649  5.75624  5.24505  5.47571  5.34502  5.90539  5.98270  6.20668  6.53186 0.929886 0.446503 -4.08444  1.28664  2.48258  1.63967  1.95315  1.32192  2.25675  1.77442  2.04681  1.78979  1.17365  1.68589  1.70562  1.33392  1.06998  1.12448  1.20908  1.24164 0.369274  1.72351  1.58425  1.50635  2.23569  1.37009  1.45154 0.605530 0.777121 0.835303 0.323345  1.32277  1.21269 0.949912 0.958566  1.72215  1.14470  1.19298 -4.22989 0.121184\n 77:     56768.518: 0.155075 -0.692782  5.80144  5.88731  5.88271  6.44447  6.43187  5.74019  6.15023  5.85183  5.90035  6.64933  5.92084  6.27072  6.51585  6.10284  6.22374  6.15907  6.26525  6.70604  6.25880  6.48064  6.09764  5.98186  6.44650  6.13701  6.01243  5.89199  5.29380  5.51719  5.39003  5.97422  6.02192  6.22034  6.59656 0.932393 0.449953 -4.08856  1.23304  2.40757  1.56536  1.82542  1.27447  2.20484  1.69433  1.99153  1.73978  1.11085  1.61907  1.63004  1.24493  1.03153  1.08945  1.14637  1.11494 0.312843  1.60899  1.52590  1.46764  2.15383  1.27227  1.40209 0.564000 0.728129 0.770416 0.237555  1.24137  1.16207 0.888757 0.905567  1.61295  1.13725  1.19045 -4.22986 0.121130\n 78:     56768.101: 0.154192 -0.683652  5.85071  5.91438  5.94365  6.51604  6.47071  5.81243  6.21401  5.92059  5.92192  6.76168  6.03286  6.32421  6.57972  6.17479  6.27856  6.24095  6.32841  6.78712  6.32435  6.52678  6.14510  6.06765  6.51478  6.19060  6.08311  5.91538  5.34386  5.58461  5.44532  6.02305  6.07301  6.28939  6.65270 0.939364 0.450305 -4.08755  1.19077  2.33215  1.50348  1.66957  1.24021  2.16229  1.62878  1.94867  1.70100  1.05816  1.58694  1.57548  1.15414  1.01585  1.07708  1.11939 0.993110 0.269667  1.50769  1.47193  1.44162  2.09592  1.16846  1.36872 0.539984 0.676788 0.710596 0.154476  1.16794  1.12031 0.842876 0.882085  1.50375  1.13238  1.18454 -4.23073 0.118414\n 79:     56767.929: 0.152864 -0.685407  5.85445  5.92193  5.95021  6.50802  6.48840  5.82193  6.22314  5.92469  5.93617  6.73210  6.04179  6.35632  6.57639  6.18086  6.28510  6.26301  6.33830  6.76952  6.35103  6.53574  6.14523  6.07657  6.50181  6.19779  6.08407  5.96420  5.37478  5.56941  5.44298  6.03445  6.08240  6.31425  6.67215 0.942189 0.449065 -4.09104  1.17332  2.31379  1.48420  1.63740  1.22988  2.14351  1.61153  1.93074  1.68393  1.02711  1.56712  1.56405  1.13326 0.996895  1.06498  1.11076 0.983531 0.243380  1.49495  1.45536  1.42419  2.07809  1.14512  1.35339 0.520054 0.663722 0.688103 0.127937  1.14806  1.10257 0.827342 0.872585  1.48865  1.12818  1.18335 -4.23055 0.118172\n 80:     56767.670: 0.149872 -0.689065  5.86591  5.92696  5.95802  6.49155  6.49139  5.84095  6.23650  5.94549  5.93383  6.70378  6.05342  6.36096  6.56823  6.19437  6.28684  6.24707  6.34675  6.76941  6.34955  6.53222  6.16021  6.08613  6.49047  6.20570  6.11767  5.95806  5.38007  5.58716  5.44831  6.05275  6.09573  6.30252  6.69990 0.945470 0.449056 -4.09398  1.15146  2.29741  1.46448  1.63425  1.20896  2.11881  1.59826  1.90912  1.65547  1.00602  1.53879  1.54463  1.12543 0.964027  1.03991  1.09017  1.00811 0.223607  1.49364  1.43287  1.39674  2.06025  1.14270  1.33033 0.493242 0.640051 0.659944 0.106841  1.13199  1.07990 0.810138 0.847981  1.49472  1.12245  1.18444 -4.23062 0.119684\n 81:     56767.526: 0.147003 -0.690815  5.87974  5.94000  5.97201  6.46551  6.47546  5.83239  6.25602  5.94527  5.97309  6.74399  6.07864  6.36165  6.56386  6.21180  6.30327  6.27165  6.31839  6.80883  6.34605  6.52218  6.17633  6.10501  6.49525  6.21937  6.11908  5.98758  5.40094  5.58510  5.45086  6.05830  6.10189  6.31394  6.68231 0.947342 0.450168 -4.09570  1.13354  2.28386  1.44987  1.64783  1.18195  2.09687  1.59002  1.88860  1.63938  1.01906  1.51972  1.52825  1.12899 0.940040  1.01712  1.07618  1.02611 0.223277  1.49813  1.41225  1.37202  2.04700  1.15495  1.31018 0.469622 0.627095 0.644984 0.0914302  1.11903  1.06244 0.796272 0.829617  1.49382  1.11854  1.18711 -4.23216 0.120035\n 82:     56767.522: 0.144344 -0.688841  5.88314  5.95953  5.98475  6.43632  6.49706  5.85341  6.27078  5.96422  5.97919  6.77913  6.07137  6.41410  6.55436  6.21030  6.30548  6.27896  6.34148  6.84765  6.38660  6.53211  6.17485  6.11657  6.47353  6.22999  6.14430  5.98588  5.40889  5.60792  5.46798  6.09531  6.13539  6.33744  6.67942 0.949982 0.450734 -4.09651  1.11821  2.26682  1.43803  1.67065  1.16140  2.09239  1.57873  1.87811  1.63349  1.03089  1.51117  1.52672  1.13275 0.935147 0.992311  1.05165  1.01918 0.224312  1.50239  1.40120  1.35348  2.03270  1.15554  1.29227 0.468642 0.616889 0.647899 0.0804975  1.10354  1.06069 0.788605 0.815773  1.49387  1.11652  1.18808 -4.23215 0.118178\n 83:     56767.428: 0.143746 -0.689303  5.89966  5.96326  5.99482  6.43738  6.50419  5.85792  6.28170  5.97515  5.98929  6.76503  6.09489  6.40794  6.55696  6.22798  6.31732  6.28196  6.35434  6.84711  6.38317  6.53540  6.19482  6.12979  6.47815  6.24055  6.15783  5.99434  5.41600  5.61145  5.47461  6.09205  6.13443  6.33355  6.69743 0.951172 0.450221 -4.09912  1.11305  2.25593  1.43213  1.68372  1.14967  2.09117  1.57261  1.87414  1.63333  1.02340  1.51332  1.51844  1.13528 0.939225 0.983266  1.03885  1.00848 0.216033  1.49542  1.39516  1.34947  2.02633  1.15694  1.28491 0.470830 0.613314 0.649748 0.0718699  1.09384  1.05794 0.782146 0.806565  1.49821  1.11498  1.18807 -4.23111 0.118160\n 84:     56767.417: 0.143744 -0.689275  5.89966  5.96326  5.99483  6.43738  6.50418  5.85791  6.28171  5.97515  5.98929  6.76501  6.09492  6.40793  6.55696  6.22799  6.31732  6.28196  6.35435  6.84710  6.38316  6.53540  6.19482  6.12981  6.47815  6.24055  6.15785  5.99432  5.41600  5.61144  5.47461  6.09205  6.13444  6.33354  6.69745 0.951162 0.450180 -4.09915  1.11305  2.25593  1.43213  1.68371  1.14967  2.09117  1.57261  1.87414  1.63332  1.02340  1.51333  1.51844  1.13528 0.939225 0.983271  1.03886  1.00849 0.216030  1.49542  1.39516  1.34948  2.02634  1.15694  1.28491 0.470830 0.613311 0.649743 0.0718644  1.09384  1.05794 0.782148 0.806566  1.49821  1.11498  1.18810 -4.23103 0.119059\n 85:     56767.411: 0.143594 -0.688857  5.89965  5.96298  5.99507  6.43741  6.50391  5.85782  6.28203  5.97523  5.98926  6.76432  6.09588  6.40760  6.55699  6.22839  6.31733  6.28197  6.35446  6.84685  6.38289  6.53513  6.19495  6.13038  6.47834  6.24061  6.15830  5.99376  5.41607  5.61104  5.47465  6.09206  6.13456  6.33326  6.69813 0.950834 0.448455 -4.10014  1.11309  2.25592  1.43215  1.68343  1.14969  2.09113  1.57270  1.87417  1.63330  1.02312  1.51342  1.51837  1.13522 0.939228 0.983409  1.03901  1.00871 0.215931  1.49535  1.39508  1.34952  2.02645  1.15693  1.28499 0.470830 0.613234 0.649572 0.0716882  1.09385  1.05793 0.782210 0.806604  1.49838  1.11467  1.18781 -4.22897 0.118571\n 86:     56767.401: 0.143548 -0.688891  5.89917  5.96351  5.99570  6.43832  6.50229  5.85879  6.28328  5.97539  5.98937  6.76284  6.09676  6.40643  6.55814  6.22855  6.31784  6.28328  6.35360  6.84625  6.38193  6.53427  6.19441  6.13163  6.48079  6.24097  6.15881  5.99357  5.41682  5.61114  5.47507  6.09466  6.13665  6.33379  6.70018 0.950746 0.448374 -4.10052  1.11278  2.25594  1.43191  1.68224  1.14936  2.09057  1.57277  1.87384  1.63260  1.02217  1.51278  1.51780  1.13495 0.938345 0.983725  1.03967  1.00943 0.215412  1.49494  1.39447  1.34913  2.02645  1.15708  1.28498 0.470092 0.612789 0.648241 0.0709662  1.09378  1.05772 0.782401 0.806765  1.49863  1.11455  1.18785 -4.22888 0.119039\n 87:     56767.386: 0.142959 -0.687654  5.89931  5.96292  5.99725  6.43933  6.50011  5.85934  6.28526  5.97615  5.98979  6.75935  6.10125  6.40473  6.55933  6.23051  6.31825  6.28405  6.35343  6.84489  6.38044  6.53271  6.19470  6.13472  6.48341  6.24155  6.16118  5.99172  5.41781  5.61019  5.47583  6.09628  6.13854  6.33325  6.70444 0.949454 0.446661 -4.10496  1.11270  2.25607  1.43175  1.67899  1.14963  2.08952  1.57313  1.87355  1.63152  1.02028  1.51213  1.51713  1.13406 0.937069 0.984860  1.04125  1.01184 0.214891  1.49439  1.39365  1.34897  2.02683  1.15677  1.28538 0.469028 0.611974 0.645544 0.0693893  1.09389  1.05707 0.782799 0.807279  1.49920  1.11347  1.18953 -4.22422 0.118237\n 88:     56767.359: 0.142572 -0.687104  5.90810  5.96389  6.00210  6.44628  6.50000  5.86403  6.28903  5.98307  5.99692  6.75991  6.11161  6.41058  6.56744  6.23997  6.32024  6.28344  6.35418  6.84606  6.38498  6.53462  6.20064  6.14009  6.49147  6.24523  6.17004  5.99513  5.42240  5.61570  5.48104  6.09507  6.14085  6.33461  6.71498 0.948739 0.445998 -4.10732  1.11271  2.25802  1.43029  1.65450  1.15716  2.07966  1.57396  1.87024  1.62212  1.01629  1.50214  1.51613  1.12622 0.924804 0.992369  1.05191  1.03359 0.217884  1.49480  1.39159  1.34761  2.02639  1.15131  1.28786 0.459094 0.608075 0.625501 0.0617621  1.09575  1.04955 0.784123 0.811731  1.49646  1.11347  1.18935 -4.22509 0.118612\n 89:     56767.350: 0.142653 -0.687513  5.90522  5.97078  6.00708  6.45478  6.50330  5.86861  6.29724  5.98401  5.99809  6.75897  6.11841  6.40627  6.56869  6.24404  6.32666  6.29045  6.35555  6.84645  6.38350  6.53881  6.20685  6.14780  6.49304  6.25043  6.17284  5.99576  5.42830  5.61713  5.48482  6.11044  6.14646  6.33576  6.71950 0.948787 0.446131 -4.10797  1.11072  2.25778  1.42886  1.64856  1.15856  2.07754  1.57408  1.86844  1.61961  1.01346  1.49966  1.51310  1.12276 0.921833 0.993918  1.05432  1.03762 0.217076  1.49293  1.39061  1.34678  2.02586  1.14866  1.28780 0.456167 0.606120 0.621716 0.0583005  1.09442  1.04944 0.783835 0.811668  1.49458  1.11351  1.18882 -4.22643 0.119037\n 90:     56767.343: 0.142559 -0.687178  5.91116  5.97350  6.01244  6.45997  6.50397  5.87406  6.30388  5.99120  6.00386  6.76028  6.12418  6.41084  6.57437  6.24770  6.33007  6.29692  6.36130  6.85101  6.38770  6.54050  6.20653  6.15455  6.50201  6.25443  6.18015  6.00088  5.43275  5.62193  5.49005  6.11149  6.15589  6.34274  6.72950 0.948842 0.446245 -4.10844  1.11032  2.25601  1.42752  1.64862  1.15603  2.07956  1.57319  1.86892  1.62168  1.01139  1.50090  1.51223  1.12282 0.923591 0.992059  1.05235  1.03362 0.215029  1.49184  1.38887  1.34533  2.02522  1.14950  1.28648 0.457474 0.606093 0.626037 0.0581139  1.09227  1.04981 0.783122 0.810728  1.49493  1.11334  1.18847 -4.22675 0.119108\n 91:     56767.336: 0.142315 -0.686384  5.91774  5.97758  6.01819  6.46292  6.50938  5.87801  6.30800  5.99555  6.00773  6.76417  6.13249  6.41902  6.58051  6.25511  6.33527  6.30085  6.36909  6.85688  6.39495  6.54493  6.21490  6.16003  6.50742  6.25997  6.18590  6.00442  5.43884  5.62608  5.49574  6.11616  6.15739  6.34752  6.73731 0.949053 0.446104 -4.10929  1.11044  2.25488  1.42647  1.64692  1.15511  2.08107  1.57199  1.86916  1.62321  1.00999  1.50235  1.51230  1.12260 0.925728 0.991390  1.05071  1.03035 0.212959  1.49133  1.38797  1.34577  2.02462  1.14893  1.28597 0.458349 0.606097 0.629319 0.0580316  1.09083  1.05061 0.781623 0.809851  1.49410  1.11326  1.18841 -4.22603 0.118904\n 92:     56767.334: 0.142113 -0.685874  5.92158  5.98006  6.02321  6.46843  6.52104  5.88201  6.31373  6.00312  6.01512  6.76926  6.14044  6.42055  6.58081  6.26015  6.34056  6.30480  6.37880  6.86280  6.39842  6.55347  6.21801  6.16756  6.50342  6.26470  6.19271  6.00967  5.44230  5.63023  5.50039  6.11300  6.16483  6.34884  6.73966 0.948654 0.445670 -4.11120  1.11044  2.25345  1.42592  1.64594  1.15605  2.08086  1.57125  1.86947  1.62375  1.00935  1.50298  1.51092  1.12052 0.926724 0.992061  1.05033  1.02837 0.210963  1.48915  1.38848  1.34585  2.02424  1.14521  1.28603 0.459393 0.606347 0.627710 0.0563444  1.09009  1.04979 0.782241 0.809491  1.49144  1.11275  1.18871 -4.22500 0.118978\n 93:     56767.332: 0.141906 -0.685472  5.93245  5.98441  6.02891  6.47216  6.52464  5.88563  6.31936  6.00649  6.01876  6.77074  6.14712  6.42638  6.58420  6.26635  6.34270  6.30876  6.38449  6.86608  6.40422  6.55661  6.22232  6.17218  6.51022  6.26838  6.19759  6.01237  5.44721  5.63432  5.50515  6.12060  6.16505  6.35516  6.74655 0.948569 0.445389 -4.11289  1.11058  2.24949  1.42580  1.64922  1.15278  2.07774  1.56934  1.86777  1.62151  1.00865  1.50261  1.51000  1.12032 0.928181 0.992433  1.04927  1.02332 0.208956  1.48446  1.38748  1.34628  2.02142  1.14381  1.28573 0.461663 0.605706 0.618667 0.0496090  1.08856  1.04984 0.783279 0.811299  1.49077  1.11233  1.18881 -4.22494 0.119207\n 94:     56767.330: 0.141650 -0.685034  5.92868  5.98983  6.03221  6.47209  6.52633  5.89108  6.32237  6.01146  6.02278  6.77176  6.15322  6.43340  6.59341  6.27135  6.34999  6.31267  6.38833  6.86869  6.41110  6.55872  6.23237  6.17824  6.51901  6.27473  6.20093  6.01658  5.45248  5.63993  5.51072  6.12262  6.17108  6.35577  6.75490 0.949431 0.445426 -4.11353  1.10804  2.24662  1.42462  1.64896  1.15008  2.07580  1.56716  1.86645  1.61987  1.00761  1.50177  1.50943  1.12123 0.928391 0.993250  1.04830  1.01981 0.207497  1.48126  1.38614  1.34701  2.01944  1.14308  1.28553 0.462004 0.604366 0.612709 0.0438708  1.08637  1.04863 0.783804 0.811085  1.49066  1.11223  1.18865 -4.22487 0.118967\n 95:     56767.329: 0.141563 -0.685253  5.93343  5.99119  6.03517  6.47494  6.52762  5.89200  6.32474  6.01288  6.02420  6.77322  6.15515  6.43373  6.59701  6.27329  6.35194  6.31498  6.38988  6.87024  6.41190  6.56070  6.23258  6.18007  6.52042  6.27656  6.20412  6.01786  5.45424  5.64096  5.51226  6.12627  6.17209  6.35747  6.75742 0.949587 0.445587 -4.11366  1.10727  2.24795  1.42285  1.64317  1.15135  2.07736  1.56718  1.86655  1.62070  1.00616  1.50080  1.50870  1.11973 0.926336 0.992109  1.04824  1.02191 0.206854  1.48231  1.38544  1.34531  2.02016  1.14214  1.28449 0.458712 0.602255 0.617605 0.0444158  1.08445  1.04771 0.780675 0.809144  1.48984  1.11192  1.18857 -4.22486 0.118707\n 96:     56767.328: 0.141509 -0.685478  5.93407  5.99316  6.03643  6.47997  6.52774  5.89368  6.32691  6.01387  6.02541  6.77510  6.15783  6.43643  6.59571  6.27647  6.35185  6.31498  6.39103  6.87251  6.41277  6.56134  6.23719  6.18120  6.52316  6.27784  6.20571  6.01957  5.45580  5.64255  5.51391  6.12755  6.17420  6.36129  6.76034 0.949772 0.445824 -4.11351  1.10643  2.24987  1.42133  1.63834  1.15233  2.07946  1.56748  1.86701  1.62189  1.00443  1.50057  1.50873  1.11692 0.924967 0.990460  1.04764  1.02358 0.205854  1.48400  1.38443  1.34462  2.02119  1.14194  1.28353 0.455596 0.600899 0.622886 0.0461971  1.08342  1.04694 0.777976 0.807499  1.48927  1.11171  1.18850 -4.22465 0.118941\n 97:     56767.328: 0.141511 -0.685484  5.93501  5.99301  6.03709  6.47956  6.52833  5.89374  6.32670  6.01431  6.02569  6.77546  6.15787  6.43650  6.59688  6.27634  6.35330  6.31583  6.39133  6.87296  6.41309  6.56182  6.23654  6.18161  6.52359  6.27849  6.20622  6.01960  5.45636  5.64262  5.51407  6.12834  6.17431  6.36057  6.76077 0.949776 0.445881 -4.11361  1.10657  2.24985  1.42142  1.63798  1.15230  2.07938  1.56736  1.86701  1.62182  1.00399  1.50056  1.50857  1.11699 0.924852 0.990466  1.04759  1.02363 0.205369  1.48421  1.38429  1.34434  2.02120  1.14200  1.28348 0.455602 0.601031 0.622639 0.0463623  1.08367  1.04707 0.777958 0.807052  1.48915  1.11179  1.18840 -4.22479 0.118962\n 98:     56767.328: 0.141531 -0.685463  5.93555  5.99354  6.03709  6.47954  6.52873  5.89413  6.32774  6.01421  6.02604  6.77580  6.15806  6.43598  6.59814  6.27665  6.35274  6.31632  6.39178  6.87344  6.41305  6.56236  6.23635  6.18192  6.52327  6.27833  6.20668  6.01978  5.45679  5.64290  5.51422  6.12873  6.17445  6.36125  6.76101 0.949675 0.445898 -4.11379  1.10676  2.24968  1.42168  1.63846  1.15200  2.07888  1.56747  1.86678  1.62143  1.00358  1.50051  1.50824  1.11724 0.924878 0.990238  1.04753  1.02372 0.204819  1.48411  1.38418  1.34423  2.02100  1.14190  1.28339 0.455949 0.601381 0.621227 0.0461679  1.08415  1.04720 0.778411 0.807179  1.48902  1.11189  1.18833 -4.22495 0.118909\n 99:     56767.328: 0.141562 -0.685479  5.93619  5.99339  6.03791  6.48068  6.52877  5.89411  6.32774  6.01517  6.02631  6.77590  6.15808  6.43629  6.59688  6.27645  6.35332  6.31650  6.39163  6.87367  6.41312  6.56243  6.23614  6.18212  6.52345  6.27875  6.20672  6.01977  5.45712  5.64296  5.51430  6.12925  6.17457  6.36155  6.76102 0.949570 0.445866 -4.11399  1.10688  2.24930  1.42199  1.63954  1.15164  2.07828  1.56736  1.86667  1.62100  1.00353  1.50029  1.50817  1.11693 0.924768 0.990523  1.04763  1.02377 0.204582  1.48375  1.38412  1.34420  2.02073  1.14188  1.28353 0.456214 0.601477 0.619934 0.0455825  1.08430  1.04723 0.778899 0.807556  1.48897  1.11196  1.18834 -4.22502 0.118932\n100:     56767.328: 0.141563 -0.685477  5.93620  5.99339  6.03791  6.48068  6.52877  5.89411  6.32774  6.01517  6.02631  6.77590  6.15808  6.43629  6.59688  6.27645  6.35332  6.31650  6.39163  6.87367  6.41312  6.56243  6.23613  6.18212  6.52345  6.27875  6.20672  6.01977  5.45712  5.64296  5.51430  6.12925  6.17457  6.36155  6.76102 0.949570 0.445866 -4.11399  1.10688  2.24930  1.42199  1.63954  1.15164  2.07828  1.56736  1.86667  1.62100  1.00353  1.50029  1.50817  1.11693 0.924767 0.990522  1.04763  1.02377 0.204582  1.48375  1.38412  1.34420  2.02073  1.14188  1.28353 0.456213 0.601477 0.619934 0.0455824  1.08430  1.04723 0.778899 0.807556  1.48897  1.11196  1.18835 -4.22501 0.118973\n101:     56767.328: 0.141563 -0.685475  5.93621  5.99340  6.03790  6.48068  6.52878  5.89412  6.32774  6.01516  6.02632  6.77591  6.15808  6.43629  6.59687  6.27645  6.35332  6.31650  6.39164  6.87367  6.41312  6.56243  6.23613  6.18213  6.52346  6.27875  6.20673  6.01977  5.45712  5.64297  5.51431  6.12925  6.17458  6.36155  6.76102 0.949570 0.445865 -4.11399  1.10688  2.24930  1.42199  1.63954  1.15164  2.07828  1.56736  1.86666  1.62099  1.00354  1.50029  1.50817  1.11693 0.924767 0.990525  1.04763  1.02378 0.204583  1.48375  1.38412  1.34420  2.02072  1.14189  1.28353 0.456214 0.601475 0.619930 0.0455767  1.08430  1.04723 0.778901 0.807558  1.48897  1.11196  1.18835 -4.22501 0.118953\n102:     56767.328: 0.141565 -0.685463  5.93624  5.99340  6.03789  6.48068  6.52879  5.89413  6.32774  6.01513  6.02632  6.77591  6.15808  6.43628  6.59687  6.27646  6.35332  6.31652  6.39164  6.87368  6.41312  6.56244  6.23610  6.18213  6.52347  6.27875  6.20674  6.01977  5.45711  5.64297  5.51431  6.12927  6.17458  6.36154  6.76102 0.949570 0.445864 -4.11401  1.10688  2.24930  1.42199  1.63954  1.15164  2.07828  1.56736  1.86666  1.62099  1.00354  1.50029  1.50816  1.11693 0.924765 0.990527  1.04764  1.02378 0.204583  1.48374  1.38412  1.34420  2.02072  1.14189  1.28353 0.456213 0.601472 0.619926 0.0455703  1.08430  1.04723 0.778902 0.807559  1.48897  1.11197  1.18840 -4.22499 0.118966\n103:     56767.327: 0.141564 -0.685459  5.93629  5.99343  6.03787  6.48067  6.52885  5.89417  6.32775  6.01507  6.02634  6.77592  6.15811  6.43628  6.59685  6.27649  6.35334  6.31655  6.39167  6.87369  6.41313  6.56246  6.23607  6.18215  6.52352  6.27874  6.20676  6.01979  5.45711  5.64299  5.51432  6.12930  6.17462  6.36153  6.76104 0.949569 0.445860 -4.11401  1.10688  2.24929  1.42198  1.63956  1.15164  2.07827  1.56735  1.86664  1.62098  1.00356  1.50028  1.50816  1.11693 0.924760 0.990539  1.04765  1.02378 0.204588  1.48372  1.38413  1.34419  2.02072  1.14189  1.28353 0.456212 0.601461 0.619908 0.0455433  1.08428  1.04723 0.778909 0.807569  1.48898  1.11197  1.18840 -4.22499 0.118950\n104:     56767.327: 0.141561 -0.685436  5.93658  5.99359  6.03781  6.48062  6.52914  5.89435  6.32786  6.01489  6.02646  6.77596  6.15823  6.43625  6.59685  6.27665  6.35337  6.31674  6.39181  6.87376  6.41318  6.56263  6.23595  6.18226  6.52374  6.27872  6.20690  6.01991  5.45712  5.64311  5.51441  6.12947  6.17477  6.36153  6.76111 0.949565 0.445840 -4.11406  1.10687  2.24925  1.42192  1.63965  1.15164  2.07822  1.56733  1.86656  1.62093  1.00367  1.50020  1.50812  1.11696 0.924716 0.990597  1.04771  1.02382 0.204622  1.48359  1.38416  1.34415  2.02067  1.14189  1.28352 0.456180 0.601376 0.619836 0.0453858  1.08417  1.04718 0.778920 0.807632  1.48900  1.11200  1.18841 -4.22499 0.118963\n105:     56767.327: 0.141555 -0.685404  5.93691  5.99384  6.03820  6.48062  6.52936  5.89436  6.32840  6.01533  6.02665  6.77607  6.15828  6.43609  6.59776  6.27673  6.35326  6.31703  6.39205  6.87383  6.41334  6.56296  6.23600  6.18244  6.52362  6.27885  6.20717  6.02004  5.45734  5.64324  5.51461  6.12977  6.17476  6.36195  6.76120 0.949574 0.445808 -4.11414  1.10678  2.24923  1.42182  1.63962  1.15158  2.07819  1.56736  1.86657  1.62091  1.00386  1.50007  1.50802  1.11722 0.924588 0.990598  1.04777  1.02385 0.204668  1.48344  1.38420  1.34410  2.02064  1.14173  1.28349 0.456041 0.601178 0.619869 0.0451585  1.08396  1.04707 0.778780 0.807719  1.48900  1.11202  1.18845 -4.22494 0.118955\n106:     56767.327: 0.141547 -0.685408  5.93743  5.99389  6.03838  6.48119  6.52924  5.89471  6.32844  6.01508  6.02692  6.77634  6.15855  6.43633  6.59833  6.27694  6.35368  6.31713  6.39228  6.87410  6.41348  6.56310  6.23604  6.18263  6.52332  6.27912  6.20741  6.02026  5.45747  5.64343  5.51476  6.13012  6.17513  6.36218  6.76139 0.949572 0.445800 -4.11419  1.10683  2.24931  1.42182  1.63940  1.15151  2.07829  1.56733  1.86656  1.62095  1.00368  1.50017  1.50800  1.11718 0.924586 0.990429  1.04760  1.02382 0.204526  1.48361  1.38407  1.34400  2.02071  1.14158  1.28341 0.455974 0.601266 0.619678 0.0452679  1.08413  1.04714 0.778717 0.807460  1.48892  1.11203  1.18846 -4.22492 0.118946\n107:     56767.327: 0.141538 -0.685409  5.93781  5.99420  6.03855  6.48139  6.52963  5.89479  6.32868  6.01535  6.02713  6.77672  6.15866  6.43647  6.59840  6.27717  6.35390  6.31754  6.39255  6.87443  6.41359  6.56338  6.23608  6.18282  6.52375  6.27927  6.20769  6.02040  5.45776  5.64359  5.51493  6.13043  6.17526  6.36237  6.76168 0.949594 0.445805 -4.11421  1.10687  2.24948  1.42185  1.63899  1.15158  2.07837  1.56735  1.86664  1.62100  1.00340  1.50027  1.50794  1.11692 0.924591 0.990161  1.04745  1.02381 0.204303  1.48386  1.38395  1.34388  2.02081  1.14164  1.28327 0.455915 0.601388 0.619491 0.0454511  1.08436  1.04722 0.778614 0.807120  1.48882  1.11205  1.18847 -4.22489 0.118939\n108:     56767.327: 0.141537 -0.685403  5.93794  5.99406  6.03884  6.48132  6.52985  5.89493  6.32880  6.01529  6.02724  6.77684  6.15871  6.43644  6.59839  6.27712  6.35396  6.31753  6.39264  6.87454  6.41364  6.56352  6.23615  6.18285  6.52399  6.27942  6.20773  6.02047  5.45781  5.64366  5.51500  6.13056  6.17535  6.36252  6.76175 0.949589 0.445799 -4.11425  1.10687  2.24947  1.42186  1.63893  1.15162  2.07839  1.56736  1.86661  1.62099  1.00332  1.50022  1.50790  1.11685 0.924500 0.990179  1.04746  1.02385 0.204200  1.48383  1.38396  1.34387  2.02080  1.14165  1.28329 0.455837 0.601310 0.619660 0.0454262  1.08428  1.04718 0.778581 0.807156  1.48877  1.11207  1.18847 -4.22489 0.118948\n109:     56767.327: 0.141538 -0.685391  5.93811  5.99422  6.03878  6.48140  6.52993  5.89491  6.32880  6.01542  6.02729  6.77692  6.15877  6.43652  6.59841  6.27724  6.35406  6.31762  6.39267  6.87462  6.41372  6.56357  6.23610  6.18293  6.52407  6.27944  6.20783  6.02052  5.45788  5.64372  5.51507  6.13069  6.17540  6.36249  6.76180 0.949585 0.445793 -4.11430  1.10685  2.24948  1.42179  1.63903  1.15161  2.07837  1.56734  1.86659  1.62097  1.00330  1.50009  1.50790  1.11683 0.924397 0.990306  1.04758  1.02392 0.204109  1.48370  1.38399  1.34385  2.02077  1.14161  1.28333 0.455738 0.601135 0.619978 0.0453177  1.08407  1.04709 0.778541 0.807275  1.48874  1.11209  1.18846 -4.22490 0.118950\n110:     56767.327: 0.141539 -0.685390  5.93814  5.99428  6.03891  6.48146  6.52996  5.89498  6.32885  6.01540  6.02732  6.77693  6.15875  6.43657  6.59840  6.27727  6.35404  6.31778  6.39272  6.87465  6.41377  6.56358  6.23610  6.18295  6.52410  6.27941  6.20789  6.02057  5.45789  5.64377  5.51510  6.13070  6.17537  6.36242  6.76184 0.949585 0.445791 -4.11432  1.10682  2.24947  1.42177  1.63905  1.15161  2.07838  1.56733  1.86658  1.62098  1.00335  1.50007  1.50790  1.11684 0.924382 0.990310  1.04762  1.02393 0.204138  1.48367  1.38400  1.34384  2.02076  1.14159  1.28331 0.455717 0.601109 0.619991 0.0453036  1.08404  1.04707 0.778507 0.807269  1.48875  1.11210  1.18846 -4.22490 0.118940\n111:     56767.327: 0.141539 -0.685384  5.93823  5.99432  6.03886  6.48148  6.53005  5.89497  6.32891  6.01545  6.02736  6.77695  6.15879  6.43657  6.59841  6.27730  6.35409  6.31780  6.39276  6.87466  6.41380  6.56365  6.23611  6.18299  6.52418  6.27947  6.20791  6.02059  5.45793  5.64379  5.51512  6.13077  6.17544  6.36250  6.76185 0.949590 0.445788 -4.11434  1.10681  2.24947  1.42173  1.63903  1.15162  2.07840  1.56733  1.86659  1.62100  1.00345  1.50008  1.50789  1.11686 0.924395 0.990286  1.04759  1.02392 0.204202  1.48366  1.38401  1.34382  2.02076  1.14160  1.28329 0.455704 0.601122 0.619905 0.0453136  1.08406  1.04709 0.778480 0.807246  1.48877  1.11211  1.18846 -4.22490 0.118945\n112:     56767.327: 0.141539 -0.685384  5.93823  5.99432  6.03886  6.48148  6.53005  5.89497  6.32891  6.01545  6.02736  6.77695  6.15879  6.43657  6.59841  6.27730  6.35409  6.31780  6.39276  6.87466  6.41380  6.56365  6.23611  6.18299  6.52418  6.27947  6.20791  6.02059  5.45793  5.64379  5.51512  6.13077  6.17544  6.36250  6.76185 0.949590 0.445788 -4.11434  1.10681  2.24947  1.42173  1.63903  1.15162  2.07840  1.56733  1.86659  1.62100  1.00345  1.50008  1.50789  1.11686 0.924395 0.990286  1.04759  1.02392 0.204202  1.48366  1.38401  1.34382  2.02076  1.14160  1.28329 0.455704 0.601122 0.619905 0.0453136  1.08406  1.04709 0.778480 0.807246  1.48877  1.11211  1.18846 -4.22490 0.118945\n\n\nNote that `getReportCovariance=FALSE` causes an error in `TMB::sdreport` when no ADREPORTed variables are present\n\n\n  0:     56767.327: 0.141539 -0.685384  5.93823  5.99432  6.03886  6.48148  6.53005  5.89497  6.32891  6.01545  6.02736  6.77695  6.15879  6.43657  6.59841  6.27730  6.35409  6.31780  6.39276  6.87466  6.41380  6.56365  6.23611  6.18299  6.52418  6.27947  6.20791  6.02059  5.45793  5.64379  5.51512  6.13077  6.17544  6.36250  6.76185 0.949590 0.445788 -4.11434  1.10681  2.24947  1.42173  1.63903  1.15162  2.07840  1.56733  1.86659  1.62100  1.00345  1.50008  1.50789  1.11686 0.924395 0.990286  1.04759  1.02392 0.204202  1.48366  1.38401  1.34382  2.02076  1.14160  1.28329 0.455704 0.601122 0.619905 0.0453136  1.08406  1.04709 0.778480 0.807246  1.48877  1.11211  1.18846 -4.22490 0.118945\n  1:     56767.327: 0.141539 -0.685383  5.93823  5.99432  6.03886  6.48148  6.53005  5.89497  6.32891  6.01545  6.02736  6.77695  6.15879  6.43657  6.59841  6.27730  6.35409  6.31780  6.39276  6.87466  6.41380  6.56365  6.23611  6.18299  6.52418  6.27947  6.20791  6.02059  5.45793  5.64379  5.51512  6.13077  6.17544  6.36250  6.76185 0.949590 0.445788 -4.11434  1.10681  2.24947  1.42173  1.63903  1.15162  2.07840  1.56733  1.86659  1.62100  1.00345  1.50008  1.50789  1.11686 0.924395 0.990286  1.04759  1.02392 0.204202  1.48366  1.38401  1.34382  2.02076  1.14160  1.28329 0.455704 0.601122 0.619905 0.0453136  1.08406  1.04709 0.778480 0.807246  1.48877  1.11211  1.18846 -4.22490 0.118947\n  2:     56767.327: 0.141539 -0.685384  5.93823  5.99432  6.03886  6.48148  6.53005  5.89497  6.32891  6.01545  6.02736  6.77695  6.15879  6.43657  6.59841  6.27730  6.35409  6.31780  6.39276  6.87466  6.41380  6.56365  6.23611  6.18299  6.52418  6.27946  6.20792  6.02059  5.45793  5.64379  5.51512  6.13077  6.17544  6.36250  6.76185 0.949591 0.445787 -4.11434  1.10681  2.24947  1.42173  1.63903  1.15162  2.07840  1.56733  1.86659  1.62100  1.00345  1.50008  1.50789  1.11686 0.924395 0.990286  1.04759  1.02392 0.204202  1.48366  1.38401  1.34382  2.02076  1.14160  1.28329 0.455704 0.601122 0.619905 0.0453132  1.08406  1.04709 0.778480 0.807246  1.48877  1.11211  1.18846 -4.22490 0.118946\n  3:     56767.327: 0.141539 -0.685382  5.93826  5.99435  6.03884  6.48147  6.53009  5.89496  6.32891  6.01545  6.02736  6.77696  6.15877  6.43655  6.59839  6.27730  6.35408  6.31782  6.39276  6.87466  6.41379  6.56367  6.23606  6.18298  6.52420  6.27945  6.20792  6.02058  5.45793  5.64380  5.51512  6.13079  6.17544  6.36250  6.76184 0.949604 0.445786 -4.11438  1.10681  2.24947  1.42173  1.63903  1.15162  2.07840  1.56733  1.86659  1.62100  1.00345  1.50008  1.50789  1.11686 0.924393 0.990284  1.04759  1.02393 0.204196  1.48366  1.38402  1.34381  2.02077  1.14161  1.28329 0.455704 0.601120 0.619903 0.0453090  1.08406  1.04709 0.778481 0.807245  1.48876  1.11213  1.18847 -4.22490 0.118947\n  4:     56767.327: 0.141540 -0.685383  5.93827  5.99436  6.03883  6.48146  6.53010  5.89495  6.32891  6.01545  6.02737  6.77697  6.15876  6.43655  6.59839  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56367  6.23605  6.18298  6.52421  6.27944  6.20793  6.02058  5.45794  5.64380  5.51511  6.13080  6.17544  6.36250  6.76184 0.949608 0.445771 -4.11439  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924393 0.990284  1.04759  1.02393 0.204193  1.48366  1.38402  1.34381  2.02077  1.14161  1.28329 0.455704 0.601119 0.619902 0.0453071  1.08406  1.04710 0.778482 0.807245  1.48876  1.11214  1.18845 -4.22490 0.118947\n  5:     56767.327: 0.141540 -0.685383  5.93827  5.99436  6.03883  6.48146  6.53010  5.89495  6.32891  6.01545  6.02737  6.77697  6.15876  6.43655  6.59839  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56367  6.23605  6.18298  6.52421  6.27944  6.20793  6.02058  5.45794  5.64380  5.51511  6.13080  6.17544  6.36250  6.76184 0.949608 0.445772 -4.11439  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924393 0.990284  1.04759  1.02393 0.204193  1.48366  1.38402  1.34381  2.02077  1.14161  1.28329 0.455704 0.601119 0.619902 0.0453070  1.08406  1.04710 0.778482 0.807245  1.48876  1.11214  1.18845 -4.22490 0.118949\n  6:     56767.327: 0.141540 -0.685382  5.93827  5.99436  6.03883  6.48146  6.53010  5.89495  6.32891  6.01545  6.02737  6.77697  6.15876  6.43655  6.59839  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56367  6.23605  6.18298  6.52421  6.27944  6.20793  6.02058  5.45794  5.64380  5.51511  6.13080  6.17544  6.36250  6.76184 0.949608 0.445773 -4.11439  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924393 0.990284  1.04759  1.02393 0.204192  1.48366  1.38402  1.34381  2.02077  1.14161  1.28329 0.455704 0.601119 0.619902 0.0453069  1.08406  1.04710 0.778482 0.807245  1.48876  1.11213  1.18845 -4.22490 0.118947\n  7:     56767.327: 0.141540 -0.685381  5.93827  5.99436  6.03883  6.48146  6.53010  5.89495  6.32891  6.01545  6.02737  6.77697  6.15876  6.43655  6.59838  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56367  6.23604  6.18298  6.52421  6.27944  6.20793  6.02058  5.45794  5.64380  5.51512  6.13080  6.17544  6.36250  6.76184 0.949608 0.445774 -4.11439  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924392 0.990284  1.04759  1.02393 0.204192  1.48366  1.38402  1.34381  2.02077  1.14161  1.28329 0.455704 0.601119 0.619902 0.0453065  1.08406  1.04710 0.778482 0.807245  1.48876  1.11213  1.18845 -4.22490 0.118948\n  8:     56767.327: 0.141539 -0.685381  5.93828  5.99437  6.03883  6.48146  6.53010  5.89495  6.32891  6.01545  6.02737  6.77697  6.15876  6.43654  6.59838  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56368  6.23604  6.18298  6.52422  6.27944  6.20793  6.02058  5.45794  5.64380  5.51512  6.13080  6.17544  6.36250  6.76184 0.949606 0.445775 -4.11439  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924392 0.990283  1.04759  1.02393 0.204191  1.48366  1.38402  1.34381  2.02077  1.14161  1.28329 0.455703 0.601119 0.619902 0.0453057  1.08406  1.04710 0.778482 0.807245  1.48876  1.11213  1.18845 -4.22490 0.118947\n  9:     56767.327: 0.141536 -0.685381  5.93828  5.99437  6.03883  6.48146  6.53011  5.89495  6.32891  6.01545  6.02737  6.77697  6.15876  6.43654  6.59838  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56368  6.23604  6.18298  6.52422  6.27943  6.20793  6.02058  5.45794  5.64380  5.51512  6.13081  6.17544  6.36250  6.76184 0.949604 0.445777 -4.11438  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924391 0.990283  1.04759  1.02393 0.204187  1.48366  1.38402  1.34381  2.02077  1.14161  1.28329 0.455703 0.601118 0.619901 0.0453036  1.08406  1.04710 0.778483 0.807244  1.48876  1.11212  1.18845 -4.22490 0.118948\n 10:     56767.327: 0.141540 -0.685378  5.93828  5.99437  6.03883  6.48146  6.53011  5.89495  6.32891  6.01545  6.02737  6.77698  6.15876  6.43654  6.59838  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56368  6.23603  6.18298  6.52422  6.27943  6.20793  6.02058  5.45794  5.64380  5.51512  6.13081  6.17544  6.36250  6.76184 0.949603 0.445777 -4.11438  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924391 0.990283  1.04759  1.02393 0.204186  1.48366  1.38402  1.34380  2.02077  1.14161  1.28329 0.455703 0.601118 0.619900 0.0453026  1.08406  1.04710 0.778483 0.807244  1.48876  1.11212  1.18845 -4.22490 0.118947\n 11:     56767.327: 0.141540 -0.685378  5.93828  5.99437  6.03883  6.48146  6.53011  5.89495  6.32891  6.01545  6.02737  6.77698  6.15876  6.43654  6.59838  6.27730  6.35408  6.31783  6.39277  6.87466  6.41379  6.56368  6.23603  6.18298  6.52422  6.27943  6.20793  6.02058  5.45794  5.64380  5.51512  6.13081  6.17544  6.36250  6.76184 0.949603 0.445777 -4.11438  1.10682  2.24948  1.42173  1.63903  1.15163  2.07840  1.56733  1.86659  1.62100  1.00345  1.50007  1.50789  1.11685 0.924391 0.990283  1.04759  1.02393 0.204186  1.48366  1.38402  1.34380  2.02077  1.14161  1.28329 0.455703 0.601118 0.619900 0.0453026  1.08406  1.04710 0.778483 0.807244  1.48876  1.11212  1.18845 -4.22490 0.118947\n\n\nPlot results\n\nplot( fit )\n\n\n### Running `plot_results`\n\n\n\n### Creating plots in directory /Users/eli.holmes/Documents/GitHub/NOAAHackDays/topics-2024/2024-04-25-vast\n\n\n\n### Making plots of data availability and knots\n\n\nWarning in plot.sf(map_data, col = land_color, add = TRUE): ignoring all but\nthe first attribute\n\n\n\n### Obtaining default settings for plotting maps\n\n\n\n### Making plot of anisotropy\n\n\n\n### Making plot of abundance index\n\n\n\n### Making plot of covariance/dissimilarity matrices\n\n\n\n### Skipping plot of composition data; must re-run with standard errors and multiple categories to plot\n\n\n\n### Making plot of spatial indices\n\n\nPlotting center-of-gravity...\n\n\nNot using bias-corrected estimates for center of gravity...\n\n\nPlotting effective area occupied...\n\n\nNot using bias-corrected estimates for effective area occupied (natural scale)...\n\n\nNot using bias-corrected estimates for effective area occupied (log scale)...\n\n\n\n### Making plot of range edges\n\n\n# Obtaining samples from predictive distribution for variable D_gct\n\n\n  Finished sample 10 of 100\n\n\n  Finished sample 20 of 100\n\n\n  Finished sample 30 of 100\n\n\n  Finished sample 40 of 100\n\n\n  Finished sample 50 of 100\n\n\n  Finished sample 60 of 100\n\n\n  Finished sample 70 of 100\n\n\n  Finished sample 80 of 100\n\n\n  Finished sample 90 of 100\n\n\n  Finished sample 100 of 100\n\n\n\n### Making plots of spatial predictions\n\n\n # plot_num 3: Plotting density maps (in log-space)\n\n\n\n### Making plots for factors (if present)\n\n\n\n### Making plots for spatial cluster analysis\n\n\nWarning in (function (fit, var_name = \"D_gct\", transform_var = log, k = 4, :\n`plot_clusters` will go slowly due to large size\n\n\n\n### Making quantile residuals using conditional simulation and package DHARMa\n\n\nSampling from the distribution of data conditional on estimated fixed and random effects\n\n\n  Finished sample 25 of 250\n\n\n  Finished sample 50 of 250\n\n\n  Finished sample 75 of 250\n\n\n  Finished sample 100 of 250\n\n\n  Finished sample 125 of 250\n\n\n  Finished sample 150 of 250\n\n\n  Finished sample 175 of 250\n\n\n  Finished sample 200 of 250\n\n\n  Finished sample 225 of 250\n\n\n  Finished sample 250 of 250\n\n\nSubstituting probability-integral-transform (PIT) residuals for DHARMa-calculated residuals\n\n\nInvisibly returning output from `DHARMa::createDHARMa`, e.g., to apply `plot.DHARMa` to this output\n\n\n\n### Plotting quantile residuals \n\n\n\n### Skipping plot of semivariance for normal-transformed quantile residuals"
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-setup.html",
    "href": "topics-2024/2024-05-24-sits/sits-setup.html",
    "title": "sits set up in dhub",
    "section": "",
    "text": "sits R package\nThis takes awhile.\nInstalling package into '/usr/local/lib/R/site-library'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'shape', 'numDeriv', 'progressr', 'SQUAREM', 'diagram', 'lava', 'cards', 'labelled', 'prodlim', 'broom.helpers', 'patchwork', 'iterators', 'clock', 'gower', 'hardhat', 'ipred', 'timeDate', 'modeltools', 'ggstats', 'poorman', 'foreach', 'ModelMetrics', 'pROC', 'recipes', 'dtw', 'clue', 'flexclust', 'ggrepel', 'RSpectra', 'RcppParallel', 'shinyjs', 'RcppThread', 'globals', 'listenv', 'parallelly', 'zeallot', 'DT', 'GGally', 'ranger', 'philentropy', 'future.apply', 'caret', 'dendextend', 'dtwclust', 'exactextractr', 'future', 'kohonen', 'luz', 'openxlsx', 'randomForest', 'randomForestExplainer', 'supercells', 'xgboost'"
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-setup.html#check-your-netrc-file",
    "href": "topics-2024/2024-05-24-sits/sits-setup.html#check-your-netrc-file",
    "title": "sits set up in dhub",
    "section": "check your netrc file",
    "text": "check your netrc file\nIt wants this at the home dir.\n\ncat(paste0(readLines(\"~/.netrc\"), collapse=\"\\n\"))\n\nShould look like this\nmachine urs.earthdata.nasa.gov\nlogin username\npassword yourpassword\nIf you don’t see this. You can make it\n\nuse_this::edit_file(\"~/.netrc\")"
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-setup.html#test-if-it-is-working",
    "href": "topics-2024/2024-05-24-sits/sits-setup.html#test-if-it-is-working",
    "title": "sits set up in dhub",
    "section": "Test if it is working",
    "text": "Test if it is working\n\nlibrary(sits)\n\nSITS - satellite image time series analysis.\n\n\nLoaded sits v1.5.1.\n        See ?sits for help, citation(\"sits\") for use in publication.\n        Documentation avaliable in https://e-sensing.github.io/sitsbook/.\n\n# Create a data cube covering an area in Brazil\ns2_23MMU_cube &lt;- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"23MMU\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2018-07-12\",\n  end_date = \"2019-07-28\"\n)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\nMake a plot.\n\nplot(s2_23MMU_cube,\n  red = \"B11\",\n  blue = \"B02\",\n  green = \"B8A\",\n  date = \"2018-10-05\"\n)"
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html",
    "href": "topics-2024/2024-05-24-sits/sits-example.html",
    "title": "landsat imagery for a region",
    "section": "",
    "text": "Update: I was unable to get the code to run when I tried to run this months later.\nIn this example, I will use sits to prepare some imagery for a specific region and get snow estimates. https://www.usgs.gov/landsat-missions/normalized-difference-snow-index\nI will use the Microsoft Planetary Computer data since it has a nice vizualization that will help me find tiles."
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html#get-the-tile-ids",
    "href": "topics-2024/2024-05-24-sits/sits-example.html#get-the-tile-ids",
    "title": "landsat imagery for a region",
    "section": "Get the tile IDs",
    "text": "Get the tile IDs\nFirst step is to go to the visualizer and figure out the tiles I need. I am looking at an area close to the Canadian border of Washington state. MPC search page. I want to click on the files in the left nav and get the tile ids around “Early Winters”. I need four: “10UFU”, “10UGU”, “10UGV”, “10UFV”.\nAt first I used tiles, but later went to a small region of interest (roi). When I went from tiles to roi in the sits_regularize() the last date had no data and that caused errors."
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html#load-the-package",
    "href": "topics-2024/2024-05-24-sits/sits-example.html#load-the-package",
    "title": "landsat imagery for a region",
    "section": "Load the package",
    "text": "Load the package\n\nlibrary(sits)\n\nSITS - satellite image time series analysis.\n\n\nLoaded sits v1.5.1.\n        See ?sits for help, citation(\"sits\") for use in publication.\n        Documentation avaliable in https://e-sensing.github.io/sitsbook/."
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html#get-the-data",
    "href": "topics-2024/2024-05-24-sits/sits-example.html#get-the-data",
    "title": "landsat imagery for a region",
    "section": "Get the data",
    "text": "Get the data\nI am going to get a month of data for a small region.\n\nroi &lt;- c(\n  lon_min = -120.436866, lat_min = 47.570978,\n  lon_max = -120.375207, lat_max = 48.611761\n)\ns2_cube &lt;- sits_cube(\n    source = \"MPC\",\n    collection = \"SENTINEL-2-L2A\",\n    roi = roi,\n    bands = c(\"B03\", \"B11\", \"CLOUD\"),\n    start_date = as.Date(\"2022-07-01\"),\n    end_date = as.Date(\"2022-07-31\")\n)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |======================================================================| 100%\n\n\nThe time line is not regular.\n\nsits_timeline(s2_cube)\n\nWarning: cube is not regular, returning all timelines\n\n\n$`10TFT`\n [1] \"2022-07-01\" \"2022-07-03\" \"2022-07-08\" \"2022-07-11\" \"2022-07-13\"\n [6] \"2022-07-16\" \"2022-07-18\" \"2022-07-21\" \"2022-07-23\" \"2022-07-26\"\n[11] \"2022-07-28\"\n\n$`10UFU`\n[1] \"2022-07-01\" \"2022-07-06\" \"2022-07-11\" \"2022-07-16\" \"2022-07-21\"\n[6] \"2022-07-26\""
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html#save-our-cube",
    "href": "topics-2024/2024-05-24-sits/sits-example.html#save-our-cube",
    "title": "landsat imagery for a region",
    "section": "Save our cube",
    "text": "Save our cube\nThe documentation says things are faster if we save a copy of our files. And we will reduce the area of interest to a really small area and weekly data. This is going to save a bunch of little files (4 tiles x 52 weeks x 3 bands) into the tempdir. This saving takes a long time itself and seems kind of pointless for this case. So I skipped this.\n\n# roi as (lon_min, lon_max, lat_min, lat_max)\nroi &lt;- c(\n  lon_min = -120.436866, lat_min = 48.570978,\n  lon_max = -120.375207, lat_max = 48.611761\n)\nsits_cube_copy(s2_cube,\n  output_dir = here::here(\"topics-2024/2024-05-24-sits/tempdir/chl1\"),\n  roi = roi\n)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |=====================                                                 |  29%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================                |  76%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%\n\n\n# A tibble: 2 × 12\n  source collection     satellite sensor tile    xmin   xmax   ymin   ymax crs  \n  &lt;chr&gt;  &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;\n1 MPC    SENTINEL-2-L2A SENTINEL… MSI    10UFU 688910 693620 5.38e6 5.39e6 EPSG…\n2 MPC    SENTINEL-2-L2A SENTINEL… MSI    10UFU 688900 693620 5.38e6 5.39e6 EPSG…\n# ℹ 2 more variables: labels &lt;list&gt;, file_info &lt;list&gt;"
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html#regularize-our-cube",
    "href": "topics-2024/2024-05-24-sits/sits-example.html#regularize-our-cube",
    "title": "landsat imagery for a region",
    "section": "Regularize our cube",
    "text": "Regularize our cube\nNext we need to regularize our cube. I will regularize to 14 day period with a 60m resolution. This is going to take a little while time.\n\nreg_cube &lt;- sits_regularize(\n  cube = s2_cube,\n  output_dir = here::here(\"topics-2024/2024-05-24-sits/tempdir/chl2\"),\n  roi = roi,\n  res  = 60,\n  period = \"P14D\",\n  multicores = 4\n )\n\nWarning: regularization is faster when data is stored locally\n use 'sits_cube_copy()' to copy data locally before regularization\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html#snow-index",
    "href": "topics-2024/2024-05-24-sits/sits-example.html#snow-index",
    "title": "landsat imagery for a region",
    "section": "Snow index",
    "text": "Snow index\nhttps://sentiwiki.copernicus.eu/web/s2-processing#S2Processing-Step1b:NormalisedDifferenceSnowIndex(NDSI)\n\nreg_cube &lt;- sits_apply(reg_cube,\n   NDSI = (B03 - B11)/(B03 + B11),\n   output_dir = here::here(\"topics-2024/2024-05-24-sits/tempdir/chl2\"),\n   multicores = 4\n   )"
  },
  {
    "objectID": "topics-2024/2024-05-24-sits/sits-example.html#plot",
    "href": "topics-2024/2024-05-24-sits/sits-example.html#plot",
    "title": "landsat imagery for a region",
    "section": "Plot",
    "text": "Plot\nMake a plot.\n\nplot(reg_cube,\n  band = \"NDSI\",\n  date = \"2022-07-15\"\n)\n\n-- tmap v3 code detected --\n\n\n[v3-&gt;v4] tm_raster(): instead of 'style = \"cont\"', use 'col.scale = tm_scale_continuous()' and migrate the argument(s) 'style.args', 'midpoint', 'palette' (rename to 'values') to 'tm_scale_continuous(&lt;HERE&gt;)'. For small multiples, specify a 'tm_scale_' for each multiple, and put them in a list: 'col.scale = list(&lt;scale1&gt;, &lt;scale2&gt;, ...)'\n\n\n[v3-&gt;v4] tm_raster(): migrate the argument(s) related to the legend of the visual variable 'col', namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run 'cols4all::c4a_gui()' to explore them. The old palette name \"RdYlGn\" is named \"rd_yl_gn\" (in long format \"brewer.rd_yl_gn\")\n\n\n\n\n\n\n\n\n\nERROR\n\n# Obtain a time series from the raster cube from a point\nsample_latlong &lt;- tibble::tibble(\n  longitude = -120.43687,\n  latitude  = -47.57098\n)\nseries &lt;- sits_get_data(\n  cube = reg_cube,\n  samples = sample_latlong\n)"
  }
]